Camille: Hallo und willkommen zurück zu „Tech-Blitz“, dem Podcast, in dem wir die Technologie, die unsere Welt prägt, verständlich machen. Ich bin Camille.
Luc: Und ich bin Luc. Heute werfen wir einen Blick hinter die Kulissen, wie die KI-Modelle, die wir täglich nutzen, eigentlich lernen und so schlau werden.
Camille: Das ist ein faszinierendes Thema. Wir sehen diese KIs oft als eine Art Blackbox, aber ihr Lernprozess folgt klaren Regeln.
Luc: Genau. Und dieses Lernen beginnt mit einem Prozess namens „Vorabtraining“.
Camille: Vorabtraining.
Luc: Stellen Sie sich das so vor, als würde man eine brandneue KI zur allgemeinen Bildung in die Schule schicken. Sie liest einen riesigen Teil des Internets, um die Grundlagen von Sprache, logischem Denken und der allgemeinen Funktionsweise der Welt zu erlernen.
Camille: Nach dem Vorabtraining ist die KI also wie ein Universitätsabsolvent: schlau und fähig, aber ohne spezifische Berufserfahrung.
Luc: Genau. Und lange Zeit war der nächste Schritt das „Finetuning“. Das ist so, als würde man diesen Absolventen für ein Spezialstudium einschreiben.
Camille: Finetuning... spielt da das „Transferlernen“ eine Rolle? Den Begriff habe ich schon einmal gehört.
Luc: Genau. Das Transferlernen ist der Schlüssel. Stellen Sie sich das so vor: Sie würden einem brillanten Physiker keine Grundlagenmathematik beibringen, bevor er sich mit der Quantenmechanik beschäftigt. Er überträgt seine vorhandenen mathematischen Fähigkeiten. Die KI macht dasselbe. Ein großartiges Beispiel dafür sind Sprachen.
Camille: Inwiefern?
Luc: Man kann ein Modell nehmen, das ein Experte für Englisch ist, und ihm dann eine viel kleinere Menge an französischem Text zeigen. Es wird unglaublich schnell Französisch lernen.
Camille: Weil es die allgemeinen Konzepte von Grammatik, Syntax und Satzstruktur bereits vom Englischen kennt?
Luc: Genau. Es muss nicht von Grund auf neu lernen, was ein Verb ist. Es lernt einfach die französischen Wörter und Regeln und überträgt dabei die zugrunde liegenden Konzepte. Darin liegt die Stärke.
Camille: Es überträgt also sein enormes Allgemeinwissen aus dem Vorabtraining auf die neue, spezifische Aufgabe.
Luc: Ganz genau. Deshalb kann es mit erstaunlich wenigen neuen Informationen zu einem Experten für Ihre Daten werden. Es fängt nicht bei Null an, sondern baut auf einem massiven Fundament auf.
Camille: Das ergibt Sinn. Aber wie wir in unserer letzten Folge über Transformer besprochen haben, zeichnet sich ein neuer, flexiblerer Ansatz ab, oder?
Luc: Ja, und er wird durch die massive Erweiterung des Kurzzeitgedächtnisses der KI, des sogenannten „Kontextfensters“, vorangetrieben. Dieser Ansatz wird In-Context Learning oder ICL genannt.
Camille: Anstatt die KI also neu zu trainieren, um eine Spezialistin zu werden, gibt man ihr einfach die Informationen, die sie für die aktuelle Aufgabe benötigt.
Luc: Genau. Es ist, als würde man einen brillanten Berater engagieren und anstatt ihn auf ein mehrjähriges Schulungsprogramm zu schicken, gibt man ihm einfach die genauen Unterlagen, die er für das aktuelle Projekt benötigt.
Camille: Hier kommt das Konzept des „Grounding“ ins Spiel, das die Antworten der KI an die spezifischen Informationen bindet, die Sie bereitstellen.
Luc: Genau. Aber das bringt uns zu einem entscheidenden Punkt, der oft missverstanden wird: die Art, wie die KI sich diese Informationen „merkt“.
Camille: Der Unterschied zwischen dem Pauken für eine Prüfung und dem wirklichen Beherrschen eines Themas?
Luc: Eine perfekte Analogie! In-Context Learning ist das „Pauken“. Das Wissen, das Sie im Prompt bereitstellen, ist temporär. Die KI nutzt es für dieses eine Gespräch, aber sobald das Gespräch beendet ist, ist dieses Wissen weg.
Camille: Es vergisst alles.
Luc: Es vergisst alles komplett. Es ist also ein Einweg-Gedächtnis. Wenn es morgen dieselben Informationen kennen soll, muss ich die Dokumente jedes Mal von neuem bereitstellen.
Camille: Verstehe.
Luc: Das ist die Realität von ICL. Es ist unglaublich flexibel, basiert aber auf dem Kurzzeitgedächtnis. Beim Finetuning hingegen geht es darum, eine dauerhafte Fähigkeit zu schaffen. Wenn man ein Modell feinabstimmt, verändert man grundlegend seine interne Struktur. Das neue Wissen wird Teil seiner Kernidentität.
Camille: Das feinabgestimmte Wissen bleibt also über alle Gespräche hinweg für immer erhalten?
Luc: Ja. Es ist wie Fahrradfahren zu lernen. Diese Fähigkeit wird verinnerlicht. Man muss sich nicht jedes Mal, wenn man auf das Fahrrad steigt, an die Physik des Gleichgewichts erinnern.
Camille: Luc, das erklärt eine sehr häufige Erfahrung, die Menschen mit Chatbots machen. Man kann ein langes, detailliertes Gespräch führen, aber wenn man ein neues Chatfenster öffnet, hat die KI keine Ahnung, worüber man vorher gesprochen hat.
Luc: Genau! Das ist In-Context Learning in Aktion. Die gesamte Chat-Historie in dieser Sitzung ist der Kontext.
Camille: Ich verstehe.
Luc: Wenn Sie ein neues Fenster öffnen, beginnen Sie mit einem leeren Kontext. Die KI hat nicht im menschlichen Sinne „vergessen“; ihr temporärer Arbeitsbereich wurde einfach geleert.
Camille: Aber was ist mit neuen Funktionen wie „Memory“, die einige KIs einführen? Es fühlt sich an, als würden sie anfangen, sich Dinge zwischen den Sitzungen zu merken.
Luc: Das ist ein hervorragender Punkt, und es ist entscheidend zu verstehen, wie das funktioniert. Die KI wird nicht ständig mit Ihren Gesprächen feinabgestimmt. Das wäre unglaublich ineffizient.
Camille: Es ist also eine Art Umgehungslösung?
Luc: Das könnte man so sagen. Diese Speicherfunktionen sind eine clevere Form des automatisierten In-Context-Learnings. Wenn Sie ein neues Gespräch beginnen, durchsucht das System schnell Ihre früheren Chats nach Informationen, die für Ihre neue Anfrage relevant erscheinen. Diese Textausschnitte fügt es dann automatisch im Hintergrund in den Prompt ein.
Camille: Es sieht also so aus, als ob die KI sich an meine Projektdetails erinnert, aber in Wirklichkeit hat man ihr direkt vor dem Gespräch mit Ihnen einen Spickzettel zugesteckt.
Luc: Genau. Das Modell selbst lernt oder entwickelt sich nicht durch Ihre Gespräche. Es nutzt lediglich ein intelligenteres System, um auf frühere Kontexte zurückzugreifen.
Camille: Die große Frage für jeden, der diese Tools nutzt, lautet also: „Brauche ich einen temporären Berater oder einen permanenten Experten?“
Luc: Das ist die perfekte Art, die Frage zu stellen. Und mit diesem Gedanken sollten wir für heute zum Schluss kommen.
Camille: Vielen Dank fürs Zuhören und bis zur nächsten Folge von „Tech-Blitz“!