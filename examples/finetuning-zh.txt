Camille: 大家好，欢迎回到“科技快报”，在这里我们将解读塑造我们世界的科技。我是卡米尔。
Luc: 我是卢克。今天，我们将揭开我们每天使用的AI模型是如何学习并变得如此聪明的神秘面纱。
Camille: 这可是个引人入胜的话题。我们常常把这些人工智能看作是某种“黑匣子”，但它们学习确实有一个真实的过程。
Luc: 没错。而这种学习始于一个叫做“预训练”的过程。
Camille: 预训练。
Luc: 你可以把它想象成把一个全新的AI送去上学接受通用的教育。它会阅读互联网的大量内容，学习语言、推理以及世界运作的基本原理。
Camille: 所以经过预训练后，人工智能就像一个大学毕业生：聪明且有能力，但没有具体的职业经验。
Luc: 正是如此。而很长一段时间，下一步是“微调”。这就像让那名毕业生去获得专业学位一样。
Camille: 微调... 这就是“迁移学习”发挥作用的地方吗？我以前听说过这个术语。
Luc: 完全正确。迁移学习是关键。你可以这样想：你不会在物理学家研究量子力学之前教他们基础数学。他们会利用已有的数学技能。人工智能也是如此。一个很好的例子是语言。
Camille: 怎么说？
Luc: 你可以拿一个英语专家模型，然后向它展示少量法语文本。它将以惊人的速度学会法语。
Camille: 因为模型已经理解了英语中的一般语法、句法和句子结构概念？
Luc: 正是如此。它不需要重新学习什么是动词。它只是学习法语单词和规则，并迁移潜在的概念。这就是它的强大之处。
Camille: 所以它能将预训练阶段积累的庞大通用知识迁移到新的、具体的任务中。
Luc: 你理解正确。 这就是为什么它能用惊人的少量新信息成为你数据的专家。它不是从零开始；它是在一个巨大的基础之上构建。
Camille: 这有道理。但正如我们在上期关于Transformer的讨论中所说，一种新的、更灵活的方法正在兴起，对吧？
Luc: 是的，这得益于人工智能的短期记忆，或称“上下文窗口”的大规模扩展。这种方法被称为上下文学习。
Camille: 所以，与其重新训练AI成为专家，你只需提供它完成当前任务所需的信息。
Luc: 你理解正确。这就像聘请一位才华横溢的顾问，而不是让他们参加为期多年的培训项目，你只需提供他们当前项目所需的精确简报文件。
Camille: 这就是“ grounding”的概念发挥作用的地方，它将人工智能的回答与你提供的具体信息联系起来。
Luc: 没错。但这引出了一个经常被误解的关键点，即人工智能“记住”这些信息的方式。这在于临时知识和永久技能之间的区别。
Camille: 死记硬背和真正掌握一个学科之间有什么区别？
Luc: 完美的类比！上下文学习就像“死记硬背”。你提供在提示词中的知识是暂时的。人工智能会在一次对话中使用它，但一旦对话结束，这些知识就会消失。
Camille: 它完全忘记了。
Luc: 它完全忘记了。所以它只有一次性记忆。如果我希望它明天还记得相同的信息，我就必须重新提供那些文档。
Camille: 没错。
Luc: 这就是ICL的现实。它非常灵活，但它基于短期记忆。而微调，则是关于创造一个永久性的技能。当你微调一个模型时，你本质上是在改变它的内部结构。新的知识成为了它核心身份的一部分。
Camille: 所以微调后的知识会永久地在所有对话中保留吗？
Luc: 是的。这就像学骑自行车。技能已经根深蒂固了。你每次骑上自行车都不需要被提醒平衡的物理原理。
Camille: 卢克，这实际上解释了人们与聊天机器人打交道时的一个常见体验。你可以进行长时间的详细对话，但如果你开始一个新的聊天窗口，人工智能就不知道你之前谈论过什么了。
Luc: 没错！这就是上下文学习的实际应用。你当前会话中的整个聊天历史都是上下文。
Camille: 我明白了。
Luc: 当你打开一个新的窗口时，你从一个空白的上下文开始。人工智能并没有像人类那样的“遗忘”；它的临时工作区只是被清空了。
Camille: 但是那些一些AI正在引入的“记忆”功能呢？感觉它们开始记住会话之间的信息了。
Luc: 这是一个非常好的观点，理解这一点至关重要。人工智能并不是在持续地用你的对话进行微调。那样会非常低效。
Camille: 所以这是一种解决方法吗？
Luc: 你可以这么说。这些记忆功能是一种巧妙的自动化上下文学习形式。当你开始新的对话时，系统会快速搜索你过去聊天中的信息，这些信息看起来与你的新查询相关。然后，它会在幕后自动将这些片段填充到提示中。
Camille: 所以看来人工智能记住了我的项目细节，但它只是在开始和你对话之前，被递上了一张小抄而已。
Luc: 正是如此。模型本身并没有从你的对话中学习或进化。它只是使用更智能的系统来回忆过去的上下文。
Camille: 因此，对于任何使用这些工具的人来说，最大的问题是：“我需要一位临时顾问，还是一位永久的专家？”
Luc: 这个说法很贴切。好了，差不多该结束了。
Camille: 感谢您的收听，我们下期“科技快报”再见！
