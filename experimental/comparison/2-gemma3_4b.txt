Camille: Hola y bienvenido a « Tech Éclair », el podcast donde analizamos la tecnología que da forma a nuestro mundo. Soy Camille.
Luc: Y soy Luc. Hoy vamos a descubrir cómo los modelos de IA que usamos a diario aprenden y se vuelven tan inteligentes.
Camille: Es un tema fascinante. A menudo percibimos estas IA como cajas negras, pero su aprendizaje sigue siendo un proceso muy real.
Luc: Exactamente. Y este aprendizaje comienza con un proceso llamado el « pre-entrenamiento».
Camille: El pre-entrenamiento.
Luc: Imaginen que enviamos una nueva IA a la escuela para darle una educación general. Ella lee una gran cantidad de datos en Internet para aprender los fundamentos del lenguaje, del razonamiento y cómo funciona el mundo en general.
Camille: Así que, después del pre-entrenamiento, la IA es como un joven que acaba de terminar sus estudios.
Luc: Precisamente. Y durante mucho tiempo, la siguiente etapa ha sido ‘el ajuste fino’ (fine-tuning). Es como enviar a este graduado a optimizar su modelo.
Camille: El ajuste fino... ¿es ahí donde entra en juego el aprendizaje por transferencia?
Luc: Exactamente. El aprendizaje por transferencia es la clave. Observen: no enseñan matemáticas básicas a un físico brillante antes de que se ataque a la mecánica cuántica. Él transfiere sus habilidades matemáticas existentes. La IA hace lo mismo. Los idiomas son un excelente ejemplo.
Camille: Es decir?
Luc: Puede tomar un modelo experto en inglés y presentarle una cantidad considerablemente menor de texto en francés. Él aprenderá el francés a una velocidad asombrosa.
Camille: Porque ya comprende los conceptos generales de gramática, de sintaxis y de estructura de frase gracias al inglés.
Luc: Exactamente. No necesita reaprender lo que es un verbo. Se basa en su conocimiento previo para aprender las palabras y las reglas del francés.
Camille: Así que, aprovecha sus enormes conocimientos generales adquiridos durante el preentrenamiento para la nueva tarea específica.
Luc: Es exactamente así. Por eso puede convertirse en un experto de sus datos con asombrosamente poca información nueva.
Camille: Lógico. Pero como comentamos en nuestro último episodio sobre los Transformers, una nueva aproximación más flexible está surgiendo, ¿no?
Luc: Sí, y esto es posible gracias a la expansión masiva de la memoria a corto plazo de la IA, o ‘ventana de contexto’. Esta aproximación se llama aprendizaje en contexto, o ICL (Aprendizaje en Contexto).
Camille: Así que, en lugar de hacerla una especialista, le damos la información que necesita para completar la tarea.
Luc: Así que, comprendió todo. Es como contratar a un consultor brillante y, en lugar de enviarlo a cursar un programa de formación de varios años, simplemente se le proporcionan los documentos de información precisos que necesita para el proyecto en curso.
Camille: Es ahí donde entra en juego el concepto de ‘anclaje’ (grounding), que consiste en vincular las respuestas de la IA a la información específica que le proporcionas.
Luc: Exactamente. Pero esto nos lleva a un punto crucial que a menudo se malinterpreta: cómo la IA ‘recuerda’ estas informaciones. Es la diferencia entre un conocimiento temporal y una habilidad permanente.
Camille: La diferencia entre memorizar algo para un examen y realmente comprenderlo.
Luc: ¡Una analogía perfecta! El aprendizaje en contexto es como estudiar para un examen. La información que proporciona en el prompt son temporales. La IA la utiliza para esta única conversación, pero una vez que la conversación termina, esta información desaparece.
Camille: Olvidó todo.
Luc: Ella olvidó todo. Por lo tanto, es una memoria de uso único. Necesito proporcionarle los documentos para que tenga conocimiento de ellos mañana.
Camille: De acuerdo.
Luc: Esta es la realidad del ICL. Es increíblemente flexible, pero se basa en una memoria a corto plazo. El ajuste, en cambio, tiene como objetivo crear una habilidad permanente.
Camille: Entonces, ¿las nuevas bases de conocimiento aprendidas mediante el ajuste persistirán en todas las conversaciones, de forma indefinida?
Luc: Sí. Es como aprender a montar en bicicleta. La habilidad se ha arraigado.
Camille: Luc, eso explica una experiencia muy común con los chatbots. Podemos tener una conversación larga y detallada, pero si abrimos una nueva ventana de discusión, la IA no recordará lo que se dijo antes.
Luc: ¡Exactamente! Es el aprendizaje en contexto en acción. Toda la conversación que han tenido en esta sesión constituye el contexto.
Camille: Entiendo.
Luc: Cuando abres una nueva ventana, comienzas con un contexto vacío. La IA no ha 'olvidado' en el sentido humano del término.
Camille: Pero, ¿qué pasa con las nuevas funciones como la «Memoria» que algunas IA están empezando a integrar? Parece que realmente están empezando a recordar las cosas de una sesión a otra.
Luc: Es un excelente comentario, y es fundamental comprender cómo funciona. La IA no se perfecciona constantemente a través de tus conversaciones. Sería increíblemente ineficiente.
Camille: Entonces, ¿es una estrategia?
Luc: Se puede decir eso. Estas funciones de memorización son una forma ingeniosa de aprendizaje en contexto automatizado. Estas funciones consultan rápidamente tus conversaciones anteriores para encontrar información relevante para tu nueva solicitud, insertando automáticamente estos extractos en el prompt, de forma interna.
Camille: Entonces, tenemos la impresión de que la IA recuerda los detalles de mi proyecto, pero en realidad, le hemos proporcionado información justo antes de que empiece a hablarme.
Luc: Precisamente. El modelo en sí no aprende ni evoluciona a partir de tus conversaciones; simplemente utiliza un sistema más eficiente para recordar el contexto anterior.
Camille: Entonces, la gran pregunta para quien usa estas herramientas es: ¿necesito un asesor temporal o un experto permanente?
Luc: Esta es la manera ideal de plantear la cuestión. Y basándonos en esta reflexión, es hora de llegar a una conclusión.”
Camille: Gracias por escucharnos, ¡y nos vemos en el próximo episodio de ‘Tech Éclair’!
