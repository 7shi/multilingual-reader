Camille: Hola y bienvenido/a a «Tecno Flash», el podcast donde desciframos la tecnología que moldea nuestro mundo. Soy Camille.
Luc: Y yo soy Luc. Hoy vamos a desvelar cómo los modelos de IA que usamos en nuestra vida cotidiana aprenden y se hacen tan inteligentes.
Camille: Es un tema fascinante. A menudo percibimos estas IAs como cajas negras, pero su aprendizaje sigue un proceso muy real.
Luc: Exacto. Este aprendizaje comienza con un proceso llamado pre-entrenamiento.
Camille: El pre-entrenamiento.
Luc: Imagina que se envía una IA completamente nueva a la escuela para darle una base general de conocimientos. Ella lee una cantidad masiva de datos en Internet para aprender los fundamentos del lenguaje, el razonamiento y el funcionamiento del mundo en general.
Camille: Entonces, después del pre-entrenamiento, la IA es como un recién graduado de la universidad: inteligente y competente pero sin experiencia laboral específica.
Luc: Eso es exactamente. Y durante mucho tiempo, el siguiente paso ha sido el afinamiento. Es como enviar a ese graduado para que realice una especialización.
Camille: El afinamiento es donde entra en juego el aprendizaje por transferencia. Ya he escuchado ese término antes.
Luc: Exactamente. El aprendizaje por transferencia es la clave. No le enseñarías matemáticas básicas a un brillante físico antes de que se enfrente a la mecánica cuántica. Transfiere sus habilidades matemáticas existentes. La IA hace lo mismo. Las lenguas son un excelente ejemplo de ello.
Camille: ¿Qué quieres decir?
Luc: Luc puede tomar un modelo experto en inglés y luego presentarle una cantidad mucho menor de texto en francés. Aprenderá el francés a una velocidad increíble.
Camille: ¿No entiende los conceptos generales de gramática, sintaxis y estructura de la frase en español debido al affinage del aprendizaje por transferencia con un modelo experto en inglés?
Luc: Exactamente. No necesita volver a aprender lo que es un verbo. Simplemente aprende las palabras y las reglas del francés, transfiriendo los conceptos subyacentes. Esa es toda la potencia de este enfoque.
Camille: Por lo tanto, transfiere su enorme conocimiento general adquirido en la preentrenamiento para realizar una nueva tarea específica.
Luc: Es exactamente así. Por eso puede convertirse en un experto de sus datos con una cantidad asombrosamente pequeña de nueva información. No parte de cero; se basa en fundamentos extremadamente sólidos.
Camille: Tiene sentido. Pero como discutimos en nuestro último episodio sobre los Transformers, ¿no está surgiendo una nueva aproximación más flexible?
Luc: Sí, y es posible gracias a la expansión masiva de la memoria a corto plazo de la IA o « ventana de contexto ». Este enfoque se llama aprendizaje en contexto, o ICL (In-Context Learning).
Camille: Por lo tanto, en lugar de volver a entrenar la IA para convertirla en una especialista, simplemente se le proporciona la información necesaria para realizar la tarea correspondiente.
Luc: Has entendido perfectamente. Es como contratar un consultor brillante y, en lugar de enviarlo a seguir un programa de formación de varios años, simplemente proporcionarle los documentos de información exactos que necesita para el proyecto actual.
Camille: Ahí es donde entra el concepto de "ancaje", que consiste en relacionar las respuestas de la IA con informaciones específicas que proporcione usted.
Luc: Exacto. Pero eso nos lleva a un punto crucial que a menudo se entiende mal, que es de qué manera la IA "recuerda" esta información. Es la diferencia entre el conocimiento temporal y una competencia permanente.
Camille: La diferencia entre estudiar de memoria para un examen y dominar verdaderamente un tema es...
Luc: ¡Una analogía perfecta! El aprendizaje en contexto es el equivalente al bachotage. Los conocimientos que usted proporciona en la indicación son temporales. La IA los utiliza para esta única conversación, pero una vez finalizada la conversación, estos conocimientos desaparecen.
Camille: Ella olvida todo.
Luc: Ella olvida todo. Es decir, tiene una memoria de uso único. Si quiero que tenga conocimiento de la misma información mañana, tendré que volver a proporcionarle los documentos.
Camille: Correcto.
Luc: Ésta es la realidad del ICL (Aprendizaje en Contexto). Es increíblemente flexible pero se basa en una memoria de corto plazo. El afinamiento, por otro lado, busca crear un habilidad permanente. Cuando afina un modelo, modifica fundamentalmente su estructura interna. Los nuevos conocimientos se convierten en parte integral de su identidad.
Camille: Entonces, ¿los conocimientos derivados del afinamiento persisten en todas las conversaciones, para siempre?
Luc: Sí. Es como aprender a montar en bicicleta. La habilidad está arraigada. No necesita que le recuerden las leyes del equilibrio cada vez que sube al sillín.
Camille: Luc, eso explica una experiencia muy común con los chatbots. Podemos tener una conversación larga y detallada, pero si abrimos una nueva ventana de conversación, la IA no tiene idea de lo que se dijo antes.
Luc: ¡Exactamente! Esto es el Aprendizaje en Contexto en acción. La totalidad del historial de su discusión en esta sesión constituye el contexto.
Camille: Entiendo.
Luc: Cuando abres una nueva ventana, partes de un contexto vacío. El espacio de trabajo temporal de la IA simplemente se ha vaciado.
Camille: Pero ¿qué hay de las nuevas funcionalidades como la "Memoria" que algunas IA comienzan a integrar? Tenemos la impresión de que realmente empiezan a recordar cosas de una sesión a otra.
Luc: Es un excelente punto y es crucial comprender cómo funciona esto. La IA no está constantemente afinada por sus conversaciones. Eso sería increíblemente ineficiente.
Camille: ¿Entonces es un truco?
Luc: Estas funciones de memoria son una forma inteligente de aprendizaje contextual automatizado. Cuando comienzas una nueva conversación, el sistema busca rápidamente en tus intercambios anteriores la información que parece relevante para tu nueva solicitud. Luego, inserta automáticamente estos fragmentos en el prompt, detrás de escena.
Camille: Entonces, tenemos la impresión de que el AI recuerda los detalles de mi proyecto, pero en realidad, simplemente se le ha dado una antisèche justo antes de empezar a hablar contigo.
Luc: Precisamente. El modelo en sí no aprende y no evoluciona a partir de sus discusiones. Solo utiliza un sistema más inteligente para recordar el contexto pasado.
Camille: Entonces, la gran pregunta para cualquiera que utilice estas herramientas es: ¿Necesito un consultor temporal o un experto permanente?
Luc: Es la manera ideal de plantear el problema. Y con esta reflexión, es hora de concluir.
Camille: ¡Gracias por escucharnos y hasta la próxima para el siguiente episodio de « Tech Éclair »!
