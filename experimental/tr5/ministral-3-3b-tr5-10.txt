Camille: ¡Hola y bienvenidos a *« Tech Flash »*, el podcast donde analizamos cómo la tecnología moldea nuestro mundo. Soy Camille.
Luc: y soy Luc. Hoy vamos a **desvelar** cómo funcionan los modelos de IA que usamos en el día a día y por qué se vuelven tan inteligentes.
Camille: Es un tema fascinante. Normalmente las IA se perciben como **cajas negras**, pero su aprendizaje sigue un proceso real y tangible.
Luc: El *«preentrenamiento»* comienza.
Camille: El preentrenamiento es el primer paso en el aprendizaje de los modelos de IA, donde se establecen las bases para que, más tarde, puedan procesar datos y mejorar su rendimiento de manera progresiva.
Luc: Imaginen que enviamos una IA completamente nueva a una escuela para darle una base cultural. Esta procesa una cantidad masiva de datos de Internet para aprender los fundamentos del lenguaje, el razonamiento y el funcionamiento del mundo.
Camille: Bueno, tras el preentrenamiento, la IA es como un joven graduado de la universidad: inteligente y competente, pero sin experiencia profesional específica.
Luc: Precisamente. Y durante mucho tiempo, la siguiente etapa fue el **ajuste fino** (afinado). Es como enviar a ese modelo a seguir una especialización.
Camille: el ajuste fino... ¿es aquí donde interviene el **aprendizaje por transferencia**? Ya lo he escuchado antes.
Luc: El aprendizaje por transferencia es la clave. Imaginen esto: no les enseñarían las matemáticas básicas a un brillante físico antes de enfrentarse a la mecánica cuántica. Él transfiere sus competencias matemáticas previas. La IA hace lo mismo. Las lenguas son un excelente ejemplo.
Camille: ¿En qué consiste el aprendizaje por transferencia?
Luc: Podrás usar un **modelo experto** y exponerle una cantidad mucho menor de datos en francés, y aprenderá francés a una velocidad increíble.
Camille: Entiende los conceptos generales de gramática, sintaxis y estructura de frase.
Luc: No necesita volver a aprender los conceptos gramaticales previos.
Camille: Así, **transfiere sus amplios conocimientos generales adquiridos durante el preentrenamiento a la tarea específica**.
Luc: Por eso puede convertirse en experto en sus datos con sorprendentemente poca información nueva, **aprendiendo a partir de fundamentos ya consolidados**.
Camille: Es comprensible. Pero, como hablamos en nuestro último episodio sobre los *Transformers*, surge una nueva aproximación más flexible, ¿no es así?
Luc: **Gracias a la ampliación masiva de la memoria a corto plazo de la inteligencia artificial, conocida como ventana de contexto, esta metodología se denomina aprendizaje en contexto (ICL, In-Context Learning).**
Camille: Camille propone **entrenar de nuevo** la IA con los datos necesarios para que, sin necesidad de ser un **experto**, pueda realizar la **tarea asignada** correctamente.
Luc: Todo lo entiendo. Es como contratar a un consultor brillante y, en lugar de enviarlo a seguir un **curso intensivo**, simplemente proporcionarle los **documentos clave** que necesita para el proyecto en curso.
Camille: El concepto de **"anclaje"** consiste en vincular las respuestas de la IA con la información específica que proporcionas.
Luc: La IA almacena estas informaciones mediante una distinción fundamental: **memoria a corto plazo** y **memoria a largo plazo**.
Camille: Estudiar de forma intensiva para un examen es **bachotear**, mientras que dominar un tema implica **maîtrizarlo**.
Luc: El aprendizaje en contexto es como **bachotear**. Las **informaciones** que proporcionas en el *prompt* son efímeras; la IA las usa solo para esta interacción única, pero **desaparecen** una vez finalizada.
Camille: Ella olvida todo.
Luc: Ella olvida todo. Es una memoria de uso único. Para que conserve el conocimiento de las mismas informaciones al día siguiente, **debo volver a proporcionarle los datos**.
Camille: Vale.
Luc: Así es la realidad del aprendizaje en contexto (ICL). Es increíblemente flexible, pero se basa en una memoria a corto plazo. En cambio, el afinamiento busca crear una competencia permanente. Cuando afinas un modelo, modificas fundamentalmente su estructura interna. Las nuevas conocimientos se integran como parte esencial de su identidad.
Camille: Las **conocimientos resultantes del afinamiento** se mantienen en todas las interacciones.
Luc: aprender a montar en bicicleta.
Camille: Luc, esto explica una experiencia muy común con los *chatbots*. Podemos tener una conversación larga y detallada, pero al abrir una nueva ventana de conversación, la IA no recuerda lo que se había dicho antes.
Luc: Exactamente. ¡Es el aprendizaje en contexto en acción! **Todo el historial de la conversación en esta sesión forma parte del contexto.**
Camille: Entiendo.
Luc: Cuando abres una nueva ventana, **empezas desde un contexto vacío**. La IA no ha "olvidado" en el sentido humano; su espacio de trabajo temporal **se ha vaciado**.
Camille: Pero, ¿qué ocurre con las nuevas funcionalidades como la **memoria** que algunas IA empiezan a incluir? **Se nota que empiezan a recordar verdaderamente entre una sesión y otra.**
Luc: Es una excelente observación, y es crucial entender cómo funciona esto. La IA no se afinar **constantemente** a través de sus conversaciones; sería increíblemente ineficiente.
Camille: ¿Es una **estrategia** que permite a las IA ajustar su conocimiento entre conversaciones?
Luc: El sistema **busca rápidamente** en tus conversaciones anteriores las informaciones relevantes y las **integra automáticamente** en el prompt de forma oculta.
Camille: Bueno, **se nota que la IA parece recordar los detalles de mi proyecto**, pero en realidad, **solo se le dio un resumen justo antes de que empezara a hablar contigo**.
Luc: El modelo en sí no aprende ni se desarrolla a partir de sus interacciones. Simplemente emplea un mecanismo más sofisticado para recuperar el contexto anterior.
Camille: ¿Debo contratar un consultor temporal o un experto permanente?
Luc: El modo ideal de plantear el problema es el momento adecuado para finalizar la reflexión.
Camille: Hasta pronto para el próximo episodio de *Tech Éclair*!
