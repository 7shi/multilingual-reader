Camille: "Camille: Hola y bienvenidos a Tech Éclair, el podcast en el que desentrañamos la tecnología que moldea nuestro mundo. Soy Camille."
Luc: "Y soy Luc. Hoy vamos a desvelar cómo los modelos de inteligencia artificial que usamos diariamente aprenden y llegan a ser tan inteligentes."
Camille: "Es un tema fascinante. A menudo percibimos a estos sistemas de inteligencia artificial como cajas negras, pero su aprendizaje sigue un proceso muy real."
Luc: "Exactamente. Y este aprendizaje comienza con un proceso llamado pre-entrenamiento."
Camille: "Camille: El pre-entrenamiento."
Luc: "Imaginemos que enviamos una inteligencia artificial completamente nueva a la escuela para darle una educación general. Ella lee una cantidad enorme de datos en Internet para aprender los fundamentos del lenguaje, del razonamiento y del funcionamiento del mundo en general." or "Imagina que enviamos una IA nueva a la escuela para que adquiera una cultura general. Ella lee una cantidad masiva de datos en Internet para aprender las bases del lenguaje, del razonamiento y del funcionamiento del mundo en general." or "Imaginad que enviamos una IA a la escuela para que aprenda. Lee enormes cantidades de datos en Internet para aprender sobre lenguaje, razonamiento y cómo funciona el mundo."
Camille: "Entonces, después del pre-entrenamiento, la IA es como un recién graduado universitario: inteligente y competente, pero sin experiencia profesional específica."
Luc: "Precisamente. Y durante mucho tiempo, la siguiente etapa ha sido el ajuste fino. Es como enviar a este graduado a profundizar en una especialidad."
Camille: "El ajuste fino... ¿Es ahí donde entra en juego el "aprendizaje por transferencia"? Ya he oído ese término."
Luc: "Exactamente. El aprendizaje por transferencia es la clave. Imaginad esto: no le enseñarías matemáticas básicas a un físico brillante antes de que se dedique a la mecánica cuántica. En su lugar, aplica sus habilidades matemáticas previas. La inteligencia artificial funciona de manera similar. Las lenguas son un ejemplo perfecto."
Camille: "¿Es decir?" "¿O sea?"
Luc: "Puedes tomar un modelo experto en inglés y luego presentársele una cantidad mucho menor de texto en francés. Aprenderá el francés a una velocidad increíble."
Camille: ¿Porque ya comprende los conceptos generales de gramática, sintaxis y estructura de oraciones gracias al inglés?
Luc: "Exactamente. No necesita reaprender lo que es un verbo. Simplemente aprende las palabras y las reglas, transfiriendo los conceptos subyacentes. Esa es toda la potencia de este enfoque."
Camille: "Entonces, transfiere sus inmensos conocimientos generales procedentes del pre-entrenamiento a la nueva tarea específica."
Luc: "Eso es exactamente. Por eso puede convertirse en un experto en sus datos con sorprendentemente poca información nueva. No parte de cero; se apoya en cimientos extremadamente sólidos."
Camille: "Es lógico. Pero como hemos discutido en nuestro último episodio sobre los Transformers, un nuevo enfoque más flexible está empezando a surgir, ¿no es así?"
Luc: "Luc: Sí, y esto se hace posible gracias a la expansión masiva de la memoria a corto plazo de la IA, o «ventana de contexto». Este enfoque se llama aprendizaje en contexto, o ICL (In-Context Learning)."
Camille: Entonces, en lugar de volver a entrenar a la IA para convertirla en una especialista, simplemente le proporcionamos la información que necesita para la tarea que debe realizar.
Luc: "Tienes todo claro. Es como contratar a un consultor brillante y, en lugar de enviarlo a un programa de formación de varios años, simplemente le proporcionas los documentos de información exactos que necesita para el proyecto en curso." Or "Exacto. Es como contratar a un consultor excepcional y, en lugar de obligarlo a seguir un programa de formación largo, le das directamente los documentos precisos que necesita para el proyecto que está llevando a cabo."
Camille: "Es ahí donde entra en juego el concepto de 'anclaje' (grounding), que consiste en conectar las respuestas de la IA con la información específica que se le da."
Luc: "Exacto. Pero esto nos lleva a un punto crucial que a menudo se malentiende: la forma en que la IA "recuerda" esta información. Es la diferencia entre un conocimiento temporal y una habilidad permanente."
Camille: ¿La diferencia entre estudiar por un examen y realmente dominar un tema?
Luc: "¡Una analogía perfecta! El aprendizaje en contexto es similar a estudiar solo para un examen. La información que se le da a la IA es temporal. La utiliza solo para esta conversación, y una vez que la conversación termina, esa información desaparece."
Camille: "Se lo olvida todo."
Luc: "She forgets everything. It's a one-time use memory. So, if I want her to have that same information tomorrow, I'll need to provide the documents to her again." She forgets everything. It's a one-time use memory. So, if I want her to have that same information tomorrow, I'll need to provide the documents to her again. "Luc: She forgets everything. It's a one-time use memory. So, if I want her to have that same information tomorrow, I'll need to provide the documents to her again." "Luc: She forgets everything. It's a one-time use memory. So, if I want her to have that same information tomorrow, I'll need to provide the documents to her again." Luc: She forgets everything. It's a one-time use memory. So, if I want her to have that same information tomorrow, I'll need to provide the documents to her again. "Luc: She forgets everything. It's a one-time use memory. So, if I want her to have that same information tomorrow, I'll need to provide the documents to her again." Luc: She forgets everything. It's a one-time use memory. So, if I want her to have that same information tomorrow, I'll need to provide the documents to her again. She forgets everything. It's a one-time use memory. So, if I want her to have that same information tomorrow, I'll need to provide the documents to her again. Luc: She forgets everything. It's a one-time use memory. So, if I want her to have that same information tomorrow, I'll need to provide the documents to her again. The final translation: Luc: She forgets everything. It's a one-time use memory. So, if I want her to have that same information tomorrow, I'll need to provide the documents to her again. "Luc: She forgets everything. It's a one-time use memory. So, if I want her to have that same information tomorrow, I'll need to provide the documents to her again." The best translation is "Luc: Ella se olvida de todo. Es una memoria de un solo uso. Así que si quiero que tenga esa misma información mañana, necesitaré proporcionarle los documentos de nuevo."
Camille: "Camille: De acuerdo."
Luc: "Luc: Esa es la realidad de ICL. Es increíblemente flexible pero basado en memoria a corto plazo. El ajuste fino, por otro lado, busca crear una habilidad permanente. Cuando ajustas un modelo, modificas fundamentalmente su estructura interna. El nuevo conocimiento se convierte en parte integral de su identidad."
Camille: ¿Entonces, el conocimiento adquirido a través del ajuste fino persiste en todas las conversaciones, para siempre?
Luc: " Sí. Es como aprender a andar en bicicleta. La habilidad está anclada. No necesitas que te recuerden las leyes del equilibrio cada vez que te subas."
Camille: "Luc, esto explica una experiencia muy común con los chatbots. Podemos tener una conversación larga y detallada, pero si abrimos una nueva ventana de chat, la IA no tiene idea de lo que se dijo antes."
Luc: "Exacto! Esto es el aprendizaje en contexto en acción. La totalidad del historial de tu discusión en esta sesión constituye el contexto."
Camille: "Camille: Entiendo."
Luc: "Cuando abres una nueva ventana, comienzas con un contexto vacío. La IA no ha 'olvidado' en el sentido humano; su espacio de trabajo temporal simplemente se ha vaciado." or "Cuando abres una nueva ventana, comienzas con una hoja en blanco. La IA no ha 'olvidado' en el sentido humano de la palabra; su espacio de trabajo temporal acaba de ser borrado."
Camille: "Pero, ¿qué hay de las nuevas características como 'Memoria' que algunas inteligencias artificiales empiezan a incorporar? Da la impresión de que realmente comienzan a recordar cosas de una sesión a otra."
Luc: "Luc: Es un comentario excelente, y es crucial entender cómo funciona. La IA no se ajusta constantemente. Sería increíblemente ineficiente."
Camille: "¿Es entonces un truco?" "¿Es eso un truco?" "¿Es una especie de truco?"
Luc: "Eso es correcto. Estas funciones de memoria representan una forma ingeniosa de aprendizaje contextual automatizado. Cuando empiezas una conversación nueva, el sistema busca rápidamente en conversaciones pasadas la información pertinente para tu solicitud actual. Luego, incorpora esos fragmentos en el prompt de manera automática, todo ello entre bastidores."
Camille: "Entonces, tenemos la impresión de que la IA recuerda los detalles de mi proyecto, pero en realidad, simplemente le han proporcionado una guía de referencia justo antes de que comience a hablar con nosotros."
Luc: "Precisamente. El modelo en sí mismo no aprende ni evoluciona a partir de tus conversaciones. Simplemente utiliza un sistema más inteligente para recordar el contexto pasado."
Camille: "La pregunta entonces es: Debo optar por un consultor temporal o un experto permanente cuando uso estas herramientas?"
Luc: "Esta es la manera ideal de plantear el problema. Y reflexionando sobre esto, es hora de concluir."
Camille: "¡Gracias por escucharnos! ¡Hasta la próxima en 'Tech Éclair'!"
