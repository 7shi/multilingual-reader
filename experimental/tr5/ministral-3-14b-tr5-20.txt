Camille: ¡Hola y bienvenidos a « Tech Éclair », el podcast donde desglosamos la tecnología que está transformando nuestro mundo! Soy Camille.
Luc: descubrir cómo los modelos de IA que usamos en nuestro día a día aprenden y se vuelven tan inteligentes.
Camille: ¡Es un tema fascinante! Suelen percibirse estas IA como cajas negras, pero su aprendizaje sigue un proceso muy real.
Luc: Exactamente. Y ese aprendizaje comienza con un proceso llamado **preentrenamiento** (o *entrenamiento previo*).
Camille: preentrenamiento
Luc: Imaginen que enviamos una inteligencia artificial completamente nueva a la escuela para que adquiera cultura general. Lee una cantidad masiva de datos de Internet para aprender los fundamentos del lenguaje, el razonamiento y el funcionamiento del mundo en general.
Camille: Entonces, después del preentrenamiento, la IA es como un recién graduado universitario: inteligente y capacitado, pero sin experiencia profesional específica.
Luc: Exactamente. Y durante mucho tiempo, el siguiente paso fue el afinamiento (*fine-tuning*). Es como enviar a ese recién graduado a especializarse.
Camille: El afinamiento... ¿es ahí donde entra en juego el aprendizaje por transferencia? Ya escuché este término.
Luc: El aprendizaje por transferencia es la clave. Miren bien: no le enseñarían matemáticas básicas a un brillante físico antes de que se adentrara en la mecánica cuántica. Él transfiere las habilidades matemáticas que ya tiene. La IA hace lo mismo. Los idiomas son un excelente ejemplo.
Camille: ¿O sea?
Luc: Puedes tomar un modelo experto en inglés y presentarle una cantidad mucho menor de texto en francés. Aprenderá francés a una velocidad increíble.
Camille: ¿Porque ya comprende los conceptos generales de gramática, sintaxis y estructura de las frases gracias al inglés?
Luc: Exactamente. No necesita reaprender qué es un verbo. Simplemente aprende las palabras y las reglas del francés, transfiriendo los conceptos subyacentes. ¡Esa es toda la potencia de este enfoque!
Camille: transfiere sus vastos conocimientos generales, adquiridos durante el preentrenamiento, a la nueva tarea específica.
Luc: ¡Exactamente! Por eso puede convertirse en un experto en sus datos con una cantidad sorprendentemente pequeña de nueva información. No parte de cero: se apoya en fundamentos extremadamente sólidos.
Camille: Tiene sentido. Pero, como hablamos en nuestro último episodio sobre los Transformers, ¿una nueva aproximación más flexible está emergiendo, no?
Luc: Sí, y es posible gracias a la expansión masiva de la memoria a corto plazo de la IA, o lo que llamamos la ventana de contexto. Este enfoque se conoce como aprendizaje en contexto (o ICL, por sus siglas en inglés: *In-Context Learning*).
Camille: En lugar de volver a entrenar a la IA para convertirla en una especialista, simplemente le damos la información que necesita para realizar la tarea.
Luc: ¡Lo han entendido todo! Es como contratar a un consultor brillante y, en lugar de enviarlo a un largo programa de formación, simplemente proporcionarle los documentos exactos que necesita para el proyecto actual.
Camille: Es aquí donde entra en juego el concepto de anclaje, que consiste en vincular las respuestas de la IA a las informaciones específicas que usted proporciona.
Luc: Exactamente. Pero esto nos lleva a un **punto clave** que suele **malinterpretarse**: la forma en que la IA **"recuerda"** esas informaciones. Aquí está la diferencia entre una **memoria temporal** y una **habilidad permanente**.
Camille: La diferencia entre **aprender de memoria para un examen** y **asimilar verdaderamente un tema** ¿cuál es?
Luc: ¡Una analogía perfecta! El aprendizaje en contexto es como aprenderse algo de memoria para un examen. Los conocimientos que le proporcionas en el *prompt* son temporales: la IA los usa solo para esa conversación, pero, una vez terminada, esos conocimientos desaparecen.
Camille: Lo olvida todo.
Luc: Lo olvida todo. Es, por tanto, una memoria de uso único. Si quiero que tenga conocimiento de las mismas informaciones mañana, debo proporcionarle los documentos nuevamente.
Camille: De acuerdo.
Luc: Así es la realidad del ICL. Es sorprendentemente flexible, pero basado en una memoria a corto plazo. En cambio, el afinamiento busca crear una habilidad permanente. Cuando afinas un modelo, modificas fundamentalmente su estructura interna. Los nuevos conocimientos se convierten en parte integral de su identidad.
Camille: ¿Entonces los conocimientos obtenidos mediante el afinamiento **persisten en todas las conversaciones para siempre**?
Luc: Sí. Es como aprender a montar en bicicleta. La competencia está **anclada**. No necesitas que te lo recuerden.
Camille: *Luc, esto explica una experiencia muy común con los chatbots. Podemos mantener una conversación larga y detallada, pero si abrimos una nueva ventana de conversación, la IA no tiene ni idea de lo que se dijo antes.*
Luc: Exacto! Esto es el aprendizaje en contexto en acción. El historial completo de su conversación en esta sesión es el contexto.
Camille: Ah, ya veo.
Luc: Cuando abren una nueva ventana, parten de un contexto vacío. La IA no ha "olvidado" en el sentido humano del término; simplemente su espacio de trabajo temporal ha sido borrado.
Camille: Pero, ¿y en cuanto a nuevas funcionalidades como la "Memoria" que algunas IA empiezan a integrar? Da la impresión de que realmente empiezan a recordar cosas de una sesión a otra.
Luc: Es una observación excelente, y es crucial entender cómo funciona esto. La IA no se ajusta constantemente a partir de sus conversaciones. Sería increíblemente ineficiente.
Camille: ¿Es eso entonces un truco?
Luc: Podríamos decir eso. Estas funciones de memoria son una forma ingeniosa de aprendizaje en contexto automatizado. Cuando empiezas una nueva conversación, el sistema busca rápidamente en tus intercambios anteriores las informaciones que parecen pertinentes para tu nueva solicitud. Luego, inserta automáticamente estos fragmentos en el *prompt*, detrás de cámaras.
Camille: Así que da la impresión de que la IA recuerda los detalles de mi proyecto, pero en realidad solo le habíamos proporcionado un resumen de referencia justo antes de que empezara a hablarle.
Luc: Precisamente. El modelo en sí no aprende ni evoluciona a partir de sus conversaciones. Solo utiliza un sistema más inteligente para recordar el contexto pasado.
Camille: ¿necesito un consultor temporal o un experto permanente?
Luc: Es la manera ideal de plantear el problema. Y sobre esta reflexión, es hora de concluir.
Camille: ¡Gracias por escucharnos y hasta pronto para el próximo episodio de *Tech Éclair*!
