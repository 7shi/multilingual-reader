Camille: ¡Hola y bienvenidos a «*Tech Flash*», el podcast donde explicamos cómo la tecnología moldea nuestro mundo. Soy Camille.
Luc: desvelar cómo funcionan los modelos de IA que usamos en el día a día y por qué se vuelven tan inteligentes.
Camille: Es un tema fascinante. Normalmente las IA se perciben como **casas negras**, pero su aprendizaje sigue un proceso **real y comprensible**.
Luc: El preentrenamiento.
Camille: El preentrenamiento.
Luc: Imagina que enviamos una **IA completamente nueva** a una escuela para darle cultura general. Ella lee una cantidad masiva de datos de Internet para aprender los fundamentos del lenguaje, el razonamiento y el funcionamiento del mundo.
Camille: Tras el preentrenamiento, la IA es como un joven graduado universitario: inteligente y competente, pero sin experiencia profesional específica.
Luc: El afinado (ajuste fino) fue el siguiente paso. Es como enviar a ese graduado a especializarse.
Camille: ¿es aquí donde interviene el aprendizaje por transferencia? Lo he oído antes.
Luc: El aprendizaje por transferencia es la clave. Imagina que no les enseñarías las matemáticas básicas a un brillante físico antes de abordar la mecánica cuántica. Él transferiría sus competencias matemáticas existentes. La IA hace lo mismo. Las lenguas son un excelente ejemplo.
Camille: ¿es decir?
Luc: Usad un **modelo de lenguaje entrenado en inglés** y luego presentadle una cantidad mucho menor de texto en francés. Aprenderá francés a una velocidad increíble.
Camille: Domina los conceptos generales de gramática, sintaxis y estructura de frase gracias al inglés.
Luc: Exactamente. No necesita volver a aprender qué es un verbo. Simplemente aprende los mismos términos y reglas del español, transferiendo los conceptos subyacentes. Es toda la potencia de este enfoque.
Camille: Así, **transfiere sus amplios conocimientos generales** adquiridos durante el preentrenamiento a la nueva tarea específica.
Luc: Por eso puede convertirse en un experto en sus datos con sorprendentemente poca nueva información, **sin partir de cero y apoyándose en bases sólidas**.
Camille: Una nueva aproximación más flexible está emergiendo actualmente.
Luc: **La ampliación masiva de la memoria a corto plazo de la IA, conocida como ventana de contexto, permite realizar un aprendizaje en contexto (ICL, *In-Context Learning*).**
Camille: En lugar de **reentrenar la IA para convertirla en un especialista**, simplemente le proporcionamos la información que necesita para cumplir su tarea.
Luc: Todo está claro. Es como contratar a un consultor brillante y, en lugar de enviarlo a seguir un programa de formación de varios años, simplemente proporcionarle los documentos de información exactos que necesita para el proyecto en curso.
Camille: anclaje
Luc: La IA **almacena** estas informaciones, pero la diferencia clave está en que no hay un **conocimiento efímero**, sino una **competencia estable**.
Camille: La diferencia entre **memorizar para un examen** y **comprender un tema profundamente** es...
Luc: El aprendizaje en contexto es como el *bachotage*. Los conocimientos que proporcionas en el prompt son efímeros. La IA los usa solo para esta conversación única, pero una vez finalizada, esos conocimientos desaparecen.
Camille: Se olvida todo.
Luc: Se olvida todo. Es una **memoria efímera**. Para que tenga conocimiento de las mismas informaciones al día siguiente, **debo proporcionarle nuevamente los mismos documentos**.
Camille: Vale.
Luc: Así es la realidad del **In-Context Learning (ICL)**: es flexible, pero depende de una **memoria a corto plazo**. En cambio, el afinado busca crear una **competencia permanente**. Al afinar un modelo, modificas su **estructura interna** de manera fundamental, integrando los nuevos conocimientos como parte esencial de su **identidad**.
Camille: Los conocimientos derivados del afinado **se mantienen de forma permanente** en todas las interacciones de la IA.
Luc: Sí. Es como aprender a montar en bicicleta. La habilidad queda **establecida**. No necesitas que te recuerden las leyes del equilibrio cada vez que montes.
Camille: Luc, esto explica por qué, al interactuar con chatbots, una conversación extensa y detallada puede "desaparecer" si se reinicia la sesión: la IA **no recuerda nada de lo anterior**.
Luc: El historial de vuestra conversación en esta sesión **es el contexto** que la IA procesa en tiempo real.
Camille: Entiendo.
Luc: cuando abres una nueva ventana, **inicias desde cero**. La IA no olvida; su espacio de trabajo temporal **se reinicia**.
Camille: Pero, ¿qué pasa con las nuevas capacidades como la **memoria contextual** que algunas IA están desarrollando? Parece que, en realidad, empiezan a retener información entre conversaciones distintas.
Luc: Es una observación excelente, y es fundamental entender cómo funciona esto. La IA no se afinará constantemente durante sus interacciones. Sería increíblemente ineficiente.
Camille: ¿Es eso, entonces, una estrategia?
Luc: Sí, es así. Estas funciones de memoria son una forma ingeniosa de **aprendizaje en contexto automatizado**. Cuando empiezas una nueva conversación, el sistema **revisa rápidamente tus intercambios anteriores** buscando información relevante para tu nueva solicitud. Luego, **integra automáticamente los fragmentos correspondientes al prompt de forma oculta**.
Camille: La IA solo tiene acceso a la información que se le dio en el momento de la interacción.
Luc: El modelo no aprende ni evoluciona durante las conversaciones; solo usa un sistema más inteligente para **recuperar el contexto pasado**.
Camille: ¿Necesito un asesoramiento temporal o un experto permanente?
Luc: La forma ideal para plantear el problema es el momento adecuado para **concluir** sobre esta reflexión.
Camille: Hasta pronto para el próximo episodio de **Tech Éclair** ¡Nos vemos!
