Camille: ¡Hola y bienvenidos a « Tech Éclair », el podcast donde desglosamos la tecnología que moldea nuestro mundo! Soy Camille.
Luc: Y yo soy Luc. Hoy vamos a desvelar cómo los modelos de IA que usamos a diario aprenden y se vuelven tan inteligentes.
Camille: Es un tema fascinante. Suelen percibir estas IA como cajas negras, pero su aprendizaje sigue un proceso muy real.
Luc: preentrenamiento
Camille: El preentrenamiento.
Luc: Imaginen que enviamos una inteligencia artificial completamente nueva a la escuela para darle una formación general. Lee una cantidad masiva de datos de Internet para aprender los fundamentos del lenguaje, el razonamiento y el funcionamiento general del mundo.
Camille: Entonces, después del preentrenamiento, la IA es como un recién graduado universitario: inteligente y competente, pero sin experiencia profesional específica.
Luc: Exactamente. Y durante mucho tiempo, el paso siguiente fue el ajuste fino (*fine-tuning*). Es como enviar a ese graduado a seguir una especialización.
Camille: El afinamiento... ¿es ahí donde entra en juego el aprendizaje por transferencia? Ya he oído este término.
Luc: El aprendizaje por transferencia es la clave. Miren: no enseñarías matemáticas básicas a un brillante físico antes de que se enfrentara a la mecánica cuántica. Él transfiere sus habilidades matemáticas existentes. La IA hace lo mismo. Los idiomas son un excelente ejemplo.
Camille: O sea
Luc: Pueden tomar un modelo experto en inglés y presentarle una cantidad mucho menor de texto en francés. ¡Aprenderá francés a una velocidad increíble.
Camille: ¿Porque ya comprende los conceptos generales de gramática, sintaxis y estructura de oración gracias al inglés?
Luc: Exactamente. No necesita volver a aprender qué es un verbo. Solo aprende las palabras y las reglas del francés, transfiriendo los conceptos subyacentes. ¡Ahí está todo el poder de este enfoque!
Camille: transfiere sus vastos conocimientos generales adquiridos durante el preentrenamiento a la nueva tarea específica.
Luc: ¡Exactamente! Por eso puede convertirse en un experto en sus datos con una cantidad sorprendentemente pequeña de información nueva. No parte de cero; se apoya en fundamentos extremadamente sólidos.
Camille: Es lógico. Pero, como habíamos discutido en nuestro último episodio sobre los Transformers, ¿no está emergiendo un nuevo enfoque más flexible?
Luc: Sí, y es posible gracias a la expansión masiva de la memoria a corto plazo de la IA, o lo que llamamos la ventana de contexto. Este enfoque se conoce como aprendizaje en contexto (o ICL, por sus siglas en inglés: *In-Context Learning*).
Camille: En lugar de reentrenar a la IA para hacerla especialista, simplemente le damos la información que necesita para la tarea que debe realizar.
Luc: Lo han entendido todo. Es como contratar a un consultor brillante y, en lugar de enviarlo a un largo proceso de formación, simplemente proporcionarle los documentos de información exactos que necesita para el proyecto en curso.
Camille: Es aquí donde entra en juego el concepto de **anclaje**, que consiste en vincular las respuestas de la IA a las **informaciones específicas** que usted proporcione.
Luc: Exactamente. Pero esto nos lleva a un punto crucial que suele malinterpretarse: la forma en que la IA recuerda esas informaciones. Aquí está la diferencia entre un conocimiento temporal y una habilidad permanente.
Camille: ¿Cuál es la diferencia entre **empollarse** para un examen y **maestrizar** un tema?
Luc: Una analogía perfecta. El aprendizaje en contexto es como empollar: los conocimientos que proporcionas en el *prompt* son temporales. La IA los usa solo para esa conversación, pero una vez terminada, esos conocimientos desaparecen.
Camille: Lo olvida todo.
Luc: Lo olvida todo. Es, por tanto, una memoria de uso único. Si quiero que tenga acceso a las mismas informaciones mañana, deberé proporcionarle los documentos nuevamente.
Camille: De acuerdo.
Luc: Esta es la realidad del ICL: es sorprendentemente flexible, pero se basa en una memoria a corto plazo. En cambio, el afinamiento busca crear una habilidad permanente. Cuando afinas un modelo, modificas fundamentalmente su estructura interna. Los nuevos conocimientos se convierten en parte integral de su identidad.
Camille: Entonces, ¿los conocimientos derivados del afinamiento persisten en todas las conversaciones, de forma permanente?
Luc: Sí. Es como aprender a montar en bicicleta. La competencia está anclada. No necesitas que te recuerden.
Camille: *Luc, esto explica una experiencia muy común con los chatbots. Se puede mantener una conversación larga y detallada, pero si se abre una nueva ventana de discusión, la IA no recuerda nada de lo que se dijo anteriormente.*
Luc: ¡Exacto! Esto es el aprendizaje en contexto en acción. Todo el historial de su conversación en esta sesión constituye el contexto.
Camille: Entiendo.
Luc: Cuando abres una nueva ventana, partes de un contexto vacío. La IA no ha olvidado en el sentido humano del término, sino que su espacio de trabajo temporal ha sido reiniciado.
Camille: Pero, ¿y las nuevas funcionalidades como la « Memoria » que algunas IA empiezan a incorporar? Da la impresión de que realmente comienzan a recordar cosas de una sesión a otra.
Luc: Es una observación excelente, y es crucial entender cómo funciona. La IA no está siendo constantemente afinada. Sería increíblemente ineficiente.
Camille: ¿Es eso un truco, entonces?
Luc: Podríamos decir eso. Estas funciones de memoria son una forma ingeniosa de aprendizaje contextual automatizado. Cuando empiezas una nueva conversación, el sistema busca rápidamente en tus intercambios anteriores las informaciones que parecen relevantes para tu nueva consulta y luego inserta automáticamente estos fragmentos en el prompt, sin que te des cuenta.
Camille: *Así que da la impresión de que la IA recuerda los detalles de mi proyecto, pero en realidad solo le hemos proporcionado una especie de "trampa" (o referencia rápida) justo antes de que empezara a hablar contigo.*
Luc: Precisamente. El modelo en sí no aprende ni evoluciona a partir de sus conversaciones. Solo utiliza un sistema más inteligente para recordar el contexto pasado.
Camille: Entonces, la gran pregunta para cualquiera que utilice estas herramientas es: ¿necesito un consultor temporal o un experto permanente?
Luc: Esa es la manera ideal de plantear el problema. Y sobre esta reflexión, es momento de concluir.
Camille: ¡Gracias por escucharnos, y hasta pronto para el próximo episodio de « Tech Éclair »!
