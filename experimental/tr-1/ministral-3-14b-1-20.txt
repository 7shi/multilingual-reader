Camille: ¡Hola, bienvenidos a **Tech Éclair**, el podcast donde **desciframos** la tecnología que **moldea nuestro mundo**! Soy Camille.
Luc: Y **soy** Luc. Hoy, **vamos a destapar** cómo los modelos de IA que usamos a diario **aprenden** y se vuelven tan inteligentes.
Camille: Es un tema fascinante.
Luc: Exactamente. Y este aprendizaje comienza con un proceso llamado el **«entrenamiento previo»** o **«preentrenamiento»**.
Camille: pre-training
Luc: **Imagine que enviamos una IA recién creada a la escuela para darle cultura general.** Le hace lectura de una **abrumadora cantidad de datos de Internet** y así aprende los **fundamentos del lenguaje, del razonamiento y del funcionamiento del mundo en general**.
Camille: Por lo tanto, después del **preentrenamiento**, la IA es como un **recién graduado universitario**: inteligente y competente, pero **sin experiencia profesional específica**.
Luc: **Precisamente.** Y durante mucho tiempo, el paso siguiente fue el **«afinado»** (*fine-tuning*). Es como enviar a ese graduado a especializarse en un área concreta.
Camille: El afinado... ¿es ahí donde entra en juego el **«aprendizaje por transferencia»**? Ya he oído ese término antes.
Luc: **Exactamente.** El **aprendizaje por transferencia** es la clave. **Miren:** no enseñarías matemáticas básicas a un brillante físico antes de que se adentrara en la **mecánica cuántica**. Él **transfiere** sus competencias matemáticas existentes. La IA hace lo mismo. **Las lenguas son un excelente ejemplo de esto.**
Camille: ¿Es decir ?
Luc: **Puedes tomar un modelo experto en inglés y luego presentarle una cantidad mucho menor de texto en francés. Aprenderá francés a una velocidad increíble.**
Camille: Porque ya **comprende los conceptos generales de gramática, sintaxis y estructura de oración gracias al inglés**.
Luc: **Exactamente.** No necesita **volver a aprender** qué es un verbo. Solo aprende las palabras y las reglas del francés, **transferiendo los conceptos subyacentes.** Es **todo el poder** de este enfoque.
Camille: **Por lo tanto, transfiere sus inmensos conocimientos generales adquiridos durante el preentrenamiento a la nueva tarea específica.**
Luc: **¡Exactamente!** Por eso puede convertirse en un experto en sus datos con una cantidad **sorprendentemente escasa** de información nueva. **No parte de cero**; se apoya en **cimientos extremadamente sólidos**.
Camille: **Es lógico. Pero, como hablamos en nuestro último episodio sobre los Transformers, ¿no está surgiendo un enfoque más flexible?**
Luc: **Sí, y es posible gracias a la expansión masiva de la memoria a corto plazo de la IA, o «ventana de contexto». Este enfoque se denomina aprendizaje en contexto, o ICL (*In-Context Learning*).**
Camille: **En lugar de reentrenar a la IA para especializarla, solo le damos los datos que necesita para realizar la tarea.**
Luc: **Lo han entendido todo.** Es como contratar a un consultor brillante y, en lugar de enviarlo a un programa de formación de varios años, **solo proporcionarle los documentos de información exactos que necesita para el proyecto en curso.**
Camille: Es ahí donde entra en juego el concepto de **«anclaje» (grounding)**, que consiste en vincular las respuestas de la IA a la información específica que aportas.
Luc: **Exactamente.** Pero esto nos lleva a un punto crucial que suele malinterpretarse: **cómo la IA «recuerda»** esas informaciones. **Es la diferencia entre un conocimiento temporal y una habilidad permanente.**
Camille: La diferencia entre **repasar para un examen** y **dominar realmente un tema** ?
Luc: **¡Una analogía perfecta!** El aprendizaje en contexto es como **repasar para un examen**. Los conocimientos que proporcionas en el *prompt* son **temporales**. La IA los usa para **esta única conversación**, pero, una vez terminada la conversación, **esos conocimientos desaparecen**.
Camille: Lo olvida todo.
Luc: Lo olvida todo. **Por lo tanto, es una memoria de uso único.** Si quiero que tenga conocimiento de las mismas informaciones mañana, **debo proporcionarle los documentos nuevamente.**
Camille: **De acuerdo.**
Luc: **Toda la realidad del ICL.** Es increíblemente flexible, pero se basa en una **memoria a corto plazo**. En cambio, el *afinado* (*fine-tuning*) busca **crear una habilidad permanente**. Cuando afinas un modelo, **modificas fundamentalmente su estructura interna**. Los nuevos conocimientos se convierten en **parte integrante de su identidad**.
Camille: Entonces, ¿los conocimientos adquiridos mediante el afinado persisten en todas las conversaciones, para siempre?
Luc: Sí. Es como aprender a montar en bicicleta. **La habilidad queda arraigada.** No necesitas que te recuerden las leyes del equilibrio cada vez que te subes a la bicicleta.
Camille: Luc, esto explica una experiencia muy común con los *chatbots*. Se puede mantener una conversación larga y detallada, pero si se abre una nueva ventana de discusión, la IA **no tiene ni idea** de lo que se dijo antes.
Luc: **¡Exacto! Esto es el aprendizaje en contexto en acción. La totalidad del historial de esta conversación constituye el contexto.**
Camille: I see.
Luc: **Cuando abre una nueva ventana, parte de un contexto vacío.** La IA **no ha «olvidado»** en el sentido humano del término; **solo se ha vaciado su espacio de trabajo temporal.**
Camille: Pero, ¿qué pasa con las nuevas funciones como la **‘Memoria’** que algunas IA empiezan a integrar? Parece que **de verdad** empiezan a recordar cosas de una sesión a otra.
Luc: Es una observación excelente, y es crucial entender cómo funciona esto. **La IA no se reentrena constantemente con tus conversaciones**. Sería increíblemente ineficiente.
Camille: **¿Es eso un truco?** (o *¿Será eso un truco?*)
Luc: **Podríamos decirlo así.** Estas funciones de memoria son una **forma ingeniosa de aprendizaje en contexto automatizado**. Cuando empiezas una nueva conversación, el sistema **busca rápidamente en tus intercambios anteriores** las informaciones que parecen relevantes para tu nueva solicitud. Luego, **inserta automáticamente esos fragmentos en el *prompt*, de manera oculta**.
Camille: **Pues parece que la IA recuerda los detalles de mi proyecto, pero en realidad solo le hemos dado una chuleta justo antes de que empezara a hablarle.**
Luc: Exactamente. **El modelo en sí no aprende ni evoluciona** a partir de sus conversaciones. **Simplemente utiliza un sistema más inteligente para recordar el contexto pasado.**
Camille: **¿Necesito un consultor temporal o un experto permanente?**
Luc: **Esta es la manera ideal de plantear el problema. Y sobre esta reflexión, es hora de concluir.**
Camille: ¡Gracias por escucharnos y hasta pronto para el próximo episodio de *«Tecno Relámpago»*! (o *«Tech Destello»* / *«Tech Rayo»*)
