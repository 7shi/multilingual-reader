Camille: ¡Hola y bienvenidos a 'Tech Éclair', el podcast donde descubrimos la tecnología que da forma a nuestro mundo. Soy Camille.
Luc: ¡Y soy Luc. Hoy, vamos a desvelar cómo los modelos de inteligencia artificial (IA) que utilizamos en nuestro día a día aprenden y se vuelven tan inteligentes. Además, exploraremos las técnicas que emplean para mejorar su conocimiento constante.
Camille: ¡Es un tema fascinante. A menudo se perciben a estas IA como procesos opacos, pero su aprendizaje sigue un proceso real y tangible.
Luc: ¡Exactamente. Y este aprendizaje comienza con un proceso llamado "preentrenamiento" (o "pre-entrenamiento", en español). Este proceso es fundamental para que los modelos de inteligencia artificial puedan aprender y mejorar continuamente.
Camille: El preentrenamiento.
Luc: ¡Imaginemos que enviamos una IA completamente nueva a la escuela para darle cultura general. Ella leerá una gran cantidad de datos en Internet para aprender los fundamentos del lenguaje, el razonamiento y el funcionamiento del mundo en general.
Camille: Por lo tanto, después del preentrenamiento, la IA es como un joven que ha completado su educación formal: inteligente y competente, pero sin experiencia profesional específica.
Luc: Precisamente. Durante mucho tiempo, el siguiente paso ha sido "el ajuste" (fine-tuning). Es como enviar a este graduado a especializarse.
Camille: ¡El afinar... es ahí donde entra en juego 'el aprendizaje por transferencia'. Ya he escuchado este término.
Luc: ¡Exactamente! El aprendizaje por transferencia es la clave. Veamos: no enseñaría matemáticas básicas a un brillante físico antes de que se enfrentar a la mecánica cuántica. Transfiere sus habilidades matemáticas existentes. La IA hace lo mismo. Las lenguas son un excelente ejemplo. Por cierto, el verbo 'leerá' en español debe ser presente imperativo para mantener el contexto original: ¡Ella leerá una gran cantidad de datos en Internet!
Camille: ¿Qué significa?
Luc: ¿Puede tomar un modelo experto en inglés y luego presentarle una cantidad mucho menor de texto en francés? Aprenderá el idioma francés a una velocidad increíble.
Camille: ¿Porque ya entiende los conceptos generales de gramática, sintaxis y estructura de oración gracias al inglés?
Luc: ¡Exactamente! No tiene necesidad de volver a aprender qué es un verbo. Simplemente aprende las palabras y las reglas del idioma francés, aplicando los conceptos que ya conoce a la nueva situación. Esta es toda la potencia de este enfoque.
Camille: Entonces, utiliza sus inmensos conocimientos generales adquiridos durante el entrenamiento previo para adaptarlos a la nueva tarea específica.
Luc: Eso es exactamente eso. Por eso puede convertirse en un experto de sus datos con sorprendentemente poca información nueva. No empieza desde cero; se basa en unas fundaciones extremadamente sólidas.
Camille: Eso es lógico. Sin embargo, como discutimos en nuestro último episodio sobre los Transformers, está surgiendo un nuevo enfoque más flexible.
Luc: Sí, y esto se logra gracias a la expansión masiva de la memoria a corto plazo de la IA, o "ventana de contexto". Este enfoque se llama aprendizaje en contexto, o ICL (Aprendizaje en Contexto). La "ventana de contexto" es una habilidad fundamental que permite al modelo de IA comprender y procesar información de manera más eficiente, lo que a su vez mejora su capacidad para aprender y adaptarse a nuevas tareas.
Camille: Por lo tanto, en lugar de volver a entrenar la IA para que se convierta en una experta, simplemente le proporcionamos las información necesarias para realizar la tarea asignada.
Luc: ¡Entiende todo perfectamente! Es como contratar a un consultor brillante y, en lugar de enviarlo a un programa de formación de varios años, simplemente proporcionarle los documentos de información exacta que necesita para el proyecto actual. Esto no solo ahorra tiempo y recursos, sino que también permite al consultor aplicar sus conocimientos y habilidades de manera más efectiva y rápida.
Camille: Es aquí donde entra en juego el concepto de « anclaje » (grounding), que consiste en vincular las respuestas de la IA con la información específica que se proporciona. Este método permite a la IA adaptarse más fácilmente a nuevas tareas y contextos, mejorando así su capacidad para aprender y procesar información de manera más eficiente.
Luc: Exactamente. Pero esto nos lleva a un punto crucial que a menudo se malinterpreta: la manera en que la IA 'se recuerda' esta información. Esta es la diferencia entre un conocimiento temporal y una competencia permanente.
Camille: ¿Cuál es la diferencia entre estudiar para un examen y realmente dominar un tema? Estudiar para un examen implica memorizar información específica para responder correctamente a preguntas o problemas en un momento determinado, mientras que dominar un tema implica una comprensión profunda y duradera de los conceptos subyacentes, habilidades prácticas y la capacidad de aplicar ese conocimiento en diferentes situaciones. Dominar un tema requiere no solo recordar hechos y teorías, sino también comprender su contexto, implicaciones y conexiones con otros campos del conocimiento.
Luc: ¡Una analogía perfecta! El aprendizaje en contexto es como estudiar para un examen. Los conocimientos que se proporcionan en el prompt son temporales y la IA los utiliza solo para esta conversación única; una vez finalizada, estos conocimientos desaparecen. Esto contrasta con el dominio permanente del tema, donde el conocimiento proporcionado no se limita a una conversación aislada, sino que se vuelve parte integral de la capacidad de la IA para adaptarse a nuevas tareas y contextos.
Camille: Ella olvida todo.
Luc: Olvidan todo. Por lo tanto, es una memoria de uso único. Si quiero que tenga conocimiento de las mismas informaciones mañana, debo proporcionarle nuevamente los documentos.
Camille: ¡De acuerdo.
Luc: Esta es la realidad del aprendizaje en contexto (ICL). Es extremadamente adaptable, pero se basa en una memoria a corto plazo. El afilamiento, por el contrario, tiene como objetivo crear una competencia permanente. Cuando afinan un modelo, modifican fundamental su estructura interna. Las nuevas conocimientos se convierten en parte integral de su identidad.
Camille: ¿Por lo tanto, los conocimientos derivados del afilamiento persisten en todas las conversaciones futuras?
Luc: Sí. Es como aprender a montar en bicicleta. La competencia está anclada. No necesitas que te recuerden las leyes de equilibrio cada vez que montas en la silla. Esto se logra a través de la práctica constante, no solo con la memoria.
Camille: Luc, eso explica una experiencia muy común con los chatbots. Puedes tener una conversación larga y detallada, pero si abres una nueva ventana de conversación, la IA no tiene idea de lo que se ha dicho anteriormente.
Luc: ¡Exactamente! El aprendizaje en contexto en práctica. Todo el historial de su discusión en esta sesión constituye el contexto.
Camille: Entiendo.
Luc: Cuando abres una nueva ventana, partimos de un contexto vacío. La IA no ha "olvidado" en el sentido humano; simplemente ha limpiado su espacio de trabajo temporal para comenzar de nuevo.
Camille: Pero ¿qué pasa con las nuevas funciones como la "Memoria" que algunas IA están empezando a integrar? Nos parece que realmente **empiezan a recordar información** de una sesión a otra.
Luc: Es una excelente observación y es crucial entender cómo funciona. La IA no se refina constantemente con tus conversaciones. Sería increíblemente ineficiente.
Camille: ¡Entonces, ¿es un truco?
Luc: Se puede afirmar que estas funciones de memorización son una forma astuta de aprendizaje en contexto automatizado. Cuando inicias una nueva conversación, el sistema busca rápidamente en tus antiguos intercambios las informaciones que parecen pertinentes para tu nueva consulta. Luego, procesa automáticamente estos extractos en segundo plano, insertándolos en el prompt, de manera que puedas continuar la interacción sin perder el hilo de la conversación previa.
Camille: Por lo tanto, damos por sentado que la IA recuerda los detalles de mi proyecto, pero en realidad se le ha proporcionado una información básica justo antes de que comience a hablar con usted.
Luc: ¡Exacto! El modelo en sí no aprende ni evoluciona a partir de sus conversaciones. Simplemente utiliza un sistema más inteligente para recordar el contexto pasado.
Camille: ¡Por lo tanto, la gran pregunta para quien utilice estas herramientas es: ¿necesito un consultor temporal o un experto permanente? Esta cuestión es crucial para entender cómo utilizar al máximo estos recursos. Si bien los modelos de IA pueden procesar rápidamente grandes cantidades de información, su eficacia depende en gran medida del tipo de experiencia que necesites y la profundidad de conocimiento requerida.
Luc: Es la mejor manera de plantear el problema. Reflexionando sobre esto, es momento de concluir.
Camille: ¡Gracias por escucharnos! Nos vemos en el próximo episodio de «Tech Éclair», equipo de Tech Éclair.
