Camille: Hola y bienvenidos/as a 'Tech Éclair', el podcast donde desglosamos la tecnología que modela nuestro mundo. Soy Camille.
Luc: Y soy Luc. Hoy, vamos a desvelar cómo los modelos de IA que utilizamos cotidianamente llegan a ser tan inteligentes.
Camille: Es un tema fascinante. A menudo percibimos estas Inteligencias Artificiales como cajas negras, pero su aprendizaje sigue un proceso bien real.
Luc: Exactamente. Y este aprendizaje comienza con un proceso llamado Pre-entrenamiento,
Camille: El pre-entrenamiento es el proceso inicial de aprendizaje de las IA. Comienza antes de que la IA comience a realizar tareas específicas y permite que el modelo adquiera conocimientos generales que pueden ser útiles para una variedad de tareas.
Luc: Imaginen que enviamos una IA totalmente nueva a la escuela para darle una cultura general. Ella lee una cantidad masiva de datos en Internet para aprender sobre el lenguaje, el razonamiento y el funcionamiento del mundo en general.
Camille: Entonces, después del pre-entrenamiento, la IA es como un recién graduado: inteligente y competente, pero sin experiencia profesional específica.
Luc: Justamente. Y durante mucho tiempo, el paso siguiente ha sido el 'afinado' o 'ajustado con precisión'. Es como enviar a un/una graduado/a a seguir una especialización.
Camille: Es aquí donde entra en juego el aprendizaje por transferencia. Ya había oído hablar de ese término.
Luc: Exactamente. El aprendizaje por transferencia es la clave. Veamos: no enseñarías matemáticas básicas a un físico brillante antes de que se enfrente a la mecánica cuántica. Él transfiere sus habilidades matemáticas existentes. La IA hace lo mismo. Los idiomas son un buen ejemplo.
Camille: ¿A qué te refieres con eso?
Luc: Puedes tomar un modelo experto en inglés, luego presentarle una cantidad mucho menor de texto en francés. Aprenderá el francés a gran velocidad.
Camille: ¿Es porque ya ha comprendido los conceptos generales de gramática, sintaxis y estructura de frase por medio del inglés?
Luc: Exactamente. No necesita volver a aprender qué es un verbo. Solo aprende las palabras y las reglas en francés, aplicando los conceptos básicos o utilizando las nociones previas. Esa es toda la potencia de este enfoque.
Camille: Entonces, aplica sus vastos conocimientos generales adquiridos durante el pre-entrenamiento a la nueva tarea específica.
Luc: Eso es así. Por eso puede convertirse en un experto en sus datos con sorprendentemente poca información nueva, ya que se apoya en unas sólidas bases previas.
Camille: Es lógico. Pero, como hablamos en nuestro último episodio sobre Transformers, está surgiendo un nuevo enfoque más flexible y dinámico, ¿verdad?
Luc: Sí, y esto se hace posible por la expansión masiva de la memoria a corto plazo de la IA, o 'ventana de contexto', que es un elemento clave del aprendizaje en contexto (ICL, In-Context Learning). La 'ventana de contexto' permite al sistema mantener un registro de las últimas entradas y utilizarlas para comprender y procesar la información actual.
Camille: En su lugar, simplemente le proporcionamos la información que necesita para hacer la tarea.
Luc: Tienes todo claro. Es como contratar a un consultor brillante y, en vez de enviarlo a seguir un programa de formación durante varios años, proporcionarle simplemente la información exacta que necesita para el proyecto actual.
Camille: El término 'ancrage' podría traducirse como 'ancrado' o explicarse de otro modo en español. La idea es vincular las respuestas de la IA a informaciones específicas que usted proporciona, lo que hace que las respuestas sean más relevantes y precisas.
Luc: Exactamente. Pero esto nos lleva a un punto crucial que a menudo se malinterpreta: la forma en que la IA 'adquiere una habilidad permanente' con estas informaciones, en lugar de un simple conocimiento temporal.
Camille: ¿Cuál es la diferencia entre estudiar deprisa y por compromiso un tema para un examen y dominar realmente el conocimiento sobre ese tema? La expresión equivalente en español a 'bachoter pour un examen' sería 'aprender de carrerilla o 'estudiar a última hora'. El objetivo es reflexionar sobre la diferencia entre adquirir conocimientos superficiales y lograr una verdadera comprensión y dominio del tema.
Luc: Un ejemplo perfecto. El aprendizaje en contexto es similar a estudiar deprisa y por compromiso. Los conocimientos que proporciona en el prompt son temporales. El IA los utiliza para esta única conversación, pero una vez terminada la conversación, esos conocimientos desaparecen.
Camille: Se le olvida todo.
Luc: Ella olvida todo. Por lo tanto, es una memoria efímera. Si quiero que tenga conocimiento de las mismas informaciones mañana, debo proporcionarle nuevamente los documentos.
Camille: Estoy de acuerdo, entendido.
Luc: Así es la realidad del aprendizaje en contexto (ICL). Es increíblemente flexible, pero basado en una memoria a corto plazo. El ajuste fino, por otro lado, tiene como objetivo crear una habilidad permanente. Cuando ajustas un modelo, modificas fundamentalmente su estructura interna. Las nuevas connaissances se vuelven parte integral de su identidad (parte de sí mismo) o forman parte de su esencia.
Camille: Entonces, ¿los conocimientos adquiridos a través del afinamiento persisten en todas las conversaciones, para siempre?
Luc: Sí. Es como aprender a hacer andar en bicicleta. La habilidad queda adquirida. No necesitas que te recuerden las leyes del equilibrio cada vez que te subes a la bici.
Camille: Luc, esto explica una experiencia muy común con los chatbots. Uno puede tener una conversación larga y detallada, pero si se abre una nueva ventana de chat, la IA no tiene ni idea de lo que se haya dicho anteriormente.
Luc: Exactamente lo mismo, ¡está en acción el aprendizaje en contexto! La totalidad de la historia de su discusión durante esta sesión constituye el contexto en acción.
Camille: Ve usted.
Luc: Cuando abres una nueva ventana, empiezas con un espacio de trabajo vacío. La IA no ha olvidado en el sentido humano del término; simplemente ha borrado su contenido temporal.
Camille: Pero ¿qué pasa con las nuevas funciones como la 'Memoria' que algunas IA están integrando? Da la impresión de que realmente comienzan a recordar cosas de una sesión a otra.
Luc: Esa es una observación excelente, y es fundamental entender cómo funciona. La IA no se ajusta de forma continua por medio de tus conversaciones. Eso sería continuamente ineficaz.
Camille: Entonces, ¿es una estrategia?
Luc: Puede decirse eso. Estas funciones de memorización son una forma ingeniosa de aprendizaje en contexto automatizado. Cuando comienza una nueva conversación, el sistema busca rápidamente en sus intercambios anteriores la información que parece relevante para su nueva solicitud. Luego, inserta automáticamente estos extractos en la solicitud, tras bambalinas.
Camille: Entonces, da la impresión de que la IA conoce los detalles de mi proyecto, pero en realidad, solo le hemos proporcionado algunas notas rápidas justo inmediatamente antes de que comience a hablar con usted.
Luc: Específicamente. El modelo en sí no aprende ni evoluciona a partir de sus conversaciones. Solo utiliza un sistema más inteligente para recordar el contexto pasado.
Camille: Entonces, la gran pregunta para quien use estas herramientas es: «¿Necesito un consultor temporal o un experto permanente?»
Luc: Esa es la forma ideal de plantear el problema, ¿no? ¡Y sobre esta reflexión, es hora de concluir!
Camille: Gracias por habernos escuchado, hasta la próxima en Tech Éclair.
