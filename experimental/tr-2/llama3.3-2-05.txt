Camille: Hola y bienvenidos a «Tecnología Iluminada», el podcast donde analizamos la tecnología que da forma a nuestro mundo. Soy Camille.
Luc: Y soy Luc. Hoy vamos a levantar el velo sobre cómo los modelos de IA que utilizamos a diario aprenden y se vuelven tan inteligentes.
Camille: Es un tema fascinante. A menudo nos parece que estas IA son un misterio, pero en realidad su aprendizaje sigue un proceso muy concreto.
Luc: En efecto. Y este aprendizaje comienza con un proceso de entrenamiento previo.
Camille: El pre-entrenamiento
Luc: Imagina que enviamos a una IA completamente nueva a la escuela para darle una cultura general. Ella lee una cantidad enorme de datos en Internet para aprender sobre los conceptos básicos del lenguaje, el razonamiento y el funcionamiento del mundo en general.
Camille: Por lo tanto, después del pre-entrenamiento, la IA se asemeja a un recién graduado universitario: es inteligente y competente, pero carece de experiencia laboral específica en su campo.
Luc: Precisamente. Y durante mucho tiempo, la etapa siguiente ha sido el ajuste fino. Es como enviar a este recién graduado universitario a seguir una especialización.
Camille: El afinamiento... ahí es donde entra en juego el aprendizaje por transferencia. Ya he oído ese término.
Luc: Exactamente. El aprendizaje por transferencia es la clave. Veamos: no necesitarías enseñarle las matemáticas básicas a un brillante físico antes de que se ocupe de la mecánica cuántica, ya que él puede transferir sus habilidades matemáticas existentes. De igual manera, la IA hace lo mismo. Los idiomas son un ejemplo excelente de esto.
Camille: ¿Qué quieres decir?
Luc: Puedes tomar un modelo experto en inglés y luego presentarle una cantidad bien menor de texto en francés. Aprenderá el francés a una velocidad increíblemente rápida.
Camille: Porque ya comprende los conceptos generales de gramática, sintaxis y estructura oracional debido a su conocimiento del inglés
Luc: Exactamente. No necesita reaprender lo que es un verbo. Simplemente aprende las palabras y las reglas del francés, transfiriendo los conceptos subyacentes. Esta es toda la potencia de este enfoque.
Camille: Entonces, transfiere sus amplios conocimientos generales procedentes de su preentrenamiento a la nueva tarea específica.
Luc: Es completamente así. Es por eso que puede convertirse en un experto en sus datos con una cantidad sorprendentemente pequeña de información nueva. No parte de cero; se basa en fundamentos extremadamente sólidos.
Camille: Tiene lógica. Pero como lo discutimos en nuestro último episodio sobre los Transformers, un nuevo enfoque más flexible está emergiendo, ¿verdad? Alternatively, a more natural translation could be: 'Es lógico. Como mencionamos en nuestro último episodio sobre los Transformers, ahora surge un enfoque más flexible.'
Luc: Sí, y es posible gracias a la expansión masiva de la memoria a corto plazo de la IA, lo que permite un contexto más amplio. Este enfoque se llama Aprendizaje en Contexto o ICL (por sus siglas en inglés, In-Context Learning).
Camille: Entonces, en lugar de volver a entrenar a la IA para hacer de ella una especialista, simplemente se le proporciona la información necesaria para la tarea que debe realizar.
Luc: Entonces, ya lo entiende todo. Es como cuando contratas a un consultor excepcional y, en lugar de hacerlo pasar por un programa de capacitación de varios años, le das directamente los documentos con la información precisa que necesita para el proyecto actual.
Camille: Es ahí donde interviene el concepto de anclaje, que consiste en vincular las respuestas de la IA a la información específica que proporcionas.
Luc: Exactamente. Pero esto nos lleva a un punto crucial que es frecuentemente mal interpretado: la manera en que la IA recuerda esta información. Es la diferencia entre un conocimiento temporal y una habilidad permanente.
Camille: La diferencia entre empollar para un examen y tener un dominio profundo de un tema
Luc: ¡Una analogía perfecta! El aprendizaje en contexto se asemeja al empollado. Los conocimientos que proporcionas en el prompt son temporales, así que la IA los utiliza solo para esa conversación en particular, y una vez terminada, estos conocimientos desaparecen.
Camille: Se olvida de todo.
Luc: Se olvida de todo. Por lo tanto, tiene una memoria de uso único. Si quiero que tenga conocimiento de la misma información al día siguiente, tendré que proporcionarle los documentos nuevamente.
Camille: De acuerdo
Luc: Así es la realidad de la Inteligencia Conversacional Limitada (ICL). Es extraordinariamente adaptable, pero se basa en una memoria a corto plazo. El afinamiento, por otro lado, tiene como objetivo crear una habilidad permanente. Cuando se afina un modelo, se modifica fundamentalmente su estructura interna, y los nuevos conocimientos se integran profundamente en su identidad, convirtiéndose en parte inseparable de ella.
Camille: Entonces, los conocimientos obtenidos del afinamiento permanecen en todas las conversaciones de manera permanente.
Luc: Sí. Es como aprender a montar en bicicleta. La habilidad está anclada. No necesitas que te recuerden las leyes del equilibrio cada vez que te montas.
Camille: Luc, esto explica una experiencia muy frecuente con los chatbots. Se puede tener una conversación larga y detallada, pero si se abre una nueva ventana de discusión, la IA no recuerda nada de lo que se discutió previamente.
Luc: Exactamente. Está funcionando el aprendizaje en contexto. La totalidad del historial de la discusión en esta sesión forma el contexto.
Camille: Entiendo
Luc: Cuando abres una nueva ventana, se inicia con un contexto vacío. La IA no ha perdido la información en el sentido que los humanos entienden por olvido; simplemente, su espacio de trabajo temporal ha sido reiniciado.
Camille: Pero, ¿qué pasa con las nuevas características como la memoria que algunas IA comienzan a integrar? Parece que verdaderamente recuerdan cosas de una sesión a otra.
Luc: Es un excelente comentario y es crucial entender cómo funciona. La IA no se mejora constantemente a través de tus conversaciones. Sería extraordinariamente ineficaz.
Camille: ¿Es entonces una treta?
Luc: Se puede decir eso. Estas funciones de memorización son una forma ingeniosa de aprendizaje automatizado en contexto. Cuando comienzas una nueva conversación, el sistema busca rápidamente en tus antiguos intercambios la información que parece relevante para tu nueva solicitud. Luego, inserta automáticamente estos extractos en el prompt de forma automatizada.
Camille: Entonces, se tiene la impresión de que la IA recuerda los detalles de mi proyecto, pero en realidad, solo se le ha proporcionado una guía de referencia justo antes de que comience a hablar.
Luc: Precisamente. El propio modelo no aprende y no evoluciona a partir de vuestras discusiones. Simplemente utiliza un sistema más inteligente para recordar el contexto pasado.
Camille: Entonces, la gran pregunta para cualquiera que utilice estas herramientas es: «¿Necesito un asesor temporal o un experto a tiempo completo?»
Luc: La forma ideal de abordar el problema es. Y en base a esta reflexión, concluimos.
Camille: Gracias por habernos escuchado, y hasta pronto para el próximo episodio de «Iluminaciones tecnológicas»
