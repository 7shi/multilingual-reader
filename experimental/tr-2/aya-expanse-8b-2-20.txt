Camille: Buenos días y bienvenidos a 'Tech Éclair', el podcast donde desentrañamos la tecnología que moldea nuestro mundo. Soy Camille.
Luc: Y yo soy Luc. Hoy vamos a desvelar cómo los modelos de IA que utilizamos en la vida cotidiana aprenden y llegan a ser tan inteligentes.
Camille: Es un tema fascinante. A menudo consideramos a estos modelos de IA como cajas negras, pero su proceso de aprendizaje sigue un procedimiento muy real. En lugar de 'cajas negras', podríamos decir que sus algoritmos o mecanismos aprenden a través de...
Luc: Exactamente. Y este proceso de aprendizaje comienza con lo que se conoce como el 'preentrenamiento'.
Camille: El preentrenamiento.
Luc: Imaginen que envían a una inteligencia artificial completamente nueva a la escuela para darle cultura general. Lee una cantidad masiva de datos en Internet para aprender los fundamentos del lenguaje, el razonamiento y el funcionamiento del mundo en general.
Camille: Así que, después del preentrenamiento, la IA se encuentra en la misma posición que un joven graduado de la universidad: inteligente y competente, pero sin experiencia laboral específica.
Luc: Precisamente. Y durante largo tiempo, la siguiente fase se ha denominando 'ajuste fino' (fine-tuning). Esto equivale a enviar a este graduado universitario a realizar una especialización para adquirir experiencia práctica en un campo específico.
Camille: L'ajuste fino... es ahí donde entra en juego la técnica de aprendizaje por transferencia, un método que ya he oído mencionar. Este proceso es similar a enviar a un graduado universitario a realizar una especialización para adquirir experiencia práctica en un campo específico.
Luc: Exactamente. El aprendizaje por transferencia es la clave. Piensen en que no se enseñarían matemáticas básicas a un físico brillante antes de que abordara la mecánica cuántica. Él transfiere sus habilidades matemáticas existentes. La IA hace lo mismo con los idiomas como un claro ejemplo.
Camille: ¿En otras palabras?
Luc: Puedes tomar un modelo experto en inglés y luego enseñarle una cantidad mucho menor de texto en francés. El modelo aprenderá francés a una velocidad asombrosa.
Camille: ¿Porque ya comprende los conceptos generales de gramática, sintaxis y estructura de oración gracias al inglés?
Luc: Exactamente. No tiene que volver a aprender lo que es un verbo. Simplemente aprende las palabras y las reglas del francés, transfiriendo los conceptos subyacentes. Esta es toda la potencia de este enfoque.
Camille: Por lo tanto, transfiere sus inmensas conocimientos generales obtenidos durante el preentrenamiento a la nueva tarea específica.
Luc: Es exactamente así. Por ello, un modelo de IA puede convertirse en un experto en sus datos con sorprendentemente pocas informaciones nuevas. No parte de cero; se basa en cimientos extremadamente sólidos.
Camille: ¿Es lógico? Pero como discutimos en nuestro último episodio sobre los Transformers, un nuevo enfoque más flexible está emergiendo, ¿no?
Luc: Sí, y esto es posible gracias a la expansión masiva de la memoria a corto plazo de la IA, o 'ventana de contexto'. Este enfoque se conoce como aprendizaje en contexto, o ICL (Aprendizaje en Contexto).
Camille: Por lo tanto, en lugar de volver a entrenar a la IA para convertirla en una especialista, simplemente se le proporciona la información necesaria para la tarea que debe realizar.
Luc: Ha captado la idea a la perfección. Es similar a contratar a un consultor altamente calificado y, en vez de inscribirlo en una formación extensa, proporcionarle directamente los datos específicos que requiere para el proyecto en cuestión.
Camille: Aquí es donde interviene el concepto de 'ancraje', que consiste en relacionar las respuestas de la IA con la información específica que proporcionas.
Luc: Exactamente. Sin embargo, esto nos lleva a un punto crucial que a menudo no se comprende bien: la manera en que la IA 'recuerda' esta información. Esta distinción es fundamental entre un conocimiento temporal y una habilidad permanente.
Camille: ¿La diferencia entre copiar para un examen y comprender verdaderamente un tema?
Luc: Una perfecta analogía ! El aprendizaje en contexto funciona como hacer trampa en un examen. Los conocimientos que incluyes en la solicitud son temporales; la IA los utiliza para esta conversación específica y luego los olvida.
Camille: Ella olvida todo.
Luc: Ella olvida todo. Por lo tanto, su memoria es de uso único. Si deseo que recuerde las mismas informaciones al día siguiente, debo proporcionarle nuevamente los documentos.
Camille: De acuerdo.
Luc: Esta es la realidad del ICL. Es increíblemente flexible, pero se basa en una memoria a corto plazo. Por el contrario, el afinamiento tiene como objetivo crear una competencia permanente. Al afinar un modelo, se modifica profundamente su estructura interna. Los nuevos conocimientos se integran de manera duradera en su identidad.
Camille: Por lo tanto, ¿los conocimientos adquiridos durante el afinamiento persisten en todas las interacciones para siempre?
Luc: Así es. Es como aprender a andar en bicicleta: la habilidad está firmemente arraigada. No tienes que recordarte las leyes del equilibrio cada vez que te subes.
Camille: Luc, esto explica una experiencia muy común con los chatbots. Podemos tener una conversación larga y detallada, pero si iniciamos una nueva charla, la IA no recuerda lo que se discutió anteriormente.
Luc: ¡Exactamente! Este es el aprendizaje en contexto en acción. Todo el historial de su discusión en esta sesión constituye el contexto.
Camille: Entiendo.
Luc: Cuando abres una nueva ventana, comienzas desde un contexto en blanco. La IA no 'ha olvidado' en el sentido humano; simplemente se ha vaciado su espacio de trabajo temporal.
Camille: Pero, ¿qué pasa con las nuevas funciones como el 'almacenamiento de conocimiento a largo plazo' que algunas IA comienzan a integrar? Da la impresión de que empiezan a recordar información de una interacción a otra.
Luc: Es una excelente observación, y comprender cómo funciona es fundamental. La IA no se perfecciona constantemente a través de nuestras conversaciones; hacerlo sería ineficiente en grado extremo.
Camille: ¿Es, pues, una astucia?
Luc: Se puede afirmar que estas funciones de memorización son una forma astuta de aprendizaje en contexto automatizado. Cuando inicias una nueva conversación, el sistema busca rápidamente en tus intercambios anteriores la información relevante para tu nueva solicitud y luego inserta automáticamente estos extractos en la solicitud, detrás de escena.
Camille: Por lo tanto, se crea la impresión de que la IA recuerda los detalles de mi proyecto, pero, en realidad, solo le proporcionamos un esquema justo antes de que inicie la conversación.
Luc: Exactamente. El modelo en sí mismo no aprende ni evoluciona a partir de vuestras conversaciones. Utiliza un sistema inteligente para recordar el contexto anterior.
Camille: Por tanto, la principal pregunta para quien emplea estas herramientas es: ¿Necesito un consultor temporal o un experto permanente?
Luc: Esta es la forma más adecuada de abordar el problema. Y tras esta reflexión, terminamos aquí.
Camille: ¡Gracias por escucharnos! Hasta pronto para el próximo episodio de 'Tech Luz'.
