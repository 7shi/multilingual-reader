Camille: Hola y bienvenido a « Tech Éclair », el podcast en el que analizamos la tecnología que da forma a nuestro mundo. Soy Camille.
Luc: Y yo soy Luc. Hoy, vamos a revelar la forma en que los modelos de IA que usamos a diario aprenden y se vuelven tan inteligentes.
Camille: Es un tema fascinante, y a menudo percibimos estas IA como cajas negras, pero su aprendizaje sigue un proceso real.
Luc: Exactamente. Y este aprendizaje comienza a través del « pre-entrenamiento».
Camille: El pre-entrenamiento.
Luc: Imaginen que le damos una educación básica a una nueva IA, o le damos una base de conocimiento. Ella lee una enorme cantidad de datos en Internet para aprender los fundamentos del lenguaje, del razonamiento y del funcionamiento del mundo en general.
Camille: Entonces, después del pre-entrenamiento, la IA es como un joven profesional: inteligente y competente, pero sin experiencia profesional específica.
Luc: Exactamente. Y durante mucho tiempo, la siguiente etapa ha sido el «afinado» (fine-tuning). Es como enviar a este graduado para que se especialice.”} </a>
Camille: El afinado... ¿cuando entra en juego el «aprendizaje por transferencia»? Ya he escuchado este término.
Luc: Exactamente. El aprendizaje por transferencia es la clave. Más bien: no enseñaría las matemáticas básicas a un físico brillante antes de que se ataque a la mecánica cuántica. Transfiere sus habilidades matemáticas existentes. La IA hace lo mismo. Los idiomas son un excelente ejemplo.
Camille: ¿Qué quieres decir?
Luc: Puedes tomar un modelo experto en inglés y luego enseñarle una cantidad mucho menor de texto en francés. Aprenderá francés a una velocidad increíble.
Camille: Dado que ya comprende...
Luc: Exactamente. No necesita volver a aprender lo que es un verbo. Simplemente aprende las palabras y las reglas del francés, transfiriendo las ideas fundamentales. Esta es toda la potencia de este enfoque.
Camille: Entonces, utiliza su conocimiento previo para abordar la nueva tarea específica.
Luc: Es totalmente eso. Por eso puede convertirse en un experto de sus datos con sorprendentemente poca información nueva. No parte de cero; se basa en fundamentos extremadamente sólidos.
Camille: Es lógico. Pero como comentamos en el último episodio sobre los Transformers...
Luc: Sí, y eso es posible gracias a la expansión masiva de la memoria a corto plazo de la IA, o 'ventana de contexto'. Este enfoque se denomina aprendizaje en contexto, o ICL (Aprendizaje en Contexto).
Camille: Entonces, en lugar de volver a entrenar a la IA para que sea una especialista, simplemente le proporcionamos la información que necesita para realizar la tarea.
Luc: Sí, lo ha entendido todo. Es como contratar a un consultor brillante y, en lugar de mandarle a estudiar un programa de formación de varios años, simplemente le proporcionamos la información exacta que necesita para el proyecto actual.
Camille: Aquí es donde interviene el concepto de "anclaje" (grounding), que consiste en vincular las respuestas de la IA a la información específica que usted proporciona.
Luc: Exactamente. Pero esto nos lleva a un punto crucial que a menudo se malinterpreta: la manera en que la IA recuerda esta información. Es la diferencia entre un conocimiento temporal y una habilidad permanente.
Camille: ¿La diferencia entre estudiar para un examen y adquirir un conocimiento profundo de un tema?
Luc: ¡Es una analogía perfecta! El aprendizaje en contexto es como estudiar a toda prisa. Los conocimientos que proporcionas en el prompt son temporales. La IA los utiliza para esta única conversación, pero una vez que la conversación termina, estos conocimientos desaparecen.
Camille: Olvidó todo.
Luc: Ella tiene una memoria temporal. Por lo tanto, si quiero que tenga conocimiento de la misma información mañana, debo proporcionarle nuevamente los documentos.
Camille: Entendido. Entonces.
Luc: Así es la realidad del ICL. Busca crear una habilidad permanente. Cuando se afina un modelo, modifica fundamentalmente su estructura interna. Las nuevas conoscenze se convierten en parte integral de su identidad.
Camille: ¿Esto significa que las capacidades aprendidas durante el afinamiento permanecerán para siempre?
Luc: Sí. Es como aprender a andar en bicicleta. La habilidad queda anclada. No necesitas que te recuerden las leyes del equilibrio a cada vez que te subes a ella.
Camille: Luc, esto explica una experiencia muy común con los chatbots. Por lo tanto, si se abre una nueva ventana de discusión, la IA no recuerda lo que se ha dicho antes.
Luc: ¡Exactamente! Es precisamente eso lo que es el aprendizaje en contexto. La totalidad de su conversación en esta sesión constituye el contexto.
Camille: Veo.
Luc: Cuando abres una nueva ventana, partes de un contexto vacío. Por lo que la IA no ha perdido el contexto, sino que su espacio de trabajo temporal ha sido simplemente vaciado.
Camille: Por supuesto. Pero, ¿qué ocurre con las nuevas funciones como la «Memoria» que algunas IA están empezando a incorporar? Tenemos la impresión de que realmente comienzan a recordar cosas de una sesión a otra.
Luc: ¡Es un excelente comentario, y es crucial entender cómo funciona esto. La IA no se está mejorando constantemente por sus conversaciones. La IA no se está actualizando constantemente por sus conversaciones.
Camille: Entonces, ¿es una táctica?
Luc: Se puede decir eso. Estas funciones de memoria son una forma astuta de aprendizaje en contexto automatizado. Cuando inicias una nueva conversación, el sistema revisa rápidamente tus intercambios anteriores para identificar la información que parece relevante para tu nueva solicitud, insertando automáticamente estos extractos en el prompt, en segundo plano.
Camille: Así que tenemos la impresión de que la IA recuerda los detalles de mi proyecto, pero en realidad, simplemente le hemos proporcionado un *prompt* justo antes de que empiece a hablar contigo.
Luc: El modelo no aprende ni evoluciona a partir de sus conversaciones. Simplemente utiliza un sistema más inteligente para recordar el contexto pasado.
Camille: Así que la cuestión principal es: ¿necesito un experto o un profesional permanente?
Luc: Es la forma ideal de abordar el problema. Y sobre esta reflexión, es momento de concluir.
Camille: Gracias por escucharnos, ¡y nos vemos pronto en el próximo episodio de ‘Tech Éclair’!
