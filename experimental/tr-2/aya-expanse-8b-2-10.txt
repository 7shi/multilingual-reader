Camille: Bienvenidos a 'Tech Éclair', el podcast donde exploramos la tecnología que moldea nuestro mundo. Yo soy Camille.
Luc: Y yo soy Luc. Hoy vamos a desvelar cómo los modelos de IA que usamos a diario aprenden y alcanzan tal nivel de inteligencia.
Camille: Es un tema fascinante. A menudo percibimos estas IA como cajas negras, pero su proceso de aprendizaje es muy real y merece nuestra atención.
Luc: Exactamente. Este proceso de aprendizaje inicia con un procedimiento denominado 'preentrenamiento'.
Camille: El preentrenamiento
Luc: Imaginen que envían una nueva IA a la escuela para recibir educación general. Lee una cantidad masiva de datos en Internet con el fin de aprender los fundamentos del lenguaje, el razonamiento y el funcionamiento del mundo en general.
Camille: Entonces, después del preentrenamiento, la IA es como un joven graduado de la escuela: inteligente y competente, pero sin experiencia laboral específica.
Luc: Precisamente. Durante mucho tiempo, la siguiente etapa ha sido conocida como el 'ajuste fino' (fine-tuning). Es como si este joven graduado decidiera especializarse en algo específico para adquirir experiencia práctica.
Camille: El afinamiento... ¿es ahí donde interviene el 'aprendizaje por transferencia'? Ya he oído este término.
Luc: Exactamente. El aprendizaje por transferencia es fundamental. Considere que no enseñaría matemáticas básicas a un físico brillante antes de que abordara la mecánica cuántica. Él aplicaría sus habilidades matemáticas preexistentes. La IA sigue un patrón similar. Los idiomas son un excelente ejemplo de esto.
Camille: ¿En otras palabras? Es decir, ¿a qué se refiere con eso?
Luc: Puedes tomar un modelo experto en inglés y luego presentarle una cantidad mucho menor de texto en francés. Aprenderá francés a una velocidad sorprendente.
Camille: ¿Es decir, porque ya comprende los conceptos generales de gramática, sintaxis y estructura de la frase gracias a su conocimiento previo del inglés?
Luc: Exactamente. No necesita volver a aprender la estructura verbal. Simplemente adquiere vocabulario y reglas del francés, aprovechando sus conocimientos previos para entender los conceptos fundamentales. Ésta es la clave de la eficiencia y potencia de este método.
Camille: Por lo tanto, transfiere sus inmensos conocimientos generales obtenidos durante el preentrenamiento a esta nueva tarea específica.
Luc: Es precisamente así. Por eso, puede convertirse en un experto en sus datos con sorprendentemente pocas informaciones nuevas. No parte de cero; se apoya en cimientos extremadamente sólidos.
Camille: ¿Es lógico? Pero, como discutimos en nuestro último episodio sobre los Transformers, un nuevo enfoque más flexible está surgiendo, ¿no?
Luc: Sí, y esto es posible gracias a la expansión masiva de la memoria a corto plazo de la IA, conocida como 'ventana de contexto'. Este enfoque se denomina aprendizaje en contexto o ICL (Aprendizaje en Contexto).
Camille: Por lo tanto, en lugar de volver a entrenar a la IA para convertirla en una especialista, simplemente se le proporciona la información que necesita para completar la tarea.
Luc: Ha comprendido perfectamente el mensaje. Es similar a contratar a un consultor experto y, en lugar de inscribirlo en un curso de formación de varios años, proporcionarle simplemente los documentos informativos precisos que necesita para llevar a cabo el proyecto actual.
Camille: Es ahí donde interviene el concepto de «anclaje», que consiste en relacionar las respuestas de la IA con la información específica que proporcionas.
Luc: Exactamente. Sin embargo, esto nos lleva a un aspecto crucial que a menudo se malinterpreta: la manera en que la Inteligencia Artificial 'recuerda' y retiene esta información. Existe una distinción fundamental entre el conocimiento temporal y las habilidades duraderas.
Camille: ¿Cuál es la diferencia entre copiar para un examen y realmente comprender y dominar un tema?
Luc: Una analógica perfecta. El aprendizaje en contexto es como hacer un resumen rápido. Los conocimientos que le ofreces en el prompt son temporales y se limitan a esta conversación. Una vez finalizada, la IA deja de tener acceso a esa información específica.
Camille: Ella olvida todo.
Luc: Ella olvida toda la información proporcionada en una conversación específica. Por lo tanto, si necesito que la IA recuerde los mismos datos para una nueva interacción, debo incluir nuevamente la información relevante en el prompt.
Camille: Entiendo. De acuerdo.
Luc: Esta es la realidad del ICL. Es increíblemente flexible, pero se basa en una memoria a corto plazo. El afinamiento, por el contrario, busca crear una competencia permanente. Al afinar un modelo, se modifica su estructura interna de manera fundamental. Los nuevos conocimientos se integran como parte esencial de su identidad.
Camille: Por lo tanto, ¿las conocimientos adquiridos mediante el afinamiento persisten en todas las interacciones futuras para siempre?
Luc: Sí. Es como aprender a andar en bicicleta. La habilidad adquirida mediante el afinamiento se integra permanentemente en la estructura del modelo, por lo que no necesitas que te recuerden las reglas de equilibrio cada vez que interactúas con él.
Camille: Luc, esto explica una experiencia muy común con los chatbots: aunque mantengamos una conversación extensa y detallada, al iniciar una nueva interacción, la IA pierde el contexto de lo discutido previamente.
Luc: ¡Exactamente! Este es el aprendizaje en contexto en acción. Todo el historial de su conversación en esta sesión sirve como contexto.
Camille: Entiendo.
Luc: Cuando abres una nueva ventana de conversación, la IA comienza con un contexto vacío. No es que 'olvide' la información previa, sino que su memoria de trabajo temporal se restablece, dejando atrás los datos de la interacción anterior.
Camille: Pero, ¿qué hay de las nuevas funciones como la 'Memoria' que algunas IA están empezando a integrar? Da la sensación de que realmente comienzan a recordar información de una interacción a otra.
Luc: Es una observación excelente y fundamental entender cómo funciona realmente la inteligencia artificial. No se actualiza constantemente con cada conversación. Sería increíblemente ineficiente hacerlo.
Camille: ¿Es entonces una artimaña?
Luc: Se puede afirmar que estas funciones de memoria constituyen una forma inteligente de aprendizaje en contexto automatizado. Cuando inicias un nuevo diálogo, el sistema busca rápidamente en tus conversaciones anteriores la información relevante para tu consulta y luego inserta automáticamente estos fragmentos de manera sutil.
Camille: Por lo tanto, tenemos la impresión de que la IA recuerda los detalles de mi proyecto, pero en realidad solo le proporcionaron un esquema o resumen justo antes de comenzar a hablar con usted.
Luc: Precisamente. El modelo no aprende ni evoluciona a partir de las discusiones con los usuarios. En lugar de eso, utiliza un sistema sofisticado para recordar y referenciar el contexto anterior.
Camille: ¿Entonces, la gran pregunta para quien utiliza estas herramientas es: ‘¿Necesito un consultor temporal o un experto permanente?’
Luc: Esta es la manera ideal de abordar el problema. Y sobre esta reflexión, es momento de concluir.
Camille: ¡Gracias por escucharnos! Hasta pronto para el próximo episodio de 'Tech Relámpago'.
