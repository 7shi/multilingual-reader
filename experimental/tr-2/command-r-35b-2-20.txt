Camille: Hola y bienvenidos a «Tech Relámpago», el podcast donde analizamos la tecnología que moldea nuestro mundo. Yo, Camille, les doy la bienvenida.
Luc: Y yo soy Luc. Hoy vamos a descubrir el secreto de cómo los modelos de IA que utilizamos diariamente aprenden y se vuelven sorprendentemente inteligentes.
Camille: Es un tema sumamente fascinante. A menudo percibimos estas IA como cajas misteriosas, pero su aprendizaje sigue un proceso real y palpable. ¡Descubramos juntos los entresijos de cómo estos sistemas aprenden!
Luc: Exacto. Y este aprendizaje inicia con un proceso conocido como "entrenamiento previo".
Camille: El pre-entrenamiento.
Luc: Imagine que enviamos una IA completamente nueva a la escuela para proporcionarle una educación general. Lee una cantidad masiva de datos en Internet con el fin de aprender los cimientos del lenguaje, el razonamiento y el funcionamiento del mundo en general.
Camille: Por lo tanto, después del pre-entrenamiento, la IA es como un recién graduado de la universidad: inteligente y competente, pero sin experiencia práctica concreta.
Luc: Precisamente. Y durante mucho tiempo, la siguiente etapa ha sido "el afinamiento" (fine-tuning). Es como enviar a este recién egresado a una especialización para profundizar en su área de expertise.
Camille: "El afinamiento... ¿es aquí donde entra el 'aprendizaje basado en transferencia'? He oído hablar de este término."
Luc: Exacto. La clave del asunto es el aprendizaje por transferencia. Piense en esto: no se le enseñarían matemáticas básicas a un brillante físico antes de que comience con la mecánica cuántica; él transfiere sus conocimientos matemáticos adquiridos previamente. La IA hace lo mismo, y las lenguas naturales son un excelente ejemplo.
Camille: ¿Podría aclararme, por favor, el significado de esa frase?
Luc: Con un enfoque en la transferencia de aprendizaje, puede aprovechar un modelo especializado en inglés y presentarlo a una cantidad relativamente pequeña de texto en francés. De esta manera, adquirirá rápidamente los conocimientos necesarios para dominar el idioma francés con impresionante rapidez.
Camille: Gracias a que ya domina los conceptos generales de gramática y estructura sintáctica gracias al inglés.
Luc: Exacto. No necesita volver a aprender qué es un verbo. Simplemente aprende las palabras y las reglas del francés, trasladando los conceptos básicos. Esa es la gran potencia de este enfoque.
Camille: Por lo tanto, aplica su extenso conocimiento general adquirido en el preentrenamiento a la nueva tarea específica.
Luc: Es exactamente así. Por eso puede convertirse en un experto de sus datos con una mínima cantidad de nueva información. No empieza desde cero; se apoya en cimientos extremadamente sólidos.
Camille: ¡Es lógico! Pero como discutimos en nuestro último episodio sobre los Transformers, una nueva aproximación más flexible está surgiendo, ¡y eso es genial!
Luc: Sí, y esto se debe a la expansión masiva de la memoria a corto plazo de la IA, o su "marco de contexto". Esta técnica se conoce como aprendizaje en contexto, abreviadamente ICL (In-Context Learning).
Camille: Entonces, en lugar de volver a entrenar la IA para convertirla en una especialista, le entregamos directamente la información necesaria para cumplir con su tarea.
Luc: Lo has comprendido perfectamente. Es como contratar a un consultor brillante y, en lugar de enviarlo a un programa de capacitación de varios años, simplemente proporcionarle los documentos informativos exactos que necesita para el proyecto en curso.
Camille: Es aquí donde entra en juego el concepto de 'enraizamiento', que consiste en vincular las respuestas de la IA a la información específica que tú provees.
Luc: Exacto. Pero esto nos lleva a un punto crucial que suele ser malinterpretado: la forma en que la IA "recuerda" esta información. Es la diferencia entre un conocimiento temporal y una habilidad permanente.
Camille: ¿Cuál es la diferencia entre estudiar con intensidad para un examen y poseer un dominio real sobre el tema?
Luc: ¡Una analogía perfecta! El aprendizaje en contexto es como prepararse a fondo para una prueba. Los conocimientos que se le brindan en el prompt son temporales y la IA los utiliza exclusivamente durante esta conversación puntual. Una vez concluida, esos conocimientos quedan olvidados.
Camille: Olvida absolutamente todo. Borra todos los datos de su memoria, dejándola en blanco.
Luc: Olvida absolutamente todo. Es una memoria únicamente para un uso, por lo que si deseas que tenga conocimiento de la misma información mañana, tendrás que proporcionarle nuevamente los documentos.
Camille: ¡Claro! ¡Está bien!
Luc: Esta es la realidad del ICL. Es sumamente flexible, pero se basa en una memoria de trabajo a corto plazo. El afinamiento, por el contrario, busca crear una habilidad permanente. Cuando afinamos un modelo, modificamos su estructura interna de manera fundamental. Los nuevos conocimientos se integran plenamente en su identidad.
Camille: ¿Por lo tanto, los conocimientos adquiridos como resultado del afinamiento persisten en todas las conversaciones de manera permanente?
Luc: Sí. Es como aprender a andar en bicicleta. La habilidad está anclada. No necesitas que te recuerden las leyes del equilibrio cada vez que te sientas en el asiento.
Camille: Luc, eso explica una experiencia muy común con los chatbots. Puedes tener una conversación larga y detallada, pero si abres una nueva ventana de conversación, la IA no tiene ni idea de lo que se ha dicho anteriormente.
Luc: Exacto, el aprendizaje en acción. El registro completo de tu conversación en esta sesión es el contexto.
Camille: Lo veo.
Luc: Cuando abres una nueva ventana, comienza desde un contexto vacío. La IA no ha olvidado en el sentido de la palabra humana; su espacio de trabajo temporal simplemente ha sido vaciado.
Camille: ¿Qué hay de las nuevas funciones como la 'Memoria' que algunas IA empiezan a incorporar? Parece que realmente comienzan a recordar cosas de una sesión a otra.
Luc: Es una observación excelente, y es esencial comprender su funcionamiento. La IA no se perfecciona continuamente a través de tus conversaciones; sería extremadamente ineficiente.
Camille: ¿Es entonces una táctica?
Luc: Sí, así es. Estas funciones de memorización son una forma astuta y automatizada de aprendizaje en contexto. Cuando inicias una nueva conversación, el sistema realiza rápidamente una búsqueda en tus intercambios anteriores para identificar la información más relevante a tu nueva solicitud. Luego, inserta automáticamente estos extractos relevantes en segundo plano, sin que lo notes.
Camille: Por lo tanto, parece que la IA recuerda los datos de mi proyecto, pero en realidad le hemos proporcionado únicamente una ayuda justo antes de que comenzara a hablarle.
Luc: El modelo en sí mismo no aprende ni evoluciona a través de sus conversaciones. Emplea un sistema inteligente y eficiente para recordar el contexto pasado.
Camille: ¿Para quién usa estas herramientas, es necesario un consultor temporal o un experto permanente?
Luc: Es la manera ideal de plantear el problema. Y con esta reflexión, es hora de concluir.
Camille: ¡Muchas gracias por escucharnos! Les agradecemos su atención y los esperamos en el próximo episodio de « Tech Éclair». ¡Hasta la próxima!
