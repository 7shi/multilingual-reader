Camille: Hola y bienvenidos a "Tech Éclair", el podcast donde exploramos la tecnología que da forma a nuestro mundo. Soy Camille. Espero que disfrutes esta aventura tecnológica.
Luc: Y soy Luc. Hoy, vamos a descubrir cómo los modelos de IA que usamos en nuestro día a día aprenden a ser tan inteligentes, revelando así sus secretos.
Camille: ¡Es un tema fascinante. A menudo, se perciben a las IA como sistemas opacos, pero su aprendizaje sigue un proceso muy real. Aunque es importante aclarar que este término se utiliza para referirse a procesos complejos y difíciles de entender, donde la entrada y salida no son directamente visibles.
Luc: Exactamente. Y este proceso de aprendizaje comienza con lo que se llama 'pre-entrenamiento'.
Camille: El preentrenamiento.
Luc: Imaginemos que enviamos a una IA totalmente nueva a la escuela para darle una cultura general. Ella lee una gran cantidad de textos en Internet, como artículos, libros y bases de datos, para aprender los fundamentos del lenguaje, el razonamiento y el funcionamiento del mundo en general.
Camille: Entonces, después del preentrenamiento, la IA es como un recién graduado de la universidad: inteligente y competente, pero sin experiencia laboral en el campo específico.
Luc: Precisamente. Y por mucho tiempo, el siguiente paso fue "el ajuste" (fine-tuning). Este proceso implica especializar a la IA en un campo específico, como si enviáramos a este graduado a seguir una formación avanzada en su área de especialización.
Camille: El ajuste... es cuando entra en juego el "aprendizaje por transferencia". Ya he escuchado este término antes.
Luc: Exactamente. El aprendizaje por transferencia es la clave. Piensen en esto: no enseñaría matemáticas básicas a un brillante físico antes de que se enfrente a la mecánica cuántica. La IA hace lo mismo. Las lenguas son un excelente ejemplo de esto. Por ejemplo, cuando una IA aprende un idioma, ya tiene conocimientos previos de otro idioma que le permiten comprender más fácilmente las estructuras y reglas del nuevo idioma. Esto se debe a que el aprendizaje por transferencia permite a la IA utilizar sus habilidades matemáticas o lingüísticas existentes para aprender nuevos conceptos en un campo diferente.
Camille: ¿A qué te refieres? ¿Cuál es el significado?
Luc: Toma un modelo de experiencia en inglés y luego presentarle una cantidad mucho menor de texto en francés. Aprenderá el francés a una velocidad increíble.
Camille: ¡Porque ya comprende los conceptos generales de gramática, sintaxis y estructura de oración gracias al inglés! Esta comprensión se logra por la familiaridad con los patrones del idioma inglés, que le permite anticipar y analizar las estructuras gramaticales y la organización de las palabras en oraciones. Esto le facilita el aprendizaje de otros idiomas, ya que puede identificar rápidamente las reglas gramaticales y la sintaxis en nuevos contextos.
Luc: Exactamente. No necesita volver a aprender qué es un verbo. Simplemente aprende las palabras y las reglas del francés, transfiriendo los conceptos subyacentes. Esta es toda la potencia de este enfoque. Es una ventaja clave de esta estrategia que permite a la IA adquirir nuevo conocimiento transferible sin tener que 'reaprender' conceptos fundamentales desde cero.
Camille: Por lo tanto, transfiere sus inmensas conocimientos generales del preentrenamiento a la nueva tarea específica.
Luc: Eso es exactamente lo que significa. Por eso puede convertirse en un experto de sus datos con una cantidad sorprendentemente baja de información nueva. No comienza desde cero; se basa en fundamentos extremadamente sólidos.
Camille: Es lógico. Pero, como discutimos en nuestro último episodio sobre Transformers, está surgiendo un nuevo enfoque más flexible, ¿no?
Luc: Sí, y esto es posible gracias a la expansión masiva de la memoria a corto plazo de la IA, o «ventana de contexto». Este enfoque se llama aprendizaje en contexto, o ICL (Aprendizaje en Contexto). La IA aprovecha su capacidad para retener información reciente, permitiendo que el modelo pueda aprender de ejemplos y patrones sin necesidad de entrenamiento adicional extensivo. Esta expansión permite un aprendizaje más eficiente y adaptativo.
Camille: Por lo tanto, en lugar de volver a entrenar a la IA para que se convierta en una especialista, simplemente le proporcionamos las información necesaria para realizar la tarea. Esto permite a la IA aprovechar su conocimiento previo y aprender de manera más eficiente.
Luc: Usted ha entendido todo. Es como contratar a un consultor brillante y, en lugar de enviarlo a un programa de formación de varios años, simplemente proporcionarle los documentos de información exactos que necesita para el proyecto actual.
Camille: Es aquí donde entra el concepto de "ancoraje" (grounding), que consiste en vincular las respuestas de la IA con la información específica que ustedes proporcionan, permitiendo así una mejor adaptación y precisión en sus resultados.
Luc: Exactamente. Pero esto nos lleva a un punto crucial que a menudo se malinterpreta: la forma en que la IA « se acuerda » de esta información, es decir, cómo su conocimiento temporal se convierte en una competencia permanente.
Camille: ¿Qué es exactamente lo que significa estudiar para un examen y dominar realmente un tema?
Luc: ¡Una analogía perfecta! El aprendizaje en contexto es como estudiar para un examen. Los conocimientos que ustedes proporcionan en el prompt son temporales. La IA los utiliza para esta única interacción, pero una vez que la conversación termina, estos conocimientos desaparecen. Sin embargo, esta forma de aprendizaje permite a la IA adaptarse y aprender de manera más eficiente sin necesidad de estudio adicional.
Camille: Ella ignora todo lo aprendido.
Luc: Olvidar todo. Por lo tanto, es una memoria de uso único. Si quiero que tenga conocimiento de las mismas informaciones mañana, tengo que proporcionarle nuevamente los documentos.
Camille: ¡Entendido!
Luc: Es así como se encuentra el ICL. Es increíblemente flexible, pero se basa en una memoria a corto plazo. El afinar, por otro lado, tiene como objetivo crear una competencia permanente. Cuando afinan un modelo, modifican fundamentalmente su estructura interna. Las nuevas conocimientos se vuelven parte integral de su identidad.
Camille: ¿Las conocimientos obtenidas a través del afinar persisten en todas las conversaciones?
Luc: Sí. Es como aprender a andar en bicicleta. La competencia se ancla. No necesitas que te recuerden las leyes de equilibrio cada vez que subas a la bicicleta.
Camille: Luc, esto explica una experiencia muy común con los chatbots. Podemos tener una conversación larga y detallada, pero si abrimos una nueva ventana de discusión, la IA no tiene idea de lo que se ha dicho anteriormente.
Luc: ¡Exactamente! Esto es el aprendizaje en contexto en acción. Todo el historial de su discusión en esta sesión forma parte del contexto.
Camille: Entiendo.
Luc: Cuando abres una nueva ventana, starts con un contexto vacío. La IA no ha "olvidado" en el sentido humano; su **espacio de trabajo temporal, que almacena temporalmente información relevante para esa conversación**, simplemente se ha vaciado.
Camille: Pero ¿qué pasa con las nuevas funcionalidades como la "Memoria" que algunas IA comienzan a integrar? Parece que realmente comienzan a recordar cosas de una sesión a otra.
Luc: Es un buen punto y es crucial entender cómo funciona. La IA no se afina constantemente con tus conversaciones. Sería increíblemente ineficiente.
Camille: ¿Es un truco? (¿No sería más apropiado preguntar '¿Se puede usar para algo más?' o '¿Cómo funciona esto exactamente?'?)
Luc: Se puede decir eso. Estas funciones de memorización son una forma inteligente de aprendizaje en contexto automatizado. Cuando se inicia una nueva conversación, el sistema busca rápidamente en sus antiguos intercambios las informaciones que parecen pertinentes para su nueva solicitud. Luego, inserta automáticamente estos extractos en el prompt, detrás del escenario. Es crucial entender cómo funcionan estas funciones para aprovechar al máximo la capacidad de la IA de recordar y aplicar el contexto.
Camille: Por lo tanto, da la impresión de que la IA recuerda los detalles de mi proyecto, pero en realidad se le ha proporcionado una información de consulta justo antes de empezar a hablar. Esto no significa que la IA realmente recuerde y aplique el contexto de las sesiones anteriores, sino que utiliza técnicas automatizadas para buscar información relevante en sus conversaciones anteriores.
Luc: Precisamente. El modelo en sí mismo no aprende ni evoluciona a partir de tus conversaciones. Simplemente utiliza un sistema más inteligente para recordar el contexto pasado. Esto significa que el modelo no adquiere experiencia o sabiduría de tus discusiones, sino que solo aprovecha la información previa para mejorar su rendimiento en conversaciones futuras.
Camille: ¡Por lo tanto, la gran pregunta para cualquiera que utilice estas herramientas es: ¿Necesito un consultor temporal o un experto permanente?!
Luc: ¡Es la mejor manera de plantear el problema! Con esta reflexión, ha llegado el momento de concluir.
Camille: Gracias por escucharnos y hasta pronto en el próximo episodio de Tech Éclair!
