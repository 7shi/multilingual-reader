Camille: ¡Hola y bienvenidos a 'Tech Éclair', el podcast en el que desciframos la tecnología que da forma a nuestro mundo. Soy Camille.
Luc: ¡Y soy Luc. Hoy vamos a quitar el velo sobre cómo aprenden los modelos de IA que usamos a diario y cómo se vuelven tan inteligentes.
Camille: ¡Es un tema fascinante. A menudo percibimos estas IAs como cajas negras, pero su aprendizaje sigue un proceso muy real.
Luc: ¡Exacto. Y este aprendizaje comienza por un proceso llamado "pre-entrenamiento".
Camille: ¡El pre-entrenamiento.
Luc: ¡Imaginen que enviamos una IA completamente nueva a la escuela para darle cultura general. Lee una cantidad masiva de datos en Internet para aprender los fundamentos del lenguaje, el razonamiento y el funcionamiento del mundo en general.
Camille: ¡Por lo tanto, después del pre-entrenamiento, la IA es como un graduado universitario joven: inteligente y competente, pero sin experiencia laboral específica.
Luc: ¡Exacto. Y durante mucho tiempo, la siguiente etapa fue 'la afinación' (fine-tuning). Es como enviar a ese graduado para que se especialice.
Camille: ¡La afinación... ¡Es aquí donde entra en juego 'el aprendizaje por transferencia'? Ya he escuchado este término.
Luc: ¡Exacto. El aprendizaje por transferencia es la clave. Veamos: no enseñaría matemáticas básicas a un físico brillante antes de que se enfrente a la mecánica cuántica. Transferencia sus habilidades matemáticas existentes. La IA hace lo mismo. Las lenguas son un excelente ejemplo.
Camille: ¿Qué quieres decir?
Luc: ¡Puedes tomar un modelo experto en inglés y luego presentarle una cantidad mucho menor de texto en francés. Aprenderá el francés a una velocidad increíble.
Camille: ¡Porque ya comprende los conceptos generales de gramática, sintaxis y estructura de la frase gracias al inglés?
Luc: ¡Exacto. No necesita volver a aprender qué es un verbo. Simplemente aprende las palabras y las reglas del francés, transfiriendo los conceptos subyacentes. Esta es toda la fuerza de este enfoque.
Camille: ¡Por lo tanto, transfiere sus inmensas competencias generales derivadas del preentrenamiento a la nueva tarea específica.
Luc: ¡Es exactamente eso. Por eso puede convertirse en un experto de tus datos con sorprendentemente poca información nueva. No empieza desde cero; se basa en una base extremadamente sólida.
Camille: ¡Es lógico. Pero como discutimos en nuestro último episodio sobre los Transformers, una nueva y más flexible metodología está surgiendo, ¿no es así?
Luc: ¡Sí, y se hace posible gracias a la expansión masiva de la memoria a corto plazo de la IA, o 'ventana de contexto'. Este enfoque se llama aprendizaje en contexto, o ICL (Aprendizaje In-Context).
Camille: ¡Por lo tanto, en lugar de volver a entrenar a la IA para que se convierta en una especialista, se le proporcionan simplemente las informaciones que necesita para llevar a cabo la tarea asignada.
Luc: ¡Entendiste todo. Es como contratar a un consultor brillante y, en lugar de enviarlo a un programa de formación de varios años, simplemente proporcionarle los documentos de información exactos que necesita para el proyecto actual.
Camille: Es aquí donde entra en juego el concepto de « anclaje » (grounding), que consiste en vincular las respuestas de la IA con las informaciones específicas que usted proporciona.
Luc: ¡Exacto. Pero esto nos lleva a un punto crucial que se malinterpretan a menudo: cómo la IA 'recuerda' esta información. Es la diferencia entre conocimiento temporal y competencia permanente.
Camille: ¡La diferencia entre estudiar para un examen y dominar realmente un tema?
Luc: ¡Una analogía perfecta! El aprendizaje en contexto es como estudiar para un examen. Los conocimientos que se proporcionan en el prompt son temporales. La IA los utiliza para esta conversación única, pero una vez que la conversación ha terminado, estos conocimientos desaparecen.
Camille: ¡Olvida todo!
Luc: ¡Olvida todo! Por lo tanto, es una memoria de uso único. Si quiero que tenga conocimiento de las mismas informaciones mañana, debo proporcionarle nuevamente los documentos.
Camille: ¡De acuerdo.
Luc: ¡Esa es la realidad del ICL. Es increíblemente flexible, pero se basa en una memoria a corto plazo. El ajuste, por otro lado, apunta a crear una competencia permanente. Cuando ajustas un modelo, modificas fondamentalmente su estructura interna. Los nuevos conocimientos se vuelven parte integral de su identidad.
Camille: ¡Por lo tanto, los conocimientos obtenidos a través del ajuste persisten en todas las conversaciones, para siempre?
Luc: ¡Sí. Es como aprender a montar en bicicleta. La competencia está anclada. No necesitas que te recuerden las leyes de equilibrio cada vez que subes a la silla.
Camille: Luc, esto explica una experiencia muy común con los chatbots. Puedes tener una conversación larga y detallada, pero si abres una nueva ventana de discusión, la IA no tiene idea de lo que se dijo antes.
Luc: ¡Exacto! Es el aprendizaje en contexto en acción. El historial completo de su discusión en esta sesión constituye el contexto.
Camille: ¡Entiendo.
Luc: Cuando abres una nueva ventana, starts con un contexto vacío. La IA no ha "olvidado" en el sentido humano; su espacio de trabajo temporal simplemente se ha vaciado.
Camille: ¡Pero, ¿qué pasa con las nuevas funcionalidades como la «Memoria» que algunas IA están empezando a integrar? Tenemos la impresión de que realmente están comenzando a recordar cosas de una sesión a otra.
Luc: ¡Eso es una excelente observación, y es crucial entender cómo funciona. La IA no se está refinando constantemente con sus conversaciones. Sería increíblemente ineficaz.
Camille: ¡Entonces es un truco?
Luc: ¡Se puede decir eso! Estas funciones de memorización son una forma astuta de aprendizaje en contexto automatizado. Cuando initiates una nueva conversación, el sistema busca rápidamente en tus antiguos intercambios las informaciones que parecen relevantes para tu nueva consulta. Luego, inserta automáticamente estos extractos en la línea de comandos, detrás de escena.
Camille: ¡Por lo tanto, parece que la IA se recuerda los detalles de mi proyecto, pero en realidad le proporcionamos una guía justo antes de que comience a hablar con usted.
Luc: Precisamente. El modelo mismo no aprende ni evoluciona a partir de sus conversaciones. Simplemente utiliza un sistema más inteligente para recordar el contexto pasado.
Camille: ¿Entonces, ¿necesito un consultor temporal o un experto permanente? Es la gran pregunta para cualquiera que utilice estos instrumentos.
Luc: Es la mejor manera de plantear el problema. Y sobre esta reflexión, es tiempo de concluir.
Camille: ¡Gracias por haber nos escuchado, y hasta pronto para el próximo episodio de Tech Éclair!
