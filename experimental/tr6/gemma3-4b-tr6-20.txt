Camille: ¡Hola y bienvenidos a « Tech Éclair », el podcast donde analizamos la tecnología que modela nuestro mundo. Soy Camille.
Luc: Y soy Luc. Hoy, vamos a desvelar la forma en que los modelos de IA que utilizamos a diario aprenden y se vuelven tan inteligentes.
Camille: Es un tema fascinante. A menudo percibimos estas IA como cajas negras, pero su aprendizaje sigue un proceso real.
Luc: Exactamente. Y este aprendizaje comienza con un proceso llamado “pré-entraînement”.
Camille: El pre-entrenamiento.
Luc: Imaginemos que enviamos una nueva IA a la escuela para que aprenda una cultura general.
Camille: Entonces, después del pre-entrenamiento, la IA es como un recién graduado de la universidad: inteligente y competente, pero sin experiencia profesional específica.
Luc: Precisamente. Y durante mucho tiempo, la siguiente etapa ha sido “el afinamiento” (fine-tuning).
Camille: El afinamiento… ¿es donde interviene “el aprendizaje por transferencia”?
Luc: Exactamente. El aprendizaje por transferencia es la clave. Miren más de cerca: no enseñarían las matemáticas básicas a un físico brillante antes de que ataque la mecánica cuántica.
Camille: Aclarando?
Luc: Puede tomar un modelo experto en inglés y, luego, presentárselo a una cantidad mucho menor de texto en francés. Aprenderá francés a una velocidad asombrosa.
Camille: ¿Porque ya comprende los conceptos generales de gramática, sintaxis y estructura de frase gracias al inglés?
Luc: Exactamente. No necesita re-aprender lo que es un verbo. Simplemente aprende las palabras y las reglas del francés, transfiriendo los conceptos subyacentes.
Camille: Entonces, transfiere sus enormes conocimientos generales provenientes del pre-entrenamiento a la nueva tarea específica.
Luc: Eso es exactamente. Es por eso que puede convertirse en un experto de sus datos con sorprendentemente poca información nueva. No empieza desde cero; se apoya en fundamentos extremadamente sólidos.
Camille: “Tiene sentido. Pero como hemos discutido en nuestro último episodio sobre los Transformers, una nueva aproximación más flexible está surgiendo, ¿no es así?”
Luc: Sí, y se hace posible por la expansión masiva de la memoria a corto plazo de la IA, o “ventana de contexto”. Esta aproximación se llama “aprendizaje en contexto”, o ICL (Aprendizaje en Contexto).
Camille: Entonces, en lugar de reentrenar la IA para convertirla en una especialista, le damos simplemente la información que necesita para la tarea a realizar.
Luc: Ya lo entendiste todo. Es como contratar a un consultor brillante y, en lugar de enviarlo a seguir un programa de formación de varios años, simplemente proporcionarle los documentos de información exactos que necesita para el proyecto en curso.
Camille: Ahí es donde interviene el concepto de “anclaje” (grounding), que consiste en ligar las respuestas de la IA a la información específica que usted proporciona.
Luc: Exactamente. Pero eso nos lleva a un punto crucial que a menudo se malinterpreta: la manera en que la IA “se recuerda” de esa información.
Camille: La diferencia entre estudiar a toda prisa para un examen y dominar realmente un tema.
Luc: ¡Una analogía perfecta! El aprendizaje en contexto, es como estudiar a toda prisa para un examen.
Camille: Se olvida todo.
Luc: Se olvida todo. Por lo tanto, es una memoria de uso único.
Camille: Está bien.
Luc: Así es la realidad del ICL. Es increíblemente flexible, pero se basa en una memoria a corto plazo. El afinamiento, en cambio, tiene como objetivo crear una habilidad permanente.
Camille: Entonces, ¿las conocimientos obtenidos a través del afinamiento persisten en todas las conversaciones, para siempre?
Luc: Sí. Es como aprender a andar en bicicleta. La habilidad está anclada.
Camille: Luc, eso explica una experiencia muy común con los chatbots. Se puede tener una conversación larga y detallada, pero si se abre una nueva ventana de discusión, la IA no tiene idea de lo que se dijo antes.
Luc: ¡Exactamente! Es el aprendizaje en contexto en acción. La totalidad del historial de su discusión en esta sesión constituye el contexto.
Camille: Ya veo.
Luc: Cuando abres una nueva ventana, empiezas con un área de trabajo vacía. La IA no ha ‘olvidado’ al sentido humano del término; su área de trabajo temporal ha simplemente sido vacía.
Camille: Pero, ¿qué tal las nuevas funciones como la “Memoria” que algunas IA están empezando a integrar?
Luc: Es una excelente observación, y es crucial entender cómo funciona. La IA no se está afinando constantemente por sus conversaciones. Eso sería increíblemente ineficiente.
Camille: ¿Entonces, es una astucia?
Luc: Se puede decir eso. Estas funciones de almacenamiento son una forma astucia de aprendizaje en contexto automatizado.
Camille: Entonces, tenemos la impresión de que la IA recuerda los detalles de mi proyecto, pero en realidad, solo le hemos proporcionado un recordatorio rápido justo antes de que empiece a hablar conmigo.
Luc: Exactamente. El modelo mismo no aprende ni evoluciona a partir de sus conversaciones. Simplemente utiliza un sistema más inteligente para recordar el contexto pasado.
Camille: Entonces, la gran pregunta para cualquiera que use estas herramientas es: "¿Necesito un consultor temporal o un experto permanente?"
Luc: Es la manera ideal de plantear el problema. Y sobre esta reflexión, es hora de concluir.
Camille: Gracias por escucharnos, y hasta pronto para el próximo episodio de « Tech Éclair » !
