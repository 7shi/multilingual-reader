Camille: decodificamos la tecnología que moldea nuestro mundo. Soy Camille.
Luc: Y yo soy Luc. Hoy vamos a descubrir cómo los modelos de IA que usamos a diario aprenden y se vuelven tan inteligentes.
Camille: Es un tema fascinante. Se percibe a menudo a estas IA como cajas negras, pero su aprendizaje es un proceso muy real.
Luc: Este aprendizaje comienza por un proceso llamado el « preentrenamiento ».
Camille: El preentrenamiento.
Luc: Le enviamos a esta IA a estudiar para darle una cultura general, leyendo una enorme cantidad de datos en Internet y así aprender los fundamentos del lenguaje, el razonamiento y el funcionamiento del mundo en general.
Camille: Después del preentrenamiento, la IA es como un recién graduado de la universidad: inteligente y competente, pero sin experiencia profesional específica.
Luc: Precisamente. Y durante mucho tiempo, el paso siguiente fue el ajuste fino. Es como enviar a ese graduado a especializarse.
Camille: ¿Es en el afinado donde interviene el aprendizaje por transferencia? Ya he oído este término.
Luc: Exactamente. El *transfer learning* es la clave. Vean ustedes: no enseñarías matemáticas básicas a un físico brillante antes de que se enfrente a la mecánica cuántica. Él transfiere sus competencias matemáticas existentes. La IA hace lo mismo. Los idiomas son un excelente ejemplo.
Camille: ¿Me explicas con un ejemplo?
Luc: Pueden tomar un modelo preentrenado experto en inglés y exponérsele una cantidad mucho más pequeña de texto en francés. Aprenderá francés a una velocidad asombrosa.
Camille: Porque ya entiende las ideas básicas de gramática, sintaxis y estructuras de las oraciones gracias al inglés.
Luc: Exactamente. No necesita reaprender lo que es un verbo. Aprende simplemente las palabras y las reglas del francés, al transferir los conceptos subyacentes. ¡Esa es toda la potencia de este enfoque!
Camille: transfiere sus conocimientos generales profundos, provenientes del preentrenamiento, a la tarea específica nueva.
Luc: ¡Exactamente! Por eso puede volverse un experto de sus datos con sorprendentemente poco nuevo. No parte de cero; se basa en fundamentos extremadamente sólidos.
Camille: Tiene sentido como hablamos en nuestro último episodio sobre Transformers, ¿no es así? Una nueva aproximación más flexible está surgiendo.
Luc: Sí, y esto es posible gracias a la expansión masiva de la ventana de contexto de la IA, o lo que llamamos ventana de contexto. Esta aproximación se denomina aprendizaje por contexto, o ICL (Aprendizaje por Contexto).
Camille: En lugar de volver a entrenar la IA para especializarla, simplemente se le proporcionan las informaciones que necesita para realizar la tarea.
Luc: **"Lo tienen claro, ¿verdad? Es como contratar a un consultor brillante: en lugar de entrenarlo durante meses para que entienda el proyecto, simplemente le das la información exacta que necesita para el proyecto en curso."**
Camille: Ahí es donde entra el concepto de anclaje, que consiste en vincular las respuestas de la IA a los datos específicos que les proporcionáis.
Luc: Exactamente. Pero esto nos lleva a un punto clave que suele malinterpretarse: **la forma en que la IA almacena o procesa estas informaciones**. La diferencia está entre una **memoria a corto plazo** y una **memoria a largo plazo**.
Camille: La diferencia entre **aprender de memoria para un examen** y **entender profundamente un tema**.
Luc: Es como aprender de memoria para un examen. Los conocimientos que le das en el prompt son temporales: la IA los usa solo para esta conversación, pero una vez terminada, esas conocimientos se borran.
Camille: Se lo olvida todo.
Luc: Ella olvida todo. Es una memoria de uso único. Si quiero que ella tenga conocimiento de las mismas informaciones mañana, debo proporcionarle los documentos nuevamente.
Camille: De acuerdo.
Luc: Así es la realidad del aprendizaje por contexto: es increíblemente flexible, pero basado en memoria a corto plazo. El afinado, en cambio, busca crear una habilidad permanente. Cuando afinas un modelo, modifica fundamentalmente su estructura interna.
Camille: Las conocimientos adquiridas mediante el afinado persisten en todas las conversaciones para siempre.
Luc: Sí, es como aprender a montar en bici: la habilidad queda internalizada. No necesitas que te recuerden las reglas del equilibrio cada vez que te subes.
Camille: Luc, esto explica una experiencia muy común con los chatbots: puedes tener una conversación larga y detallada, pero si se abre una nueva ventana de conversación, la IA no tiene ni idea de lo que se dijo antes.
Luc: El aprendizaje por contexto en acción. Todo el historial de tu conversación en esta sesión constituye el contexto.
Camille: Ah, ya veo.
Luc: Cuando abren una nueva sesión, parten desde cero. La IA no olvida como lo entendemos los humanos; su memoria a corto plazo se borra automáticamente.
Camille: ¿Qué hay de las nuevas funcionalidades como la "Memoria" que algunas IA empiezan a integrar? Parece que realmente empiezan a recordar de una sesión a otra.
Luc: Es un excelente punto, y es crucial entender cómo funciona. La IA no se modifica constantemente por nuestras conversaciones; sería poco práctico.
Camille: Entonces, ¿es un truco?
Luc: Podríamos decir eso. Estas funciones de memorización son una forma ingeniosa de aprendizaje en contexto automatizado. Cuando empiezas una nueva conversación, el sistema revisa rápidamente tus intercambios anteriores para encontrar las informaciones que parecen pertinentes para tu nueva solicitud. Después, incorpora esos fragmentos en el prompt de manera automática, sin que te des cuenta.
Camille: Parece que la IA recuerda los detalles de mi proyecto, pero en realidad solo le dimos un resumen de apoyo justo antes de que empezara a hablar contigo.
Luc: Exactamente. El modelo en sí no aprende ni evoluciona a partir de sus conversaciones. Simplemente utiliza un sistema más inteligente para recordar el contexto pasado.
Camille: ¿Necesito un consultor temporal o un experto permanente?
Luc: Esto es la forma ideal de formular el problema. A partir de esta reflexión, ya es tiempo de concluir.
Camille: Gracias por escucharnos, y hasta pronto en el próximo episodio de « Tech Éclair ».
