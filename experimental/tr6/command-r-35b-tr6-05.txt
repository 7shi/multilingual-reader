Camille: Hola y bienvenidos a "Tech Express", el podcast donde desentrañamos la tecnología que está modelando nuestro mundo. Soy Camille.
Luc: Y yo soy Luc. Hoy vamos a levantar el velo sobre cómo los modelos de inteligencia artificial que utilizamos en nuestro día a día aprenden y se vuelven tan inteligentes.
Camille: Es un tema fascinante. A menudo se perciben estas IA como cajas negras, pero su aprendizaje es seguido por un proceso bien real.
Luc: "Exactamente. Y este aprendizaje comienza con un proceso llamado 'pre-entrenamiento'."
Camille: El preentrenamiento.
Luc: Imagina que enviamos a la última inteligencia artificial al colegio para darle unos conocimientos generales. Lee una cantidad masiva de datos en internet para aprender los fundamentos del lenguaje, el razonamiento y el funcionamiento del mundo en general.
Camille: "Camille: Entonces, después del pre-entrenamiento, la IA es como un joven licenciado universitario: inteligente y competente, pero sin experiencia profesional específica."
Luc: Precisamente. Y durante mucho tiempo, la siguiente etapa ha sido el ajuste fino. Es como enviar a este graduado a una especialización.
Camille: "El afinado... ¿es ahí donde entra en juego el aprendizaje basado en transferencia? Ya había oído hablar de ese término."
Luc: "¡Exactamente! La transferencia de aprendizaje es la clave. Mira antes de continuar: no le enseñarías matemáticas básicas a un físico brillante antes de que se enfrentara a la mecánica cuántica. Él transfiere sus habilidades matemáticas existentes. La IA hace lo mismo. Las lenguas son un ejemplo excelente."
Camille: ¿O sea?
Luc: Puede tomar un modelo experto en inglés y luego presentarle una cantidad menor de texto en francés.
Camille: ¿Por qué ya entiende los conceptos generales de gramática, sintaxis y estructura gracias al inglés?
Luc: "Él no necesita volver a aprender qué son los verbos. Simplemente aprende palabras y reglas del francés, trasladando los conceptos básicos. Es ahí donde radica la fuerza de este enfoque."
Camille: Por lo tanto, aplica sus vastos conocimientos generales obtenidos en el pre-entrenamiento a la nueva tarea específica.
Luc: ¡Justamente! Por eso puede llegar a ser un experto en sus datos con una cantidad mínima de nueva información. No comienza desde el principio; se apoya en fundamentos extremadamente sólidos.
Camille: *Lógico.* Como ya hablamos en nuestro último episodio de Transformers, una nueva aproximación más flexible está surgiendo ¿no es cierto?
Luc: Sí, y es posible gracias a la ampliación significativa de la memoria a corto plazo de la IA, o lo que se conoce como «ventana de contexto». Este enfoque recibe el nombre de aprendizaje en contexto, también conocido como ICL (In-Context Learning).
Camille: Así que en lugar de volver a entrenar al IA para especializarlo, le proporcionamos simplemente la información necesaria para completar la tarea.
Luc: Lo has entendido perfectamente. Es como si contratáramos a un experto brillante, en lugar de mandarlo a un programa de formación de varios años, simplemente le proporcionamos la información precisa que necesita para el proyecto actual.
Camille: Aquí es donde entra en juego el concepto de "fijación", que consiste en unir las respuestas del IA a la información específica que usted proporciona.
Luc: Exactamente. Pero eso nos lleva a un punto fundamental, a menudo malinterpretado: cómo el IA recuerda esa información. Es la diferencia entre conocimiento temporal y habilidad permanente.
Camille: "La diferencia entre estudiar de memoria para un examen y comprender en profundidad un tema."
Luc: ¡Una analogía perfecta! El aprendizaje en contexto es como empollar para un examen. Las habilidades que le brindas a través de los prompts son temporales. La IA las utiliza solo para esa única conversación, pero una vez que acaba la charla, esas habilidades desaparecen.
Camille: “Lo olvida todo.”
Luc: Ella lo olvida todo. Es una memoria temporal, así que si quiero que tenga conocimiento de esa información mañana, tendré que volver a proporcionarle los documentos.
Camille: De acuerdo.
Luc: Así es la esencia del ICL, sorprendentemente flexible pero basada en memoria temporal. El refinamiento, por otro lado, busca crear un conocimiento duradero. Cuando refinas un modelo, modificas fundamentalmente su estructura interna; los nuevos conocimientos se convierten en parte integrante de su identidad.
Camille: Entonces, ¿las habilidades obtenidas mediante la afinación permanecen en todas las conversaciones para siempre?
Luc: Sí. Aprender es como andar en bicicleta; una vez que lo dominas, no necesitas recordar las leyes del equilibrio cada vez.
Camille: Luc, esto explica una experiencia muy común con los chatbots. Podemos mantener una conversación extensa y detallada, pero si abrimos una nueva ventana de diálogo, la IA no tiene memoria de lo que se ha dicho antes.
Luc: "¡Exactamente! Es el aprendizaje contextual en acción. Todo el historial de tu conversación en esta sesión es el contexto clave."
Camille: Entiendo.
Luc: Al abrir una nueva ventana de diálogo, estás ante una ausencia total de contexto previo. El chatbot no pierde la memoria en el sentido tradicional, más bien se reinicia el espacio de trabajo temporal.
Camille: ¿Y qué pasa con las nuevas funcionalidades como el "Registro de Memoria" que algunas IA están empezando a incorporar? Pareciera que realmente retienen información de una sesión a otra.
Luc: Es una excelente observación y es crucial comprender cómo funciona esto. La inteligencia artificial no se refina continuamente con sus interacciones. Sería increíblemente ineficiente.
Camille: ¿Es ese el truco entonces?
Luc: Podemos decirlo así. La memoria es una forma inteligente de aprendizaje automatizado contextual. Cuando comienzas una nueva conversación, el sistema realiza una búsqueda rápida en tus intercambios anteriores para encontrar información relevante relacionada con tu nueva solicitud. Luego, en secreto, inserta automáticamente esos extractos en el prompt.
Camille: Entonces, parece que la inteligencia artificial recuerda los detalles de mi proyecto, pero en realidad solo le han proporcionado un resumen de referencia justo antes de empezar a hablar contigo.
Luc: Precisamente, el modelo no aprende ni evoluciona a partir de sus conversaciones; utiliza un sistema avanzado para recuperar datos del contexto previo.
Camille: Entonces, la gran pregunta para cualquiera que use estas herramientas es: "¿Necesito un consultor temporal o un experto permanente?"
Luc: Es la manera ideal de plantear la cuestión. Y sobre esta reflexión, es hora de llegar a una conclusión.
Camille: Gracias por habernos escuchado, ¡hasta pronto en el próximo episodio de «Tech Éclair»!
