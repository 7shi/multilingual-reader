Camille: "Camille: Hola y bienvenida/o a 'Tech Éclair', el podcast donde desentrañamos la tecnología que moldea nuestro mundo. Yo soy Camille."
Luc: Y yo soy Luc. Hoy vamos a revelar cómo aprenden y se vuelven tan inteligentes los modelos de IA que usamos diariamente.
Camille: "Es un tema fascinante. A menudo percibimos a la IA como cajas negras, pero su aprendizaje sigue procesos muy reales."
Luc: "Exactamente. Y este aprendizaje comienza con un proceso llamado 'preentrenamiento'."
Camille: El preentrenamiento.
Luc: Imaginen que enviamos a una inteligencia artificial completamente nueva a la escuela para darle cultura general. Lee una cantidad masiva de datos de internet para aprender los fundamentos del lenguaje, del razonamiento y del funcionamiento del mundo en general.
Camille: "Así que, después del preentrenamiento, la IA es como un joven graduado universitario: inteligente y capaz, pero sin experiencia laboral específica."
Luc: "Precisamente. Y durante mucho tiempo, la siguiente etapa fue la ‘especialización’. Es como enviar a este graduado a una especialización."
Camille: "¿El afinamiento... es ahí donde interviene el aprendizaje por transferencia? Ya lo he oído mencionar."
Luc: Luc dice: **Exactamente. El aprendizaje por transferencia es la clave. Imaginen que no les enseñarían matemáticas básicas a un físico brillante antes de que abordara la mecánica cuántica. Le transferirían sus conocimientos matemáticos previos. Eso es exactamente lo que hace la IA. Un excelente ejemplo son los idiomas.**
Camille: "Es decir, ¿quiere decir...?"
Luc: Puede tomar un modelo experto en inglés y luego presentarle una cantidad mucho menor de texto en francés. **De esta forma**, aprenderá el francés a una velocidad increíble.
Camille: "Porque ya comprende los conceptos generales de gramática, sintaxis y estructura de frase gracias al inglés."
Luc: "Exactamente. No necesita rehacer el aprendizaje de lo que es un verbo. Aprende simplemente las palabras y las reglas del francés, transfiriendo los conceptos subyacentes. Esa es toda la potencia de este enfoque."
Camille: Por lo tanto, transfiere sus inmensos conocimientos generales, adquiridos durante el preentrenamiento, a la nueva tarea específica.
Luc: "Eso es exactamente así. Es por eso que puede convertirse en experta en sus datos con sorprendentemente poca información nueva, ya que se basa en cimientos extremadamente sólidos."
Camille: "Es lógico. Pero como discutimos en nuestro último episodio sobre los Transformers, una nueva aproximación más flexible está surgiendo, ¿no?"
Luc: "Sí, y esto es posible gracias a la expansión masiva de la memoria a corto plazo de la IA, o 'ventana de contexto'. Esta aproximación se denomina Aprendizaje en Contexto (ICL)."
Camille: "En lugar de volver a entrenar a la IA para especializarse, basta con darle la información precisa para cada tarea."
Luc: "Ha entendido todo perfectamente. Es como contratar a un brillante consultor y, en lugar de enviarlo a realizar un extenso programa de formación, simplemente proporcionarle los documentos informativos exactos que necesita para el proyecto actual."
Camille: Ahí es donde entra en juego el concepto de **"referenciación"**, que consiste en conectar las respuestas de la IA con la información específica que le proporcionas.
Luc: Exactamente. Pero esto nos lleva a un punto crucial que a menudo se malinterpreta: la forma en que la IA "recuerda" esta información. Es la diferencia entre un conocimiento temporal y una habilidad permanente.
Camille: La diferencia entre "bachoter" y "maîtriser".
Luc: ¡Una analogía perfecta! El aprendizaje en contexto es como hacer bachotaje. Los conocimientos que usted proporciona en el prompt son temporales, los usa para esta única conversación pero desaparecen una vez finalizada.
Camille: Olvida todo.
Luc: Ella olvida todo. Es por eso que es una memoria de uso único. Si quiero que recuerde la misma información mañana, debo darle nuevamente los documentos.
Camille: De acuerdo.
Luc: "Esta es la realidad del ICL. Es increíblemente flexible, pero se basa en la memoria a corto plazo. Por el contrario, el afinado tiene como objetivo crear una competencia permanente. Cuando afinamos un modelo, modificamos fundamentalmente su estructura interna. Los nuevos conocimientos se convierten en parte integral de su identidad."
Camille: ¿Entonces, los conocimientos adquiridos mediante afinamiento persisten en todas las conversaciones para siempre?
Luc: "Es como aprender a andar en bicicleta. La habilidad se ancla. No necesitas recordar las leyes del equilibrio cada vez que subes."
Camille: "Esto ilustra muy bien una experiencia común con los chatbots. Podemos tener una conversación extensa y detallada, pero si abrimos una nueva ventana o contexto de diálogo, la IA no tiene ni idea de lo discutido previamente."
Luc: "¡Exactamente! Esa es la esencia del aprendizaje en contexto. Todo el historial de nuestra conversación en esta sesión constituye el contexto."
Camille: Entiendo.
Luc: Cuando abres una nueva conversación, la IA vuelve a un estado inicial sin recordar lo discutido anteriormente. Su espacio de trabajo temporal simplemente se ha vaciado.
Camille: "Pero, ¿qué pasa con las nuevas funciones como la 'Memoria' que algunas IA están empezando a integrar? Da la impresión de que realmente están comenzando a recordar cosas de una sesión a otra."
Luc: "Es una excelente observación y es crucial entender cómo funciona. La IA no se perfecciona continuamente a través de nuestras interacciones. Sería increíblemente ineficaz."
Camille: "¿Entonces, es como un truco para recordar la información de una conversación a otra?"
Luc: "Se podría decir que estas funciones de memorización son una forma astuciosa de aprendizaje en contexto automatizado. Cuando empiezas una nueva conversación, el sistema busca rápidamente en tus intercambios anteriores la información relevante y luego inserta automáticamente estos extractos en la solicitud."
Camille: "Por lo tanto, da la impresión de que la IA recuerda los detalles de mi proyecto, pero en realidad solo le dimos una guía resumida justo antes de que comenzara a hablar con usted."
Luc: "Luc: Precisamente. El modelo no aprende ni evoluciona a partir de sus conversaciones. Simplemente utiliza un sistema inteligente para recordar el contexto anterior."
Camille: ¿Necesito un consultor temporal o un experto permanente?
Luc: Esta es la forma más adecuada de plantear el problema. Y tras esta reflexión, es momento de llegar a una conclusión.
Camille: ¡Gracias por escucharnos! Hasta el próximo episodio de "Tech Éclair".
