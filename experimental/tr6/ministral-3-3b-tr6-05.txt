Camille: Bonjour y bienvenido/a en *Tech Flash*, el podcast donde desglosamos la tecnología que moldea nuestro mundo.
Luc: Y soy **Luc. Hoy vamos a desvelar** la manera en que los modelos de IA que usamos a diario **aprenden y se vuelven tan inteligentes**.
Camille: Es un tema fascinante. A menudo las percibimos como **cajas negras**, pero su aprendizaje sigue un proceso muy real.
Luc: Exacto. Y este aprendizaje **empieza** con un proceso llamado el **« pre-entrenamiento »**.
Camille: El **preentrenamiento**.
Luc: Imaginen enviar una inteligencia artificial completamente nueva a la escuela para que aprenda los fundamentos del lenguaje, el razonamiento y el funcionamiento del mundo mediante la lectura de una gran cantidad de datos en Internet.
Camille: Por lo tanto, tras el pre-entrenamiento, la IA es como un joven graduado de la universidad: inteligente y competente, pero sin experiencia profesional específica.
Luc: **afinamiento**
Camille: ¿No es el **aprendizaje por transferencia** el momento en que interviene el **afinamiento**? Lo he escuchado antes.
Luc: Exactamente. El **aprendizaje por transferencia** es la clave. Veamos: no se enseñan las matemáticas básicas a un brillante físico antes de que inicie el estudio de la mecánica cuántica. Él transfiere sus conocimientos matemáticos previos. La IA hace lo mismo. Las lenguas son un excelente ejemplo.
Camille: ¿En qué se basa?
Luc: Podéis tomar un modelo experto en inglés y luego presentarle una cantidad mucho menor de texto en francés. Él aprenderá el francés a una velocidad increíble.
Camille: **¿No es que ya entiende los conceptos generales de gramática, sintaxis y estructura de frase por el conocimiento previo del inglés?**
Luc: Exactamente. **No necesita volver a aprender qué es un verbo. Aprende simplemente las palabras y las reglas del francés, transferiendo los conceptos subyacentes. Es toda el poder de esta aproximación.**
Camille: Así que **transfiere sus inmensas conocimientos generales adquiridos del pre-entrenamiento a la nueva tarea específica**.
Luc: *Exactamente. Es por eso que puede convertirse en experto en vuestros datos con sorprendentemente poca nueva información. No parte de cero; se basa en bases sólidas extremadamente bien establecidas.*
Camille: Es lógico. Pero, como hemos discutido en nuestro último episodio sobre los Transformers, una nueva aproximación más flexible está emergiendo, ¿no es así?
Luc: Esta aproximación se llama **aprendizaje contextual** (ICL).
Camille: En lugar de **reentrenar** la IA para convertirla en una especialista, simplemente le damos **la información que necesita para realizar la tarea**.
Luc: Has entendido todo. Es como contratar un consultor brillante y, en lugar de enviarlo a seguir un programa de formación de varios años, simplemente proporcionarle los documentos de información exactos que necesita para el proyecto en curso.
Camille: Es aquí donde interviene el concepto de **anclaje** (grounding), que consiste en vincular las respuestas de la IA a las **informaciones específicas** que proporcionas.
Luc: **Exactamente. Pero esto nos lleva a un punto clave que suele malinterpretarse: la forma en que la IA almacena estas informaciones. Es la diferencia entre un conocimiento temporal y una competencia permanente.**
Camille: La diferencia entre estudiar de forma intensiva para un examen y dominar realmente un tema.
Luc: El aprendizaje en contexto es como memorizar. Las **conocimientos que proporcionas en el prompt son temporales**. La IA las usa solo para esta única conversación, pero una vez terminada, **desaparecen**.
Camille: Todo se evapora de su memoria.
Luc: Todo se evapora de su memoria. Es, por tanto, una memoria de uso único. Si quiero que tenga conocimiento de las mismas informaciones mañana, debo proporcionarle de nuevo los documentos.
Camille: Sí.
Luc: Esta es la realidad de la **IA de contexto**: es increíblemente flexible, pero basada en una memoria a corto plazo. El afinamiento, en cambio, busca crear una competencia permanente. Cuando afinas un modelo, modificas fundamentalmente su estructura interna: las nuevas **conocimientos** se convierten en parte esencial de su identidad.
Camille: ¿Los conocimientos adquiridos mediante el afinamiento permanecen en todas las conversaciones, **eternamente**?
Luc: Sí. Es como aprender a montar en bicicleta. La habilidad está arraigada. No necesitas que te recuerden las leyes del equilibrio cada vez que subas en la silla.
Camille: Luc, esto explica una experiencia muy común con los chatbots. Se puede mantener una conversación larga y detallada, pero si se abre una nueva ventana de conversación, la IA no recuerda nada de lo anterior.
Luc: Exactamente. Es el aprendizaje en contexto en acción. La totalidad del historial de tu conversación en esta sesión **es** el contexto.
Camille: Lo entiendo.
Luc: Al abrir una nueva ventana, **reinicias un contexto vacío**. La IA no olvida: es una reinicialización de su espacio de trabajo temporal, no un olvido como el humano.
Camille: Pero, ¿qué hay de las nuevas capacidades como la **memoria**, que algunas IA empiezan a incorporar? Tenemos la sensación de que empiezan realmente a recordar las cosas **entre sesiones**.
Luc: Es una excelente observación, y es crucial entender cómo funciona. La IA no se afinar constantemente por vuestras conversaciones. Sería increíblemente ineficiente.
Camille: ¿No es una técnica?
Luc: Las funciones de memoria son una forma ingeniosa de aprendizaje en contexto automatizado. Cuando empiezas una nueva conversación, el sistema recopila rápidamente las informaciones más relevantes de tus intercambios anteriores y las integra automáticamente en tu solicitud, en el fondo.
Camille: Así, tenemos la sensación de que la IA recuerda los detalles de mi proyecto, pero en realidad, solo se le ha proporcionado un **resumen rápido** justo antes de que empiece a hablarte.
Luc: Precisamente. El modelo en sí no aprende ni se actualiza a partir de vuestras interacciones. Simplemente utiliza un sistema de recuperación de contexto para buscar información relevante en conversaciones anteriores.
Camille: Para quien use estos **herramientas**, la gran pregunta es: ¿Necesito un asesor temporal o un experto permanente?
Luc: Es la manera ideal de plantear el problema y, tras esta reflexión, es el momento de concluir.
Camille: Gracias por habernos escuchado, y hasta pronto para el próximo episodio de **«Tech Éclair»**!
