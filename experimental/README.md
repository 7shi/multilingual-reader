# ローカルLLM翻訳実験：推論レベル別性能分析と実用指針

フランス語からスペイン語にポッドキャストの翻訳を行い、Gemini 2.5 Flashによる客観評価を実施。構造化出力と推論レベルが翻訳品質に与える影響を体系的に分析しました。

## 実験の背景と設計思想

### 構造化出力による推論制御の理論的背景

**基本仮説**: スキーマフィールド順序でモデルの処理順序を制御できる

構造化出力のスキーマ設計により、`reasoning_level`パラメータ一つで翻訳手法を動的に切り替える柔軟なシステムを実装。モデルの思考プロセスを制御し、段階的な品質向上を実現することを目指しました。

### 多モデル協調による認知バイアス回避

**問題認識**: 同一モデルでの自己評価では認知バイアスにより見落としが発生

**解決アプローチ**:
- Phase 1: 基本モデルでの初回翻訳
- Phase 2: 別モデルでの客観的品質チェック  
- Phase 3: 基本モデルでの修正反映

異なるモデルの強みを統合的に活用し、単一モデルの限界を克服する設計。

### 評価手法の変遷と重要な発見

#### 初期評価（Claude Codeによる主観評価）
| 手法 | スコア | 改善幅 | 主要効果 |
|:---|:---:|:---:|:---|
| レベル0 (直接翻訳) | 65点 | - | ベースライン |
| レベル1 (推論付き) | 85点 | +20点 | 思考の連鎖 |
| レベル2 (2段階翻訳) | 93点 | +28点 | 自己品質チェック |

詳細👉[comparison/README.md](comparison/README.md)

#### 客観評価（Gemini 2.5 Flash）による結果の逆転
同じシステムをGemini 2.5 Flashの5項目評価で測定すると、全く異なる結果が判明：

**主観評価の問題点**:
- **複雑システムへの期待値バイアス**: 複雑な推論システムに対する主観的高評価
- **一貫性の欠如**: 評価者の個人的見解に依存
- **再現性の問題**: 同一システムでも評価が変動

**客観評価の優位性**:
- **5項目体系的評価**: 読みやすさ、流暢性、専門用語、文脈適応、情報完全性
- **複数回評価による信頼性**: 3回評価の中央値で評価ブレを排除
- **LLMによる一貫した基準**: 人間の主観を排除した客観的測定

#### 設計思想の根本的転換

**従来の仮説**:
```
複雑な推論システム → 高品質翻訳
```

**客観評価による新発見**:
```
適切なモデル選択 → シンプルな直接出力 = 最高効率
```

## 実験概要

### 評価システム
- **評価ツール**: [evaluate_translation.py](evaluate_translation.py) (Gemini 2.5 Flash使用)
- **評価基準**: 5項目各20点満点（計100点）👉[EVAL.md](EVAL.md)
  1. 読みやすさと理解しやすさ
  2. 流暢さと自然さ
  3. 専門用語の適切性
  4. 文脈適応性
  5. 情報の完全性
- **統計的信頼性**: 3回評価の中央値を使用（[aggregate_evaluations.py](aggregate_evaluations.py)）
- **評価結果**: [SCORES.txt](SCORES.txt)

## 評価システムの技術詳細

### evaluate_translation.py: 翻訳品質評価ツール

**概要**: Gemini 2.5 Flashを使用した5項目翻訳品質評価システム

**主な機能**:
- **5項目評価基準** (各20点満点、計100点)
  1. **読みやすさと理解しやすさ**: 目標言語読者の理解容易性
  2. **流暢さと自然さ**: ネイティブスピーカーにとっての自然性
  3. **専門用語の適切性**: 技術用語の正確性と一貫性
  4. **文脈適応性**: 原文の意図と文化的背景の適切な反映
  5. **情報の完全性**: 情報の欠落・追加なく簡潔明瞭な伝達

**使用方法**:
```bash
python evaluate_translation.py --original 原文.txt --translation 翻訳文.txt \
  -m gemini-2.5-flash-latest -f French -t Spanish -o 評価結果.json
```

**出力形式**: 各項目の詳細な推論と点数、総合評価コメント

### aggregate_evaluations.py: 評価結果集約ツール

**概要**: 複数回評価の統計的集約により信頼性の高い品質測定を実現

**主な機能**:
- **3回評価の自動検出**: `ファイル名-{1,2,3}.json`パターンを認識
- **統計値計算**: 中央値、平均値、標準偏差を項目別・総合別に算出
- **信頼性向上**: 評価のブレを統計的に補正

**使用方法**:
```bash
# 詳細表示
python aggregate_evaluations.py evaluation-*-*.json --verbose

# 簡潔表示（中央値のみ）
python aggregate_evaluations.py evaluation-*-*.json
```

**統計的意義**: 単発評価の主観的ブレを3回評価の中央値で排除し、客観的品質測定を実現

### 実験の実行とスコア取得方法
翻訳と評価の実行は`batch.sh`で一斉処理され、最終的にスコア集約まで自動化されています：

```bash
# 翻訳と評価を一斉実行
sh batch.sh
```

`batch.sh`では各翻訳結果に対して自動的に3回評価を実行し、統計的信頼性を確保しています。

### 翻訳システムの構成
- [translate.py](translate.py): 構造化出力による5段階推論レベル
- [translate4.py](translate4.py): 非構造化直接翻訳
- [translate5.py](translate5.py): 非構造化簡略推論
- [translate6.py](translate6.py): 非構造化詳細推論

### 凡例
- 表中のボールドは行ごとの最高点
- (t): `--translated-context`オプション（履歴に翻訳文のみ提供）
- (nt): `--no-think`オプション（reasoningモデルでの無効化）
  - Ollamaの制約により構造化出力利用時はreasoningが無効化され、(nt)と同様の効果

## 推論レベル別システム設計と実験スコア
[translate.py](translate.py)の `-r` オプションで推論レベル指定（すべて構造化出力）

| モデル | -r 0 | -r 1 | -r 2 | -r 3 | -r 4 |
|:---|:---:|:---:|:---:|:---:|:---:|
| **qwen3-4b** | **71** | 52 | 60 | 65 | 69 |
| **qwen3-14b** | 90 | 71 | **91** | 87 | 80 |
| **gemma2-9b** | **74** | 30 | 70 | 58 | 34 |
| **gemma3-4b** | 52 | 42 | 47 | **52** | 20 |
| **gemma3-12b** | **95** | 11 | 90 | 86 | 89 |
| **gemma3n-e4b** | 72 | 17 | **88** | 70 | 53 |
| **phi4 (14B)** | 82 | 80 | 81 | **83** | 74 |

- **レベル0（直接翻訳）**: 高性能モデルで最高性能を実現
- **レベル1（推論付き翻訳）**: 全モデルで大幅劣化（gemma3-12bとgemma3n-e4bでは壊滅的）
- **レベル2（2段階翻訳）**: 中・低性能モデルで改善効果が顕著
- **レベル3（推論付き2段階翻訳）**: レベル1とレベル2の統合だが、レベル2に比べて明確な改善が認められない
- **レベル4（推論付き2段階翻訳の分割）**: レベル3をクエリ分割実行するが、レベル3に比べて劣化傾向（コンテキスト分断の悪影響だと推測）

**結論**: レベル0/1は構造化出力を外して比較（tr4/tr6）、レベル3/4は明確な改善が認められないため調査対象から除外。

### レベル0: 直接翻訳
**特徴**: 最もシンプルな翻訳方式
```python
class Translation(BaseModel):
    translation: str = Field(description=f"Direct translation from {args.from_lang} to {args.to_lang}")
```

[translate.py](translate.py)の `--history` オプションでコンテキストに含める履歴数を指定（省略時のデフォルト値は5）

- 0-20は2回測定して変動を調査（他の項目もこの程度の変動はあると考えられる）

| モデル | 0-05 | 0-10 | 0-15 | 0-20-a | 0-20-b | 0-25 |
|:---|:---:|:---:|:---:|:---:|:---:|:---:|
| **qwen3-4b** | 60 | 55 | 61 | 56 | **62** | 45 |
| **qwen3-4b (t)** | 56 | 53 | 56 | 56 | **60** | 47 |
| **qwen3-14b** | **91** | 86 | - | 84 | **91** | - |
| **gemma2-9b** | 77 | **79** | - | 71 | 77 | - |
| **gemma3-4b** | 69 | **74** | - | 68 | 70 | - |
| **gemma3-12b** | 89 | 91 | - | **93** | 72 | - |
| **gemma3n-e4b** | 53 | 63 | - | 83 | **87** | - |
| **phi4** | 80 | **92** | - | 79 | 79 | - |

- **(t)効果**: テストしたのはqwen3-4bのみだが、改善は認められない
- **gemma3-12b**: 履歴20で変動が大きい
- **gemma3n-e4b**: 履歴20で大幅改善
- **phi4**: 履歴10で大幅改善（全体最高クラス）

**結論**: 履歴数はモデルの能力が許す範囲内でなるべく多い方が良い。

## コンテキスト履歴（--history）オプション詳細

### 概要
`--history N`オプションは過去N件の翻訳履歴をコンテキストとして提供し、対話の一貫性と翻訳品質を向上させます。

### 設定値と効果
- **デフォルト値**: `--history 5`（省略時）
- **推奨設定**: `--history 10`（中・低性能モデルで大幅改善）
- **履歴形式**: 原文と翻訳文の対訳形式でコンテキストに含める

### 実装詳細
```python
# 直前の5つ（またはN個）の翻訳結果をコンテキストとして追加
context_lines = []
if context_history:
    context_lines.append("Previous conversation context:")
    context_lines.append("")
    for ctx in context_history[-N:]:  # Nは--historyで指定
        context_lines.append(f"Original: {ctx['speaker']}: {ctx['original']}")
        context_lines.append(f"Translation: {ctx['speaker']}: {ctx['translation']}")
        context_lines.append("")
```

### モデル別効果
- **高性能モデル** (Gemma3 12B, Qwen3 14B): 改善効果限定的
  - 既に高い文脈理解力を持つため追加履歴の恩恵は小さい
- **中性能モデル** (Phi4 14B): **劇的改善（+12点）**
  - **優れたコンテキスト把握力**により過去の翻訳履歴から一貫性を学習
  - **翻訳の一貫性が大幅向上**し、高性能モデルを凌駕する性能を実現
- **低性能モデル** (Qwen3 4B): 顕著改善（+5点）
  - 履歴情報により翻訳品質が底上げされる

### 関連オプション
- `--translated-context`: 履歴に翻訳文のみを提供（対訳形式でなく）
  - 実験結果では一貫性がなく、通常の対訳形式が推奨

### レベル1: 推論付き翻訳
**特徴**: 5項目詳細推論（構文解析、文脈解釈、語彙選択、文化的配慮、翻訳根拠）
```python
class Translation(BaseModel):
    reasoning: str = Field(description="""Detailed translation reasoning process:
1. Syntactic analysis of the original text...
2. Contextual interpretation of speaker's intent...
3. Evaluation of translation options...
4. Consideration of cultural nuances...
5. Justification for final translation choices...""")
    translation: str = Field(description="Translation result")
```

| モデル | 1-05 | 1-10 | 1-15 | 1-20 | 1-25 |
|:---|:---:|:---:|:---:|:---:|:---:|
| **qwen3-4b** | 50 | 41 | 51 | **69** | 60 |
| **qwen3-4b (t)** | 50 | 58 | 57 | 58 | **71** |
| **qwen3-14b** | **85** | 82 | - | 82 | - |
| **gemma2-9b** | **64** | 46 | - | 40 | - |
| **gemma3-4b** | 42 | 34 | - | **54** | - |
| **gemma3-12b** | 2 | **5** | - | **5** | - |
| **gemma3n-e4b** | 55 | **56** | - | 39 | - |
| **phi4** | 8 | 15 | - | **69** | - |

- **(t)効果**: テストしたのはqwen3-4bのみだが、改善は認められない
- **指示複雑化による混乱**: 推論フィールドの強制により、多くのモデルで翻訳タスクへの集中力が阻害
  - **gemma3-12b, phi4**: 極端な品質劣化（モデルが完全に混乱）
  - **gemma3-4b**: 品質劣化が顕著
- **qwen3-14b**: 例外的に実用レベルを維持

**結論**: 複雑な指示を構造化制約の中でこなすのはモデルの能力を超えることが多く、壊滅的破綻を招くこともある。

### レベル2: 2段階翻訳
**特徴**: 直接翻訳後、推敲して翻訳文を生成する2段階翻訳
```python
class Translation(BaseModel):
    draft_translation: str = Field(description="First draft translation")
    quality_assessment: str = Field(description="Analyze translation for errors, mistranslations, language mixing...")
    improvement_suggestions: str = Field(description="Provide specific suggestions for improving quality")
    improved_translation: str = Field(description="Improved translation based on assessment")
```

| モデル | 2-05 | 2-10 | 2-15 | 2-20 | 2-25 |
|:---|:---:|:---:|:---:|:---:|:---:|
| **qwen3-4b** | 61 | **76** | 62 | 66 | 59 |
| **qwen3-4b (t)** | **71** | 35 | 61 | 63 | 68 |
| **qwen3-14b** | **92** | 89 | - | 88 | - |
| **gemma2-9b** | 65 | 79 | - | **82** | - |
| **gemma3-4b** | **51** | 41 | - | 41 | - |
| **gemma3-12b** | **90** | **90** | - | 82 | - |
| **gemma3n-e4b** | **90** | 78 | - | 65 | - |
| **phi4** | 82 | **94** | - | 77 | - |

- **(t)効果**: qwen3-4bで2-10が大幅劣化、(t)自体が不安定だと思われる
- **qwen3-14b**: 高い安定性能を維持
- **gemma3-12b**: レベル0に迫る高性能を実現
- **gemma3n-e4b**: 大幅な性能向上を達成
- **phi4**: 履歴10で大幅改善（全体最高クラス）

**結論**: 一定の品質は確認できたが、レベル0より改善しないと意味がないため、次で比較。

### 翻訳改善効果の検証（レベル0 vs レベル2）

レベル0（直接翻訳）とレベル2（2段階翻訳）の性能比較により、2段階翻訳による改善効果を検証

| モデル | 0-05 | 0-10 | 0-20-a | 0-20-b | 2-05 | 2-10 | 2-20 |
|:---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| **qwen3-4b** | 60 | 55 | 56 | 62 | 61 | **76** | 66 |
| **qwen3-14b** | 91 | 86 | 84 | 91 | **92** | 89 | 88 |
| **gemma2-9b** | 77 | 79 | 71 | 77 | 65 | 79 | **82** |
| **gemma3-4b** | 69 | **74** | 68 | 70 | 51 | 41 | 41 |
| **gemma3-12b** | 89 | 91 | **93** | 72 | 90 | 90 | 82 |
| **gemma3n-e4b** | 53 | 63 | 83 | 87 | **90** | 78 | 65 |
| **phi4** | 80 | 92 | 79 | 79 | 82 | **94** | 77 |

- **モデル性能の限界**: qwen3-14b, gemma3-12b, phi4は既にレベル0で高品質のため改善余地が少ない
- **qwen3-4b**: 2-10で大幅改善（ただし品質は高くない）
- **gemma3-4b**: レベル2は複雑な推論過程で混乱
- **gemma3n-e4b**: 2-05で大幅改善だが2-20で大幅劣化、処理速度から0-20が実用的と思われる

**結論**: 明確な差異が認められない場合、処理速度の観点からレベル0（直接翻訳）を優先。

### レベル3: 推論付き2段階翻訳

**特徴**: レベル1の推論とレベル2の2段階翻訳を統合
```python
class Translation(BaseModel):
    reasoning: str = Field(description="Detailed translation reasoning process...")
    draft_translation: str = Field(description="First draft translation")
    quality_assessment: str = Field(description="Analyze the draft translation for errors...")
    improvement_suggestions: str = Field(description="Provide specific suggestions...")
    improved_translation: str = Field(description="Based on the quality assessment...")
```
- **処理**: 推論→下訳→品質評価→改善提案→最終翻訳
- **利点**: 最も詳細な処理、全プロセス可視化
- **用途**: 研究目的、品質分析
- **実験結果**: レベル2に比べて明確な改善が認められない

### レベル4: 推論付き2段階翻訳の分割

**特徴**: レベル3を2つのステージに分割実行
```python
# 第1段階
class FirstStageTranslation(BaseModel):
    reasoning: str = Field(description="Detailed translation reasoning process...")
    draft_translation: str = Field(description="First draft translation")

# 第2段階
class SecondStageTranslation(BaseModel):
    quality_assessment: str = Field(description="Analyze the draft translation for errors...")
    improvement_suggestions: str = Field(description="Provide specific suggestions...")
    improved_translation: str = Field(description="Based on the quality assessment...")
```
- **処理**: ステージ1（推論+下訳）→ステージ2（品質評価+改善）
- **利点**: 段階的制御、メモリ効率化
- **用途**: 大規模翻訳、実験的処理
- **実験結果**: レベル3に比べて劣化傾向（コンテキスト分断の悪影響）

## 複雑な推論の逆効果メカニズム

客観評価により判明した、複雑推論による品質悪化の原因：

### 1. 翻訳選択肢の増加による混乱
- 推論プロセスで複数の翻訳候補を検討
- 選択肢が増えることで決定が不安定化
- 結果として一貫性のない翻訳が生成

### 2. 一貫性よりも局所最適化の優先
- 各段階で最適化を図るが全体最適を見失う
- 部分的な改善が全体品質を損なう
- フェーズ間での情報ロスが発生

### 3. 複雑な思考プロセスによる判断の不安定化
- 推論が深くなるほど迷いが生じる
- 自己評価による混乱が品質低下を招く
- シンプルな直接翻訳の方が安定した結果

## translate4.py: 非構造化直接翻訳による構造化制約の検証

構造化出力（translate.py -r 0）と非構造化出力（translate4.py）の直接翻訳性能を比較し、構造化制約の影響を検証しました。

### 核心的な発見

**構造化出力vs非構造化出力の比較実験**により、モデル特性に応じた個別最適化の重要性が判明：

| 推論方式 | 構造化出力 | 非構造化出力 | 性能差（例：Gemma3 12B, h05） |
|:---|:---|:---|:---|
| **直接翻訳** | レベル0: 89点 | translate4: 79点 | **-10点** |

### 重要な結論

1. **構造化出力の効果はモデル依存**: 全般的悪影響は存在せず、モデル・履歴数の組み合わせに強く依存
2. **個別最適化の重要性**: 画一的判断を避け、モデル特性に応じた設定が必要
3. **Reasoning制御の価値**: reasoning処理の制御が構造化出力制約よりも性能に大きく影響
4. **実行時安定性の考慮**: 評価スコアと実際の安定性が一致しない場合があり、実用性重視の選択が重要

**最適化戦略**: 
- **構造化出力優位**: Gemma3 12B、Gemma3 4B、Qwen3 14B（3/7モデル、43%）
- **非構造化出力優位**: Gemma2 9B、Gemma3n E4B、Phi4（3/7モデル、43%）
- **高得点での均衡**: 90点以上では構造化・非構造化が拮抗（各50%）

### 直接翻訳における構造化出力の影響調査（レベル0 vs tr4）

[translate.py](translate.py) の `-r 0` オプションで構造化出力、[translate4.py](translate4.py) で非構造化出力

| モデル | 0-05 | 0-10 | 0-20-a | 0-20-b | tr4-05 | tr4-10 | tr4-20 |
|:---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| **qwen3-4b** | 60 | 55 | 56 | **62** | 52 | 54 | 42 |
| **qwen3-14b** | 91 | 86 | 84 | **91** | 79 | 77 | 75 |
| **qwen3-4b (nt)** | - | - | - | - | **71** | 58 | 56 |
| **qwen3-14b (nt)** | - | - | - | - | 81 | **90** | 84 |
| **gemma2-9b** | 77 | 79 | 71 | 77 | **80** | 65 | 65 |
| **gemma3-4b** | 69 | **74** | 68 | 70 | 25 | 58 | 71 |
| **gemma3-12b** | 89 | 91 | 93 | 72 | 79 | **94** | 90 |
| **gemma3n-e4b** | 53 | 63 | 83 | **87** | 77 | 84 | 86 |
| **phi4** | 80 | 92 | 79 | 79 | 84 | 89 | **92** |
| **gpt-oss-20b** | - | - | - | - | **91** | 86 | 83 |

- **(nt)効果**: tr4での比較では、ntオプションにより明確な改善が認められる
  - Ollamaの制限により構造化出力はreasoningを無効化するため、レベル0（構造化出力）とtr4-ntはほぼ同等
- **gemma3-4b**: 構造化出力が明確に優位だが、出力崩壊による再試行が頻発
- **gemma3-12b**: レベル0（構造化出力）が優位
- **phi4**: 両方式で同等の高性能を達成
- **gpt-oss-20b**: 最高品質（tr4-05で91点）、実用的な性能レベルを確保

**結論**: モデル特性により異なるが、レベル0とtr4が同等な場合、パースの安定性からレベル0（構造化出力）を推奨。

## translate5.py: 自由記述式推論による構造化出力制約の検証

レベル1での壊滅的失敗（11点）の原因を特定するため、構造化出力の制約を除去した自由記述式推論実験を実施しました。

### 核心的な発見

**構造化 vs 非構造化推論の対比実験**により、同じ推論プロセスでも実装方法で劇的に性能が変わることを実証：

| 推論方式 | 構造化出力 | 非構造化出力 | 性能差 |
|:---|:---|:---|:---|
| **直接翻訳** | レベル0: 95点 | translate4: 79点 | **-16点** |
| **推論付き翻訳** | レベル1: 11点 | translate5: 93点 | **+82点** |

### 重要な結論

1. **構造化出力制約の有害性実証**: レベル1（11点）→ translate5（93点）の+82点改善
2. **推論プロセス自体の限界**: レベル0（95点）に対してtranslate5（93点）は-2点の軽微な劣化
3. **言語化によるオーバーヘッド**: 明示的分析が注意容量を圧迫し翻訳品質を阻害
4. **後付け説明方式の優位性**: 品質とのトレードオフを回避する設計原則を提示

**最終判断**: 翻訳タスクにおいては直接翻訳（レベル0）が最適解。推論プロセスは構造化制約下では有害、自由記述式では品質をほぼ維持するが、コストパフォーマンスで直接翻訳に劣る。

## translate6.py: 改良された自由記述式推論による比較実験

translate5.pyの推論プロンプトを改良し、レベル1との公平な比較を実現するバージョンです。

### 改造の目的

translate5.pyの初期実験では、推論内容がレベル1と異なっていたため、公平な比較ができませんでした。translate6.pyは以下の改良を実施：

1. **推論内容の統一**: translate.py -r 1と同じ5項目の詳細推論を実装
2. **翻訳選択肢の検討**: 重要語彙や慣用表現の翻訳オプション評価を追加
3. **根拠の明確化**: 最終的な翻訳選択の正当化プロセスを強化

### 改良された推論プロンプト

```
First, provide detailed translation reasoning covering:
1. Syntactic analysis of the original {args.from_lang} text (subject, predicate, object, modifiers, etc.)
2. Contextual interpretation of speaker's intent and emotional tone
3. Evaluation of {args.to_lang} translation options for key vocabulary and idiomatic expressions
4. Consideration of cultural nuances and appropriate register/politeness level
5. Justification for final {args.to_lang} translation choices and overall approach

Then provide your final translation on the last line.
```

### 実験の価値

translate6.pyにより、構造化出力制約の影響をより正確に測定し、レベル1との真の性能差を検証可能になります。特に「どのように翻訳するか」という視点を含む完全な推論プロセスの比較が実現されます。

### 推論付き翻訳における構造化出力の影響調査（レベル1 vs tr6）

[translate.py](translate.py) の `-r 1` オプションで構造化出力、[translate6.py](translate6.py) で非構造化出力

| モデル | 1-05 | 1-10 | 1-20 | tr6-05 | tr6-10 | tr6-20 |
|:---|:---:|:---:|:---:|:---:|:---:|:---:|
| **qwen3-4b** | 50 | 41 | **69** | 55 | 47 | 66 |
| **qwen3-14b** | 85 | 82 | 82 | 74 | **87** | 70 |
| **qwen3-4b (nt)** | - | - | - | 54 | 49 | **65** |
| **qwen3-14b (nt)** | - | - | - | **96** | 83 | 82 |
| **gemma2-9b** | 64 | 46 | 40 | 48 | 46 | **68** |
| **gemma3-4b** | 42 | 34 | 54 | **64** | 61 | 48 |
| **gemma3-12b** | 2 | 5 | 5 | 87 | **93** | 91 |
| **gemma3n-e4b** | 55 | 56 | 39 | **74** | 73 | 68 |
| **phi4** | 8 | 15 | 69 | 78 | **89** | 79 |
| **gpt-oss-20b** | - | - | - | **97** | 83 | 91 |

- **(nt)効果**: qwen3-14bはtr6で大幅改善（96点）
  - qwen3-4bでは効果が認められない、レベル1ともほぼ同等
- **gpt-oss-20b**: tr6-05で最高得点（97点、全実験最高記録）
- **gemma3-12b, phi4**: tr6で劇的改善（レベル1は壊滅的）
- **gemma3-4b, gemma3n-e4b**: tr6で大幅改善（ただし品質は高くない）

**結論**: レベル1は複雑な指示を構造化制約の中でこなすのはモデルの能力を超えることが多く、全体的にtr6が優位。

### 自由記述式推論比較（tr5 vs tr6）

[translate5.py](translate5.py) は簡略推論、[translate6.py](translate6.py) は詳細推論

| モデル | tr5-05 | tr5-10 | tr5-20 | tr6-05 | tr6-10 | tr6-20 |
|:---|:---:|:---:|:---:|:---:|:---:|:---:|
| **qwen3-4b** | 44 | 46 | 60 | 55 | 47 | **66** |
| **qwen3-14b** | 77 | 73 | 86 | 74 | **87** | 70 |
| **qwen3-4b (nt)** | 8 | 10 | 5 | 54 | 49 | **65** |
| **qwen3-14b (nt)** | 85 | 80 | 88 | **96** | 83 | 82 |
| **gemma2-9b** | **75** | 74 | 68 | 48 | 46 | 68 |
| **gemma3-4b** | **88** | 78 | 77 | 64 | 61 | 48 |
| **gemma3-12b** | **93** | 89 | 78 | 87 | **93** | 91 |
| **gemma3n-e4b** | **79** | 73 | 69 | 74 | 73 | 68 |
| **phi4** | 76 | 85 | **93** | 78 | 89 | 79 |
| **gpt-oss-20b** | 83 | 92 | 95 | **97** | 83 | 91 |

- **(nt)効果**: qwen3-4bはtr5で壊滅的劣化
  - 全体を通してreasoningの効果が唯一認められるケース（ただし低品質）
- **gpt-oss-20b**: tr5-20で優秀な性能（95点）、一貫して高品質
- **gemma2-9b**: tr5で大幅改善（ただし品質は高くない）
- **gemma3-4b**: tr5で大幅改善、軽量のため品質をあまり重視しない用途では一定の実用性

**結論**: tr5で明確な優位性が認められるのはgpt-oss-20b（95点）、gemma2-9b、gemma3-4bだが、実用レベルを満たすのはgpt-oss-20bのみ。


## 実験結果分析

## モデル別実用設定一覧

スコア変動を考慮し、85点以上を実用レベルの目安として設定。

| モデル | スコア | 設定 |
|:---|:---:|:---|
| **gpt-oss-20b** | 97 | tr6-05 |
| **gpt-oss-20b** | 95 | tr5-20 |
| **gpt-oss-20b** | 92 | tr5-10 |
| **gpt-oss-20b** | 91 | tr4-05, tr6-20 |
| **gpt-oss-20b** | 86 | tr4-10 |
| **qwen3-14b (nt)** | 96 | tr6-05 |
| **qwen3-14b** | 92 | 2-05 |
| **qwen3-14b** | 91 | 0-05, 0-20, -r 2 (2-05) |
| **qwen3-14b (nt)** | 90 | tr4-10 |
| **qwen3-14b** | 87 | tr6-10 |
| **qwen3-14b** | 85 | 1-05 |
| **gemma3-12b** | 95 | -r 0 (0-05) |
| **gemma3-12b** | 94 | tr4-10 |
| **gemma3-12b** | 93 | 0-20, tr5-05, tr6-10 |
| **gemma3-12b** | 90 | 2-05, 2-10 |
| **phi4** | 94 | 2-10 |
| **phi4** | 93 | tr5-20 |
| **phi4** | 92 | 0-10, tr4-20 |
| **phi4** | 89 | tr6-10 |
| **gemma3n-e4b** | 90 | 2-05 |
| **gemma3n-e4b** | 88 | -r 2 (2-05) |
| **gemma3n-e4b** | 87 | 0-20 |
| **gemma3-4b** | 88 | tr5-05 |

**実用レベル未達**: gemma2-9b（最高80点）、qwen3-4b（最高76点）

## 推奨モデルと設定

**注意**: Gemmaシリーズは用途にライセンス上の制約があります。

### CPU 実行環境
1. **gemma3n-e4b**:
   - **2-05**: 品質優先
   - **0-20**: 速度優先

2. **gemma3-4b**:
   - **tr5-05**: 語彙面がやや弱い印象

### GPU 実行環境
1. **gpt-oss-20b**
   - **tr6-05**: 品質優先（全実験最高スコア）、教育利用
   - **tr5-20**: 品質優先
   - **tr4-05**: 速度優先（reasoningがあるため他のモデルより遅い）

2. **qwen3-14b**
   - **tr6-nt-05**: 品質優先、教育利用
   - **0-20**: 速度優先

3. **phi4**
   - **2-10**: 品質優先
   - **0-10**: 速度優先

4. **gemma3-12b**
   - **0-10**: 速度優先（スコア変動を考慮した安定設定）
   - **tr4-10**: 品質優先
   - **tr6-10**: 教育利用

**教育利用**: レベル1とtr6の5項目推論（構文解析、文脈解釈、語彙選択、文化的配慮、翻訳根拠）は人間の翻訳思考プロセスに近く、語学学習に有用。

## まとめ

### 構造化出力の特性
1. **最低性能要件**: gemma3-4bでは出力が頻繁に破綻
2. **複雑指示の限界**: レベル1は多くのモデルで処理能力を超過
3. **Ollamaの制約活用**: 構造化出力時のreasoning自動無効化が有効に作用

### 最適化戦略
1. **高性能モデル**: レベル0（直接翻訳）で最高品質
2. **中性能モデル**: レベル2 + 適切な履歴設定で大幅改善
3. **低性能モデル**: 非構造化出力の活用を検討

### オプション効果の総括
**--translated-context (t)**:
- 効果が限定的かつ不安定、非推奨

**--no-think (nt)**:
- qwen3系で大幅な性能向上
- Reasoningモデルでの翻訳タスクには有効

## 実用システム構築の指針

### モデル選択の優先順位
1. **Qwenシリーズ**: 活発な開発、安定した品質
2. **Phiシリーズ**: 優れたコンテキスト活用能力
3. **Gemmaシリーズ**: ライセンス制約を考慮して選択

### パフォーマンス vs 品質のバランス
- **明確な差異がない場合**: 処理速度優先でレベル0を選択
- **品質重視**: モデル特性に応じた個別最適化
- **教育用途**: 推論プロセス可視化のためtr6を活用

### 実装時の注意点
1. **スコア変動の考慮**: 単一評価でなく複数回測定を推奨
2. **安定性重視**: 評価スコアと実際の運用安定性は必ずしも一致しない
3. **リソース効率**: 複雑なシステムが常に高品質とは限らない

## 結論

本実験により、「複雑な推論システム = 高品質翻訳」という従来仮説は客観評価により否定され、「適切なモデル選択 + シンプルな直接出力 = 最高効率」が実証されました。

構造化出力による推論制御は教育的価値は高いものの、実用翻訳においては：
- **高性能モデル**: シンプルな直接翻訳が最適
- **中・低性能モデル**: 適切なコンテキスト履歴活用により高性能モデルを凌駕可能

これらの知見は翻訳以外の言語タスク（文章要約、コード生成、創作支援）にも応用可能ですが、常に**シンプルな直接出力の有効性**を検証することが重要です。

## その他の実験ツール一覧

以下のPythonスクリプトは研究開発過程で作成された実験的ツールです。詳細な実装内容と評価結果については [OBSOLETE.md](OBSOLETE.md) を参照してください。

- **translate-exp.py**: サブコマンド方式の多段階翻訳システム（Phase 1/2/2a/3対応）
- **translate2.py**: 3段階多モデル翻訳 一気通貫版
- **translate3.py**: Phase 2a統合システム 一気通貫版（推奨）
- **draft_to_text.py**: JSON形式中間データからテキスト抽出ユーティリティ
- **analyze_2stage_diff.py**: 翻訳手法別品質差分析ツール

これらのツールは実験的性質が強く、客観的評価によりレベル0（直接翻訳）の圧倒的優位性が判明したため、研究記録として保持されています。
