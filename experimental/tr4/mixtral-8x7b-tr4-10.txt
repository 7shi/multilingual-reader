Camille: Hola y bienvenidos a «Tech Claridad», el podcast donde desentrañamos la tecnología que da forma a nuestro mundo. Soy Camille.
Luc: ¡Y soy Luc. Hoy, vamos a desvelar cómo es que los modelos de IA que utilizamos a diario aprenden y se vuelven tan inteligentes!
Camille: ¡Es un tema fascinante. A menudo se perciben a estas IA como cajas negras, pero su proceso de aprendizaje sigue un proceso bien real. (This is a fascinating topic. AI is often perceived as a black box, but its learning process follows a very real method.)
Luc: ¡Claro! Este aprendizaje comienza con un proceso llamado "pre-entrenamiento".
Camille: El preentrenamiento. (This is the step known as pre-training.)
Luc: ¡Imaginen que enviamos a una IA totalmente nueva a la escuela para darle una cultura general! Ella lee una cantidad masiva de datos en Internet para aprender los fundamentos del lenguaje, el razonamiento y el funcionamiento del mundo en general.
Camille: Entonces, después del pre-entrenamiento, la IA es como un joven graduado universitario: inteligente y capacitada, pero sin experiencia laboral específica.
Luc: ¡Claro! La etapa siguiente ha sido durante mucho tiempo el "afinamiento" (ajuste fino). Es como enviar a ese graduado a seguir una especialización. (Specifically. For a long time, the next step has been "tuning" (fine-tuning). It's like sending that graduate to pursue a specialization.)
Camille: ¡El ajuste fino... es allí donde entra en juego "el aprendizaje por transferencia"? Ya había escuchado ese término. (This is where "transfer learning" comes into play, right? I've heard that term before.)
Luc: ¡Claro! El aprendizaje por transferencia es la clave. Miren, ustedes no le enseñarían las matemáticas básicas a un físico brillante antes de que éste aborde la mecánica cuántica. Él transfiere sus habilidades matemáticas previas. La IA hace lo mismo. Los idiomas son un excelente ejemplo de ello.
Camille: ¡Es decir?
Luc: ¡Puedes tomar un modelo experto en inglés y presentarle una cantidad mucho menor de texto en francés. Aprenderá francés a una velocidad increíble!
Camille: ¿Es porque ya entiende los conceptos generales de gramática, sintaxis y estructura de frase gracias al inglés? (Is it because it already understands the general concepts of grammar, syntax, and sentence structure thanks to English?)
Luc: ¡Claro! No necesita volver a aprender qué es un verbo. Sencillamente, aprende las palabras y las reglas del francés, transfiriendo los conceptos subyacentes. ¡Esa es toda la potencia de este enfoque!
Camille: then, it transfers its vast general knowledge from pre-training to the new specific task. (Entonces, transfiere sus enormes conocimientos generales obtenidos durante el pre-entrenamiento a la nueva tarea específica.)
Luc: ¡Eso es exactamente así! Es por eso que puede volverse un experto en tus datos con sorprendentemente poca información nueva. No parte de cero; se basa en unas bases muy sólidas. (That's totally it. This is why it can become an expert in your data with astonishingly little new information. It doesn't start from scratch; it relies on extremely solid foundations.)
Camille: ¡Eso tiene sentido. Pero, como hablamos en nuestro último episodio sobre Transformers, una nueva approach más flexible está emergiendo, ¿verdad? (That makes sense. But as we discussed in our last episode on Transformers, a new, more flexible approach is emerging, isn't it?)
Luc: ¡Sí, y esto es posible gracias al gran aumento en la memoria a corto plazo de la IA, o «ventana de contexto». Este enfoque se denomina aprendizaje en contexto, o ICL (In-Context Learning).!
Camille: ¡Entonces, en lugar de volver a entrenar a la IA para especializarla, simplemente le proporcionamos la información que necesita para realizar la tarea! (Instead of re-training the AI to specialize it, we simply give it the information it needs to accomplish the task!)
Luc: ¡Lo has comprendido perfectamente! Es como contratar a un consultor brillante y, en lugar de enviarlo a seguir un programa de formación durante varios años, simplemente proporcionarle la información exacta que necesita para el proyecto en curso. (You have understood everything perfectly. It's like hiring a brilliant consultant and, instead of sending them to follow a multi-year training program, simply providing them with the exact information they need for the current project.)
Camille: ¡Es allí donde interviene el concepto de «ancraje» (grounding), que consiste en vincular las respuestas de la IA con información específica que proporcionas tú!
Luc: ¡Claro! Pero esto nos lleva a un punto crucial que a menudo se malinterpreta: la forma en que la IA «recuerda» esta información. Esta es la diferencia entre un conocimiento temporal y una habilidad permanente.
Camille: ¡La diferencia entre estudiar a vapor para un examen y dominar realmente un tema!? (The difference between cramming for an exam and truly mastering a subject?)
Luc: ¡Una analogía perfecta! El aprendizaje en contexto es como estudiar a vapor. Los conocimientos que proporcionas en el prompt son temporales. La IA los utiliza solo para esa única conversación, pero una vez terminada la conversación, esos conocimientos desaparecen. (Luc: Una analogía perfecta! El aprendizaje en contexto es como cramming. The knowledge you provide in the prompt is temporary. The AI uses it for this single conversation, but once the conversation is over, that knowledge disappears.)
Camille: Ella olvida todo. (She forgets everything.)
Luc: Ella olvida todo. Por lo tanto, es una memoria descartable. Si quiero que tenga conocimiento de la misma información mañana, debo proporcionarle nuevamente los documentos. (She forgets everything. So it's a one-time memory. If I want it to have knowledge of the same information tomorrow, I have to provide it with the documents again.)
Camille: ¡De acuerdo! (Okay.)
Luc: ¡Así es la realidad del ICL! Es increíblemente flexible, pero se basa en una memoria a corto plazo. La afinación, por otro lado, tiene como objetivo crear una habilidad permanente. Cuando afinas un modelo, modificas fundamentalmente su estructura interna. El nuevo conocimiento se convierte en parte integral de su identidad. (This is the reality of ICL! It's incredibly flexible, but based on short-term memory. Tuning, on the other hand, aims to create a permanent skill. When you tune a model, you fundamentally modify its internal structure. The new knowledge becomes an integral part of its identity.)
Camille: ¡Entonces, ¿las conocimientos adquiridos a través del ajuste persisten en todas las conversaciones, para siempre?](https://www.speakspanishonline.eu/)
Luc: ¡Sí! Es como aprender a andar en bicicleta. La habilidad está inculcada. No necesitas recordarte las leyes del equilibrio cada vez que te subes a la bicicleta. (Yes. It's like learning to ride a bike. The skill is ingrained. You don't need to remind yourself of the laws of balance every time you get on the bike.)
Camille: Luc, esto explica una experiencia muy común con los chatbots. Se puede tener una conversación larga y detallada, pero si se abre una nueva ventana de chat, la IA no tiene la más mínima idea de lo que se dijo antes. (Luc, this explains a very common experience with chatbots. You can have a long and detailed conversation, but if you open a new chat window, the AI has no clue about what was said before.)
Luc: ¡Claro! Eso es el aprendizaje en contexto en acción. Todo el historial de su discusión en esta sesión constituye el contexto. (Luc: Exactamente! That is contextual learning in action. The entire history of your discussion in this session constitutes the context.)
Camille: ¡Veo! (I see!)
Luc: ¡Cuando abres una nueva ventana, empiezas con un contexto en blanco! La IA no ha "olvidado" en el sentido humano; simplemente se ha vaciado su espacio de trabajo temporal. (When you open a new window, you start with a blank context! The AI hasn't "forgotten" in the human sense; its temporary workspace has simply been emptied.)
Camille: ¡Pero, ¿qué pasa con las nuevas características como la «Memoria» que algunas IAs están comenzando a integrar? Tiene la impresión de que realmente comienzan a recordar cosas de una sesión a otra. (But what about new features like "Memory" that some AIs are starting to integrate? It seems they really start to remember things from one session to another.)
Luc: ¡Es un excelente comentario, y es fundamental comprender cómo funciona. La IA no se está ajustando constantemente a través de tus conversaciones. Eso sería increíblemente ineficiente. (It's an excellent remark, and it is crucial to understand how this works. The AI isn't being constantly tuned by your conversations. That would be incredibly inefficient.)
Camille: ¡¿Es entonces un truco?!
Luc: ¡Podrías decir eso! Estas funciones de memorización son una forma ingeniosa de aprendizaje en contexto automatizado. Cuando comienzas una nueva conversación, el sistema busca rápidamente en tus intercambios anteriores la información que parece relevante para tu nueva consulta. Luego, inserta automáticamente estos extractos en el prompt, detrás de escena. (You could say that! These memorization functions are a cunning form of automated learning in context. When you start a new conversation, the system quickly searches your past exchanges for information that seems relevant to your new query. Then, it automatically inserts these extracts into the prompt, behind the scenes.)
Camille: Por lo tanto, da la impresión de que la IA recuerda los detalles de mi proyecto, pero en realidad solo le hemos proporcionado un pañuelo con notas justo antes de que comenzara a hablar con usted. (Then, it seems as if the AI remembers the details of my project, but in reality, we have only provided it with a crib sheet right before it starts talking to you.)
Luc: ¡Exactamente! El modelo en sí no aprende ni evoluciona a partir de sus discusiones. Simplemente utiliza un sistema más inteligente para recordar el contexto pasado.
Camille: then, the big question for anyone who uses these tools is: 'Do I need a temporary consultant or a permanent expert?' (Por lo tanto, la gran pregunta para cualquiera que use estas herramientas es: ¿Necesito un consultor temporal o un experto permanente?')
Luc: ¡Así es como se plantea perfectamente el problema! Y sobre esta reflexión, es hora de concluir. (This is the ideal way to present the problem. And on that note, it's time to conclude.)
Camille: ¡Gracias por habernos escuchado, y hasta pronto para el próximo episodio de 'Tech Éclair'! (Thank you for listening to us, and see you soon for the next episode of 'Tech Éclair'!)
