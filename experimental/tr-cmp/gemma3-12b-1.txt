Camille: Hola y bienvenidos a « Tech Éclair », el podcast donde explicamos la tecnología que moldea nuestro mundo. Soy Camille.
Luc: desenmascarar
Camille: se suelen percibir
Luc: Exactamente. Y este aprendizaje comienza con un proceso llamado 'pre-entrenamiento'.
Camille: El pre-entrenamiento
Luc: Imagina
Camille: Así que, después
Luc: Exactamente. Y durante mucho tiempo, la siguiente etapa ha sido el 'ajuste fino' (fine-tuning). Es como enviar a este graduado a realizar una especialización.
Camille: El ajuste fino
Luc: Precisamente. El aprendizaje por transferencia es la clave. Miren: no le enseñaríamos matemáticas básicas a un físico destacado antes de que se dedicara a la mecánica cuántica. Él transfiere sus conocimientos matemáticos existentes. La IA hace lo mismo.
Camille: ¿Qué quiere decir?
Luc: Puede usar un modelo experto en inglés y luego presentarle una cantidad mucho menor de texto en francés. Aprenderá francés a una velocidad increíble.
Camille: Porque ya comprende los conceptos generales de gramática, sintaxis y estructura de la oración gracias al inglés?
Luc: Exactamente. No necesita volver a aprender qué es un verbo; simplemente aprende las palabras y las reglas del francés, transfiriendo los conceptos subyacentes. Ese es el verdadero poder de este enfoque.
Camille: proveniente de
Luc: Exactamente. Es por eso que puede convertirse en un experto de sus datos con tan poca información nueva. No empieza de cero; se apoya en cimientos extremadamente sólidos.
Camille: ¿Es lógico. Pero como hablamos de ello en nuestro último episodio sobre los Transformers, una nueva aproximación más flexible está surgiendo, ¿verdad?
Luc: Sí, y es posible gracias a la expansión masiva de la memoria a corto plazo de la IA, o «ventana de contexto». Este enfoque se llama aprendizaje en contexto, o ICL (In-Context Learning).
Camille: Así que, en lugar de volver a entrenar la IA para convertirla en una especialista, simplemente le damos la información que necesita para realizar la tarea.
Luc: Lo ha comprendido todo
Camille: Es ahí donde entra en juego...
Luc: the difference between temporary knowledge and a permanent skill.
Camille: La diferencia entre memorizar para un examen y realmente dominar un tema?
Luc: ¡Una analogía perfecta! El aprendizaje en contexto es como aprender de memoria. Los conocimientos que le proporcionas en el prompt son temporales. La IA los utiliza para esta única conversación, pero una vez terminada la conversación, esos conocimientos desaparecen.
Camille: Ella lo olvida.
Luc: Ella lo olvida. Por lo tanto, es una memoria de un solo uso. Si quiero que tenga conocimiento de la misma información mañana, tengo que volver a proporcionarle los documentos.
Camille: Vale.
Luc: estructura interna
Camille: Entonces, ¿el conocimiento obtenido del ajuste fino permanece en todas las conversaciones, para siempre?
Luc: Sí. Es como aprender a montar en bicicleta. La habilidad está arraigada. No necesitas que te recuerden las leyes del equilibrio cada vez que te subes.
Camille: Esto explica
Luc: The entirety of your discussion
Camille: Ya veo.
Luc: Cuando abres una nueva ventana, comienzas con un contexto vacío. La IA no ha "olvidado" como un humano lo haría; su espacio de trabajo temporal simplemente se ha borrado.
Camille: Mémoire
Luc: Es un excelente comentario, y es crucial entender cómo funciona. La IA no se ajusta constantemente con tus conversaciones; sería increíblemente ineficiente.
Camille: ¿Es un truco?
Luc: listillo/a,
Camille: Entonces, tenemos la impresión de que la IA recuerda los detalles de mi proyecto, pero en realidad, simplemente le hemos dado una 'cheat sheet' justo antes de que empezara a hablarte.
Luc: ;translati
Camille: La gran pregunta
Luc: Es la manera ideal de plantear el problema. Y considerando esto, es hora de concluir.
Camille: Gracias por escucharnos, ¡y hasta pronto para el próximo episodio de ‘Tech Éclair’!
