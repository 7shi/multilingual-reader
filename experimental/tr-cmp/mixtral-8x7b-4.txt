Camille: Hola y bienvenidos al podcast 'Tecnología Iluminada'. Soy Camille. Aquí desentrañamos la tecnología que moldea nuestro mundo.
Luc: Hola, soy Luc. Hoy vamos a desvelar cómo aprenden y se vuelven tan inteligentes los modelos de IA que usamos a diario.
Camille: Es un tema fascinante. A menudo, la gente percibe a estas IAs como cajas negras, pero su aprendizaje sigue un proceso bien real.
Luc: Exactamente. Y este aprendizaje comienza con un proceso llamado 'preentrenamiento'.
Camille: el preentrenamiento
Luc: Imaginaos cómo una nueva IA lee y procesa una gran cantidad de datos en internet para adquirir los fundamentos del lenguaje, el razonamiento y el funcionamiento del mundo. Lee una cantidad masiva de datos en internet para aprender los fundamentos del lenguaje, el razonamiento y el funcionamiento del mundo en general."}''
Camille: Así, después del preentrenamiento, la IA es como un recién graduado de la université: inteligente y competente, pero sin experiencia profesional específica.
Luc: Precisamente. Y durante mucho tiempo, el paso siguiente ha sido 'el ajuste fino' (fine-tuning). Es como enviar a este graduado a seguir una especialización en un área específica o un entrenamiento adicional en una materia en particular.
Camille: El ajuste fino... ¿es allí donde entra en juego el aprendizaje por transferencia? Ya he oído hablar de este término.
Luc: Exactamente. El aprendizaje por transferencia es la clave. Veamos: no le enseñaría matemáticas básicas a un físico talentoso antes de que se enfrentara a la mecánica cuántica. Él transfiere sus habilidades matemáticas existentes. La IA hace lo mismo. Los lenguajes, por ejemplo, son un excelente ejemplo.
Camille: ¿Qué quiere decir?
Luc: Puede utilizar un modelo experto en inglés y, después, presentarle una cantidad mucho menor de texto en francés. Aprenderá francés a un ritmo sorprendente.
Camille: ¿Porque ya entiende los conceptos generales de gramática, sintaxis y estructura de frase gracias al conocimiento del inglés?
Luc: Exactamente. No necesita volver a aprender los conceptos de verbos, simplemente aprende las palabras y reglas del francés, transfiriendo los conceptos subyacentes. Esa es toda la potencia de este enfoque.
Camille: Por lo tanto, transfiere sus vastos conocimientos generales adquiridos durante el preentrenamiento (o entrenamiento previo) a la nueva tarea específica.
Luc: Eso es exactamente. Por eso se vuelve un experto en sus datos con sorprendentemente poca información adicional, ya que no parte de cero sino que aprovecha unas bases extremadamente sólidas.
Camille: Eso tiene sentido. Pero, como hablamos en nuestro último episodio sobre los Transformers, está emergiendo un nuevo enfoque más flexible, ¿verdad?
Luc: Sí, y está hecho posible por la expansión masiva de la memoria a corto plazo o 'ventana de contexto' de la IA. Este enfoque se denomina aprendizaje en contexto, o Aprendizaje en Contexto (ICL).
Camille: En su lugar, en lugar de volver a entrenar a la IA para especializarla, simplemente le proporcionamos la información que necesita para llevar a cabo la tarea. En este enfoque, se evita la necesidad de reentrenar la IA y, en su lugar, se confía en darle a la IA las herramientas y conocimientos específicos que necesita para realizar una tarea particular.
Luc: Lo has comprendido a la perfección. Es como contratar a un consultor brillante y, en lugar de enviarlo a un programa de formación durante varios años, simplemente proporcionarle los documentos de información exactos de que necesita para el proyecto.
Camille: Es aquí donde entra en juego el concepto de 'ancraje' (grounding), que consiste en vincular las respuestas de la IA a la información específica que usted provee.
Luc: Exactamente. Pero esto nos lleva a un punto clave que a menudo se malinterpreta: la forma en que la IA almacena o registra estas informaciones, lo que marca la diferencia entre un conocimiento temporal y una habilidad permanente.
Camille: ¿Cuál es la diferencia entre estudiar a última hora para el examen y realmente dominar un tema? Esto se refiere a la distinción entre repasar rápidamente para un examen y tener un conocimiento profundo y sólido sobre un tema.
Luc: Una analogía perfecta! Aprendizaje en contexto es como estudiar a última hora. Los conocimientos que proporcionas en el prompt son temporales y el IA los utiliza únicamente para esa conversación. Sin embargo, una vez terminada la conversación, esos conocimientos desaparecen y se olvidan.
Camille: Ellos o ellas olvidan todo lo que sabían.
Luc: Elimina todo. Por lo tanto, se trata de una memoria de único uso. Si quiero que tenga conocimiento de las mismas informaciones mañana, debo proporcionarle nuevamente los documentos.
Camille: Entendido.
Luc: Esta es la realidad del 'el ICL'. Es increíblemente flexible, pero basado en memoria a corto plazo. Por otro lado, el ajuste fino busca crear una competencia permanente. Cuando se ajusta un modelo, se modifica fundamentalmente su estructura interna. Las nuevas conocimientos se integran a su estructura, convirtiéndose en parte de su identidad.
Camille: ¿Persisten, entonces, los conocimientos adquiridos a través del ajuste fino en todas las conversaciones y para siempre?
Luc: Sí. Es como aprender a montar en bici. La habilidad se queda grabada. No necesitas que te recuerden los principios del equilibrio cada vez que te subes a la bicicleta.
Camille: Luc, se trata de una experiencia muy común al interactuar con chatbots. Puedes mantener una conversación larga y detallada, pero si inicias una nueva conversación, el sistema no recuerda nada de lo discutido anteriormente.
Luc: Exactamente, ¡eso es el aprendizaje en acción! La historia completa de su discusión durante esta sesión constituye el contexto.
Camille: ¡Ah, entiendo!
Luc: Cuando abres una nueva ventana, se reinicia el contexto para la nueva sesión. El sistema no ha 'olvidado' en el sentido humano de la palabra; simplemente, su espacio de trabajo temporal ha sido vaciado.
Camille: Pero, ¿qué pasa con las nuevas funciones como la 'Memoria' que algunas inteligencias artificiales comienzan a integrar? Realmente comienzan a recordar cosas de una sesión a otra.
Luc: Esa es una observación muy acertada, y es fundamental entender su funcionamiento. La IA no se perfecciona constantemente a través de sus conversaciones; sería increíblemente ineficaz.
Camille: ¡Entonces es así!
Luc: Podría decirse que sí. Estas funciones de memorización son una forma hábil de aprendizaje en contexto automatizado. Cuando comienza una nueva conversación, el sistema busca rápidamente en sus intercambios anteriores la información que parece pertinente para su nueva solicitud. Luego, inserta automáticamente estos extractos en el prompt tras bambalinas.
Camille: Por lo tanto, da la impresión de que la IA recuerda los detalles de mi proyecto, pero en realidad, solo le hemos proporcionado un resumen (o notas) antes de que comience a hablar contigo.
Luc: Precisamente. El modelo en sí no aprende ni evoluciona a partir de sus discusiones, sino que simplemente utiliza un sistema más inteligente para recuperar el contexto previo.
Camille: Por lo tanto, la gran pregunta para cualquier persona que use estas herramientas es: «¿Necesito un consultor temporal o un experto permanente?»
Luc: Esta es la mejor manera de plantear el problema. Y sobre este pensamiento, es hora de finalizar.
Camille: Gracias por escucharnos, hasta pronto en el siguiente episodio de Tech Éclair.
