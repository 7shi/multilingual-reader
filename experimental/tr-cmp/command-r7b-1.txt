Camille: ¡Hola y bienvenidos a «Tech Éclair», el podcast donde desciframos la tecnología que da forma a nuestro mundo.
Luc: ¡Y soy Luc. Hoy, vamos a descubrir cómo los modelos de IA que utilizamos en nuestro día a día aprenden y se vuelven tan inteligentes.
Camille: ¡Es un tema fascinante. A menudo, percibimos estas IA como cajas negras, pero su proceso de aprendizaje sigue siendo muy real.
Luc: ¡Y este aprendizaje comienza con un proceso llamado ‘preentrenamiento’.
Camille: ¡El preentrenamiento!
Luc: ¡Imaginemos que enviamos una IA completamente nueva a la escuela para darle cultura general. Lee una cantidad masiva de datos en Internet para aprender los fundamentos del lenguaje, del razonamiento y del funcionamiento del mundo en general.
Camille: ¡Por lo tanto, después del preentrenamiento, la IA es como un recién graduado universitario: inteligente y competente, pero sin experiencia laboral específica.
Luc: ¡Exacto. Y durante mucho tiempo, la siguiente etapa ha sido el 'ajuste fino' (fine-tuning). Esto es similar a enviar al graduado para una especialización.
Camille: ¡El ajuste fino... ¡Es aquí donde entra en juego el aprendizaje por transferencia! Ya había oído este término.
Luc: Exacto. El aprendizaje por transferencia es la clave. Mira esto: no enseñaría matemáticas básicas a un brillante físico antes de que se enfrente a la mecánica cuántica. Transfiere sus habilidades matemáticas existentes. La IA hace lo mismo. Las lenguas son un excelente ejemplo.
Camille: ¿Qué quiere decir?
Luc: ¡Puede tomar un modelo experto en inglés y luego presentarle una cantidad mucho menor de texto en francés. Aprenderá el francés increíblemente rápido.
Camille: Porque ya comprende los conceptos generales de gramática, sintaxis y estructura de oración gracias al inglés?
Luc: ¡Exacto. No tiene que volver a aprender qué es un verbo. Simplemente aprende las palabras y las reglas del francés, transfiriendo los conceptos subyacentes. Esta es toda la fuerza de este enfoque.
Camille: Por lo tanto, transfiere sus enormes conocimientos generales adquiridos en el pre-entrenamiento a la nueva tarea específica.
Luc: Eso es exactamente así. Por eso puede convertirse en un experto de sus datos con sorprendentemente poca información nueva. No empieza desde cero; se basa en fundamentos extremadamente sólidos.
Camille: Es lógico. Pero como lo mencionamos en nuestro último episodio sobre los Transformers, ¿verdad que está surgiendo un nuevo enfoque más flexible? ¿No?
Luc: Sí, y se debe a la expansión masiva de la memoria a corto plazo de la IA, o «ventana de contexto». Este enfoque se llama aprendizaje en contexto, o ICL (Aprendizaje In-Context).
Camille: ¡Por lo tanto, en lugar de volver a entrenar la IA para convertirla en una especialista, simplemente se le proporcionan las información que necesita para realizar su tarea.
Luc: ¡Usted lo ha entendido todo. Es como contratar a un consultor brillante y, en lugar de enviarlo a un programa de capacitación de varios años, simplemente proporcionarle los documentos informativos exactos que necesita para el proyecto actual.
Camille: ¡Ahí es donde entra en juego el concepto de « encaje » (enraizamiento), que consiste en vincular las respuestas de la IA con la información específica que usted proporciona.
Luc: Exactamente. Pero nos lleva a un punto crucial que a menudo se malinterpreta: la manera en que la IA 'se acuerda' de esta información. Es la diferencia entre conocimiento temporal y habilidad permanente.
Camille: ¿Cuál es la diferencia entre estudiar para un examen y dominar realmente un tema?
Luc: Aprendizaje contextual, es memoria de estudios. Los conocimientos que proporciona en el prompt son temporales. La IA los utiliza para esta única conversación, pero una vez la conversación termina, esos conocimientos desaparecen.
Camille: Ella olvida todo
Luc: Ella olvida todo. Esto es una memoria de uso único. Si quiero que tenga conocimiento de las mismas informaciones mañana, tengo que proporcionarle nuevamente los documentos.
Camille: De acuerdo.
Luc: Aquí está la realidad del aprendizaje contextual. Es increíblemente flexible, pero se basa en una memoria a corto plazo. El afinar, por otro lado, busca crear una competencia permanente. Cuando afinan un modelo, modifican fundamentally su estructura interna. Las nuevas competencias se convierten en parte integral de su identidad.
Camille: Entonces, ¿los conocimientos obtenidos gracias al afinar persisten en todas las conversaciones para siempre??
Luc: Sí. Es como aprender a montar en bicicleta. La habilidad está incorporada. No necesitas que te recuerde las leyes del equilibrio cada vez que montas.
Camille: ¡Luc! Esto explica una experiencia muy común con los chatbots. Podemos tener una conversación larga y detallada, pero si abrimos una nueva ventana de discusión, la IA no tiene idea de lo que se ha dicho anteriormente.
Luc: ¡Exacto! Es el aprendizaje en contexto en acción. Toda la historia de su conversación en esta sesión constituye el contexto.
Camille: ¡Entiendo.
Luc: Cuando abres una nueva ventana, empiezas con un contexto vacío. La IA no ha "olvidado" en el sentido humano; su espacio de trabajo temporal simplemente se ha vaciado.
Camille: Pero, ¿qué pasa con las nuevas características como la "Memoria" que algunos IA están empezando a integrar? Tenemos la impresión de que realmente comienzan a recordar cosas de una sesión a otra.
Luc: ¡Eso es una excelente observación y es crucial comprender cómo funciona. La IA no se perfecciona constantemente con sus conversaciones. Sería increíblemente ineficaz.
Camille: Entonces es un truco？
Luc: Se puede decir eso. Estas funciones de memorización son una forma inteligente de aprendizaje en contexto automatizado. Cuando begins una nueva conversación, el sistema rápidamente busca en tus antiguos intercambios las informaciones que parecen pertinentes para tu nueva solicitud. Después, automáticamente inserta estos fragmentos en el prompt, tras bambalinas.
Camille: ¡Por lo tanto, tiene la impresión de que la IA recuerda los detalles de su proyecto, pero en realidad, le dimos solo una guía rápida antes de comenzar a hablar con usted!
Luc: Precisamente. El modelo en sí mismo no aprende ni evoluciona a partir de sus conversaciones. Simplemente utiliza un sistema más inteligente para recordar el contexto pasado.
Camille: ¡Por lo tanto, la gran pregunta para cualquiera que utilice estas herramientas es: « ¿Necesito un consultor temporal o un experto permanente? »
Luc: ¡Esa es la forma ideal de plantear el problema. Y sobre esta reflexión, es tiempo de concluir.
Camille: ¡Gracias por escucharnos, y hasta pronto en el próximo episodio de « Tech Éclair»!
