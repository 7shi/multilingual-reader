Camille: Hola y bienvenidos a 'Tech Éclair', el podcast donde explicamos la tecnología que configura nuestro mundo. Soy Camille.
Luc: Y soy Luc. Hoy, vamos a explicar cómo los modelos de IA que usamos a diario aprenden y se vuelven tan inteligentes.
Camille: Es un tema fascinante. Frecuentemente percibimos a estos IAs como cajas negras, pero su aprendizaje sigue un proceso real.
Luc: Exacto. Y este aprendizaje comienza con un proceso llamado 'pre-entrenamiento' o 'entrenamiento previo', que es fundamental en el desarrollo de modelos de inteligencia artificial.
Camille: El entrenamiento previo.
Luc: Imaginad que enviamos una IA totalmente nueva a aprender los conceptos básicos, proporcionándole una educación general. Ella lee una cantidad masiva de datos en Internet para aprender los fundamentos del lenguaje, el razonamiento y el funcionamiento del mundo en general.
Camille: Entonces, después del pre-entrenamiento, la IA es como un recién graduado universitario: inteligente y competente, pero sin experiencia profesional específica.
Luc: Exactamente. Y durante mucho tiempo, la siguiente etapa ha sido el 'fine-tuning' o ajuste fino. Es como enviar a este graduado a especializarse.
Camille: El ajuste... ahí es donde entra en juego el 'aprendizaje por transferencia'. Ya he oído ese término. (Nota: El término 'aprendizaje por transferencia' es correcto, pero en algunos contextos, podría ser más común 'aprendizaje transferible' o simplemente 'transferencia de aprendizaje', dependiendo de la audiencia y el ámbito específico.)
Luc: Exactamente. El aprendizaje por transferencia es la clave. Más bien, no enseñarías las matemáticas básicas a un brillante físico antes de que aborde la mecánica cuántica. Él transfiere sus habilidades matemáticas existentes. La IA hace lo mismo. Los idiomas son un ejemplo excelente de esto.
Camille: ¿O sea?
Luc: Puedes tomar un modelo experto en inglés, luego presentarle una cantidad significativamente menor de texto en francés. Adquirirá el francés a un ritmo increíble.
Camille: Porque ya comprende los conceptos generales de gramática, sintaxis y estructura de la oración gracias al inglés.
Luc: Exacto. No necesita reaprender lo que es un verbo. Solo necesita aprender las palabras y las reglas del francés, transfiriendo los conceptos subyacentes. Esa es toda la fuerza de este enfoque.
Camille: Entonces, transfiere sus enormes conocimientos generales procedentes del entrenamiento previo a la nueva tarea específica.
Luc: Eso es absolutamente así. Por eso puede convertirse en un experto en tus datos con increíblemente poca información nueva. No comienza desde cero; se apoya en bases muy sólidas.
Camille: Es lógico. Pero como hemos discutido en nuestro último episodio sobre los Transformers, un nuevo enfoque más flexible está surgiendo, ¿no?
Luc: Sí, y es posible gracias a la expansión masiva de la memoria a corto plazo de la IA, o 'ventana de contexto'. Este enfoque se llama Aprendizaje en Contexto, o ICL (In-Context Learning). También se podría expresar de la siguiente manera manteniendo el término en inglés para mayor claridad técnica: 'Sí, y es posible gracias a la expansión masiva de la memoria a corto plazo de la IA, o ventana de contexto. Este enfoque se llama In-Context Learning (ICL) o Aprendizaje en contexto.'
Camille: Entonces, en vez de volver a entrenar a la IA para que se especialice, solo se le proporciona la información que necesita para realizar la tarea.
Luc: Usted lo ha entendido todo. Es como contratar a un consultor brillante y, en lugar de enviarlo a un largo programa de formación, proporcionarle directamente los documentos de información precisos que necesita para el proyecto en curso.
Camille: Es ahí donde entra en juego el concepto de 'anclaje' (grounding), que consiste en vincular las respuestas de la inteligencia artificial a la información específica que usted proporciona.
Luc: Exactamente. Pero esto nos lleva a un punto crucial que a menudo se entiende mal: la manera en que la IA recuerda esa información. Es la diferencia entre un conocimiento temporal y una habilidad permanente.
Camille: La diferencia entre empollar para un examen y dominar de verdad un tema.
Luc: Una analogía perfecta! El aprendizaje en contexto es como estudiar para un examen de manera intensiva pero temporal. Los conocimientos que proporcionas en el prompt son transitorios. La IA los utiliza solo para esta conversación, y una vez que termina, esos conocimientos se desvanecen.
Camille: Se olvida de todo.
Luc: Ella olvida todo. Es decir, es una memoria de uso único. Si quiero que ella tenga conocimiento de la misma información mañana, debo proporcionarle de nuevo los documentos.
Camille: De acuerdo.
Luc: Esta es la realidad de la ICL. Es increíblemente flexible, pero se basa en una memoria a corto plazo. El afinamiento, por otro lado, busca crear una competencia permanente. Cuando se afinan los modelos, se modifica fundamentalmente su estructura interna. Los nuevos conocimientos se convierten en parte integral de su identidad.
Camille: Entonces, ¿los conocimientos adquiridos a través del afinamiento permanecen en todas las conversaciones, siempre?
Luc: Sí. Es como aprender a montar en bicicleta. La habilidad queda consolidada. No necesitas que te recuerden las leyes del equilibrio cada vez que te subas a la bicicleta.
Camille: Luc, esto explica una experiencia habitual con los chatbots. Se puede tener una conversación larga y detallada, pero si se inicia una nueva conversación, la IA no tiene idea de lo que se dijo anteriormente.
Luc: Exacto! Esto es el aprendizaje en contexto. Toda la historia de su discusión en esta sesión constituye el contexto.
Camille: Veo.
Luc: Cuando abres una nueva ventana, empiezas con un contexto vacío. La IA no ha 'olvidado' en el sentido humano del término; su área de trabajo temporal simplemente se ha vaciado.
Camille: Pero ¿qué pasa con las nuevas características como la 'Memoria' que algunas IAs empiezan a incorporar? Da la sensación de que realmente empiezan a acordarse de las cosas de una sesión a otra.
Luc: Es una excelente observación, y es crucial entender cómo funciona esto. La IA no se perfecciona constantemente mediante tus conversaciones. Eso sería increíblemente ineficiente.
Camille: Es entonces un truco ?
Luc: Se puede decir eso. Estas funciones de memorización son una forma inteligente de aprendizaje automatizado en contexto. Cuando comienzas una nueva conversación, el sistema busca rápidamente en tus intercambios anteriores la información que parece relevante para tu nueva solicitud. Luego, inserta automáticamente esos fragmentos en la solicitud, entre bastidores.
Camille: Entonces, parece que la IA se acuerda de los detalles de mi proyecto, pero en realidad, solo le hemos proporcionado una especie de chuleta justo antes de que empiece a hablar con usted.
Luc: Precisamente. El modelo en sí mismo no aprende ni evoluciona a partir de tus conversaciones. Utiliza simplemente un sistema más inteligente para recordar el contexto previo.
Camille: Entonces, la gran pregunta para quien utiliza estas herramientas es: '¿Necesito un consultor temporal o un experto permanente?' podría mejorarse a: 'Entonces, la gran pregunta para cualquiera que utilice estas herramientas es: '¿Necesito un consultor temporal o un experto permanente?''.
Luc: Es la manera ideal de plantear el problema. Y sobre esta reflexión, llega el momento de concluir.
Camille: Gracias por escucharnos, y nos vemos pronto para el próximo episodio de 'Tech Éclair'!
