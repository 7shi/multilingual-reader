Camille: Hola y bienvenidos a 'Tech Éclair', el podcast donde desciframos la tecnología que moldea nuestro mundo. Soy Camille.
Luc: Y yo soy Luc. Hoy vamos a levantar el velo sobre la forma en que los modelos de IA que utilizamos diariamente aprenden y se vuelven tan inteligentes.
Camille: Es un tema fascinante. A menudo consideramos estas IA como cajas negras, pero su aprendizaje sigue un proceso muy real.
Luc: Exactamente. Y este aprendizaje comienza con un proceso llamado «entrenamiento previo».
Camille: El preentrenamiento
Luc: Supongamos que enviamos una IA completamente nueva a la escuela para darle conocimientos generales. Lee un volumen masivo de información en Internet para aprender los fundamentos del lenguaje, el razonamiento y cómo funciona el mundo en general.
Camille: Entonces, después del pre-entrenamiento, la IA es como un recién graduado universitario: inteligente y competente pero sin experiencia laboral específica.
Luc: Justamente. Y durante mucho tiempo, el siguiente paso ha sido la "puesta a punto". Es como enviar a nuestro joven diplomado para seguir una especialización.
Camille: ¿Entonces, ¿es en el afinamiento donde entra el 'aprendizaje por transferencia'? Ya he escuchado ese término.
Luc: Exactamente. El aprendizaje por transferencia es la clave. Considera esto: no enseñarías matemáticas básicas a un destacado físico antes de que se ocupe de mecánica cuántica. Él transfiere sus habilidades matemáticas existentes. La IA funciona de manera similar. Los idiomas son un excelente ejemplo.
Camille: ¿A qué te refieres?
Luc: Puede emplear un modelo especialista en inglés y luego exponerle una cantidad mucho menor de texto en francés. Aprenderá el francés a una velocidad sorprendente.
Camille: ¿Es porque ya tiene conocimiento sobre los fundamentos lingüísticos gracias al inglés?
Luc: Exactamente. Aprende las palabras y reglas del francés, transfiriendo los conceptos subyacentes en lugar de volver a aprender lo que es un verbo. Ese es todo el poder de este método.
Camille: Entonces, transfiere su extenso conocimiento previo adquirido durante el pre-entrenamiento a la nueva tarea específica.
Luc: Así es. Es por esto que puede convertirse en un experto de sus datos con asombrosamente pocos datos nuevos. No parte de cero, se apoya sobre una base sumamente robusta.
Camille: Es lógico. Como discutimos en nuestro último episodio sobre los Transformers, un nuevo enfoque más flexible está surgiendo, ¿no es así?
Luc: Sí, y es posible gracias a la expansión masiva de la memoria a corto plazo de la IA, o 'ventana de contexto'. Este enfoque se llama aprendizaje en contexto, o ICL (In-Context Learning).
Camille: Por lo tanto, en lugar de reentrenar la IA para convertirla en una especialista, simplemente se le proporciona la información necesaria para llevar a cabo la tarea.
Luc: Has entendido perfectamente. Es como contratar a un consultor brillante y, en vez de mandarlo a realizar un programa de capacitación de varios años, simplemente proporcionarle la información específica necesaria para el proyecto actual.
Camille: Ahí es donde entra el concepto de 'fondeo' (grounding), que consiste en vincular las respuestas de la IA a la información específica que proporciona.
Luc: Exactamente. Pero esto nos lleva a un punto crucial que es a menudo mal entendido: la manera en que la IA retiene esta información. Se trata de la diferencia entre un conocimiento temporal y una habilidad permanente.
Camille: ¿La diferencia entre repasar intensamente para un examen y dominar realmente un tema?
Luc: ¡Una analogía perfecta! Aprender en contexto es como estudiar intensamente para un examen. La información que se proporciona en el prompt es temporal. La IA la utiliza solo para esta conversación única, pero una vez finalizada la conversación, esta información desaparece.
Camille: Ella olvida todo
Luc: Olvída todo. Por lo tanto, es una memoria de un solo uso. Si quiero que tenga conocimiento de la misma información mañana, debo proporcionarle los documentos nuevamente.
Camille: De acuerdo.
Luc: Así es la realidad del AIC (Aprendizaje Interactivo Contextual). Es increíblemente flexible, pero se basa en una memoria de corto plazo. El fine-tuning, por otro lado, tiene como objetivo crear habilidades permanentes. Cuando ajustas finamente un modelo, modificas fundamentalmente su estructura interna. Los nuevos conocimientos se vuelven parte integral de su identidad.
Camille: Entonces, ¿el conocimiento resultante del fine-tuning persiste en todas las conversaciones, para siempre?
Luc: Sí. Es como aprender a andar en bicicleta. Una vez adquirida la habilidad, se vuelve permanente. No necesita que alguien le recuerde las leyes del equilibrio cada vez que se sube a la bicicleta.
Camille: Luc, esto explica una experiencia muy común con los chatbots. Se puede tener una conversación larga y detallada, pero si se abre una nueva ventana de conversación, no recuerda nada de la conversación anterior.
Luc: ¡Exactamente! Es el aprendizaje contextual en acción. La totalidad del historial de la discusión en la presente conversación constituye el contexto.
Camille: Veo.
Luc: ¿Qué sucede cuando abres una nueva ventana? Comienzas con un contexto vacío. El IA no 'olvida' en el sentido humano de la palabra; su espacio temporal de trabajo simplemente se ha limpiado.
Camille: Pero, ¿qué hay de las nuevas funcionalidades como la Memoria que ciertas IA comienzan a incorporar? Da la impresión de que realmente empiezan a recordar detalles entre diferentes sesiones.
Luc: Esta es una excelente observación y es crucial entender cómo funciona esto. La IA no está constantemente refinada por sus conversaciones. Eso sería increíblemente ineficiente.
Camille: ¿Entonces es un truco?
Luc: Se puede decir eso. Estas funcionalidades de almacenamiento son una forma inteligente de aprendizaje en contextos automatizados. Cuando comienzas una nueva conversación, el sistema busca rápidamente en tus intercambios anteriores la información que parece relevante para tu nueva solicitud. Luego, inserta automáticamente estos fragmentos en el encadenamiento (la entrada de usuario a la IA) detrás de escena.
Camille: Por lo tanto, tengo la impresión de que la inteligencia artificial recuerda los detalles de mi proyecto, pero en realidad, simplemente se le ha proporcionado un apunte antes de empezar a hablar contigo.
Luc: Específicamente. El propio modelo no aprende ni evoluciona a partir de sus discusiones. Sencillamente emplea un sistema más inteligente que recuerda el contexto anterior.
Camille: Entonces, la gran pregunta para cualquiera que utilice estas herramientas es: ¿Necesito un consultor temporal o un experto permanente?
Luc: Esa es la forma perfecta de abordar el tema. Dicho esto, ha llegado el momento de concluir.
Camille: ¡Muchas gracias por escucharnos y hasta pronto para el próximo episodio de 'Tech Éclair'!
