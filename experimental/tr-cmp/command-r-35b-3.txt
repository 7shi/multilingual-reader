Camille: Hola y bienvenidos a "Flash Tech", el pódcast en el que analizamos la tecnología que está moldeando nuestro mundo. Estoy aquí, Camille.
Luc: Y yo soy Luc. Hoy vamos a revelar gradualmente cómo los modelos de IA que utilizamos diariamente aprenden y se vuelven tan inteligentes.
Camille: Es un tema realmente fascinante. A menudo percibimos estas IA como sistemas enigmáticos, pero su proceso de aprendizaje sigue una lógica muy real y tangible.
Luc: Exacto. Y este aprendizaje comienza con un proceso llamado el "pre-entrenamiento".
Camille: El pre-entrenamiento.
Luc: Imaginemos que enviamos una recién creada IA al colegio para proporcionarle educación general. Lee gran cantidad de información en línea sobre el lenguaje, el razonamiento y cómo funciona nuestro mundo.
Camille: Así que después del pre-entrenamiento, la IA es como un estudiante recién graduado: inteligente y capacitado, pero sin experiencia laboral específica.
Luc: Precisamente. Y por largo tiempo, la siguiente etapa fue el "ajuste fino" (afinamiento detallado). Es como enviar a este graduado a una especialización.
Camille: “El afinamiento... ¿es allí cuando se produce el 'aprendizaje por transferencia'? Creo haber escuchado ese término antes.”
Luc: Exactamente. El aprendizaje por transferencia es la clave. Considera esto: no le enseñarías matemáticas básicas a un brillante físico antes de que se aventure en la mecánica cuántica. Transfiere sus habilidades matemáticas existentes, al igual que la IA, quien también lo hace con las lenguas, un excelente ejemplo.
Camille: ¿A qué te refieres exactamente?
Luc: Puedes tomar un modelo especializado en inglés y luego presentarle una cantidad mucho menor de texto en francés. Aprenderá francés a una velocidad increíble (un modelo experto en procesar el idioma inglés).
Camille: ¿Porque él comprende ya los conceptos generales de gramática, sintaxis y estructura de oraciones gracias al inglés?
Luc: Exactamente. No necesita volver a aprender lo que es un verbo; simplemente aprende las palabras y reglas del francés, transfiriendo los conceptos subyacentes. Es allí donde reside toda la potencia de este enfoque.
Camille: Por lo tanto, él transfiere sus conocimientos generales enormes adquiridos en el preentrenamiento hacia la nueva tarea específica.
Luc: Es exactamente eso. Por eso puede convertirse en un experto de sus datos con sorprendentemente poca información nueva. No parte de cero; se basa en una base extremadamente sólida.
Camille: Tiene sentido. Pero como discutimos en nuestro último episodio sobre los Transformadores, una nueva aproximación más flexible está surgiendo, ¿verdad?
Luc: Sí, y es posible gracias a una expansión abrumadora de la memoria a corto plazo de la IA (o "ventana de contexto"). Este enfoque revolucionario se llama aprendizaje en contexto (In-Context Learning [ICL]).
Camille: Por lo tanto, en lugar de reiniciar el entrenamiento de la IA para especializarla, le damos simplemente la información que necesita para realizar la tarea.
Luc: Lo has entendido todo. Es como contratar a un consultor brillante y, en lugar de hacerle seguir un extenso programa de formación, simplemente proporcionarle los documentos informativos exactos que necesita para el proyecto actual.
Camille: Ahí es donde entra en juego el concepto de "anclaje" (grounding), que consiste en vincular las respuestas del IA a la información específica que usted proporciona.
Luc: Exactamente. Pero esto nos lleva a un punto crucial que a menudo se malinterpreta: la forma en que la IA « almacena información » temporalmente, diferenciándola de una habilidad permanente.
Camille: ¿Cuál es la diferencia entre 'estudiar de memoria' para un examen y dominar realmente el tema?
Luc: ¡Una analogía perfecta! El aprendizaje en contexto es como estudiar de memoria para un examen. Los conocimientos que proporcionas en el prompt son temporales. La IA los utiliza solo durante esta conversación, pero al finalizarla, esos conocimientos desaparecen. Es diferente a una habilidad permanente que se desarrolla y se retiene.
Camille: Ella lo olvida todo.
Luc: Ella lo olvida todo. Por consiguiente, es una memoria de uso único. Si deseo que tenga conocimiento de la misma información al día siguiente, tendré que proporcionarle nuevamente los documentos.
Camille: ¡Claro!
Luc: Esa es la realidad del ICL. Es increíblemente flexible, pero se basa en una memoria a corto plazo. El afinado, por otro lado, apunta a crear una habilidad permanente. Cuando afinas un modelo, modificas esencialmente su estructura interna. Las nuevas habilidades o conocimientos se convierten en parte integral de su identidad interna.
Camille: Él así, los conocimientos de la afinación persisten para siempre en cualquier conversación.
Luc: Sí, es como aprender a andar en bicicleta. La habilidad se queda grabada, no necesitas que te recuerden las leyes del equilibrio cada vez que te subas al sillín.
Camille: Luc, esto explica una experiencia muy frecuente con los chatbots. Podemos tener una conversación larga y detallada, pero si abrimos una nueva pestaña de conversación, la IA no sabe nada de lo que se dijo anteriormente.
Luc: ¡Exactamente! El aprendizaje contextual entra en acción. La totalidad de la conversación que han mantenido hasta ahora en esta sesión constituye el contexto global, permitiendo así una retención consistente del conocimiento a lo largo de múltiples sesiones.
Camille: Lo veo.
Luc: Cuando abres una nueva ventana, inicias con un contexto en blanco. La IA no olvida como lo haríamos nosotros; su espacio de trabajo temporal se ha borrado.
Camille: ¿Qué hay de las innovadoras funciones como la «Memoria» que algunas IA están incorporando? Realmente da la sensación de que empiezan a recordar cosas de una sesión a otra.
Luc: ¡Es una observación excelente! Es crucial comprender cómo funciona esto. La IA no se refina constantemente con tus conversaciones. Sería sumamente ineficiente.
Camille: ¿Es un secreto bien guardado?
Luc: Se puede decir así. Estas funciones de memoria son una forma astuta de aprendizaje en contexto automatizado. Cuando inicias una nueva conversación, el sistema busca rápida y automáticamente la información relevante de tus intercambios anteriores que pueda ser útil para tu nueva consulta. Luego, inserta estos extractos en segundo plano.
Camille: De hecho, da la impresión de que la IA recuerda los detalles de mi proyecto, pero en verdad solo se le ha dado una pista justo antes de comenzar a hablar contigo.
Luc: Precisamente. El modelo no aprende ni se desarrolla a partir de sus conversaciones; en cambio, utiliza una forma más sofisticada para recordar el contexto anterior: un sistema de memoria contextual automatizada.
Camille: La cuestión importante para cualquiera que utilice estos sistemas es: « ¿Es necesario un consultor temporal o un experto permanente? »
Luc: Es la forma ideal de plantear el problema. Y con esta reflexión, es hora de finalizar por hoy.
Camille: Gracias por prestarnos atención y hasta la próxima en el siguiente episodio de « Tech Éclair » !
