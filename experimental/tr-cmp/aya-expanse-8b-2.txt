Camille: ¡Hola y bienvenido a 'Tech Éclair', el podcast donde desciframos la tecnología que moldea nuestro mundo. Yo soy Camille!
Luc: Y yo soy Luc. Hoy vamos a desvelar cómo los modelos de inteligencia artificial que usamos a diario aprenden y desarrollan tal nivel de inteligencia.
Camille: Es un tema fascinante. A menudo percibimos a estas IA como entidades opacas, pero su proceso de aprendizaje sigue un procedimiento muy tangible y medible.
Luc: ¡Exactamente. Y este aprendizaje comienza con un proceso llamado 'pre-entrenamiento'!
Camille: El pre-entrenamiento
Luc: Imaginen que enviamos a una IA recién creada a la escuela para dotarla de cultura general. Lee enormes cantidades de datos en Internet para aprender los cimientos del lenguaje, el razonamiento y cómo funciona el mundo en general.
Camille: Por lo tanto, tras el pre-entrenamiento, la IA es como un joven graduado universitario: inteligente y capaz, pero sin experiencia profesional específica.
Luc: Precisamente. Y durante largo tiempo, la siguiente fase ha sido el 'ajuste fino' (fine-tuning). Similar a cuando enviamos a un graduado universitario a realizar una especialización para adquirir experiencia práctica en su campo.
Camille: El afinamiento... es ahí donde interviene ‘el aprendizaje por transferencia’. Ya he oído este término.
Luc: Exactamente. El aprendizaje por transferencia es la clave. Imaginen que no se enseñarían matemáticas básicas a un físico brillante antes de que abordara la mecánica cuántica. Él transfiere sus habilidades matemáticas existentes. La IA hace lo mismo con los idiomas.
Camille: ¿En qué sentido?
Luc: Puedes tomar un modelo experto en inglés y luego exponerlo a una cantidad mucho menor de texto en francés. El modelo aprenderá francés a una velocidad sorprendente.
Camille: ¿Porque ya comprende los conceptos generales de gramática, sintaxis y estructura de oraciones gracias a su conocimiento del inglés?
Luc: Exactamente. No necesita volver a aprender lo que es un verbo. Simplemente aprende las palabras y las reglas del francés, transfiriendo los conceptos subyacentes. Esa es toda la potencia de este enfoque.
Camille: Por lo tanto, transfiere sus inmensos conocimientos generales obtenidos durante su preentrenamiento a esta nueva tarea específica.
Luc: Es exactamente así. Es por eso que puede convertirse en un experto en sus datos con sorprendentemente pocas informaciones nuevas. No parte desde cero; se basa en cimientos extremadamente sólidos.
Camille: ¿Es lógico? Pero como discutimos en nuestro último episodio sobre los Transformers, un nuevo enfoque más flexible está surgiendo, ¿verdad?
Luc: Sí, y esto es posible gracias a la expansión masiva de la memoria a corto plazo de la IA, o «ventana de contexto». Este enfoque se conoce como aprendizaje en contexto, o ICL (Aprendizaje en Contexto).
Camille: Por tanto, en lugar de volver a entrenar a la IA para convertirla en una experta, simplemente se le ofrecen los datos que requiere para llevar a cabo la tarea.
Luc: Ha comprendido todo a la perfección. Es como contratar a un consultor altamente calificado y, en lugar de enviarlo a un extenso programa de capacitación, proporcionarle simplemente los documentos con la información exacta que requiere para el proyecto en cuestión.
Camille: Ahí es donde interviene el concepto de «anclaje», que consiste en relacionar las respuestas de la IA con la información específica que usted ofrece.
Luc: Exactamente. Sin embargo, esto nos lleva a un aspecto fundamental que a menudo se malinterpreta: la manera en que la Inteligencia Artificial 'recuerda' estos datos. Esta distinción marca la diferencia entre el conocimiento efímero y la competencia duradera.
Camille: La diferencia entre copiar para un examen y dominar realmente un tema radica en que, mientras el primer método implica memorizar información a corto plazo, el segundo implica comprender y retener conceptos de manera duradera.
Luc: ¡Una analogía perfecta! El aprendizaje contextual es similar a copiar para un examen. Los conocimientos que ofreces en la solicitud son temporales; la IA los utiliza para esta conversación específica, pero una vez finalizada, esa información desaparece.
Camille: Ella olvida todo.
Luc: Ella olvida todo. Por lo tanto, su memoria es de uso único. Si deseo que recuerde la misma información al día siguiente, debo proporcionarle nuevamente los documentos.
Camille: ¡De acuerdo!
Luc: Esta es la realidad de LCI (Aprendizaje en Contexto Limitado). Es increíblemente flexible, pero se basa en una memoria a corto plazo. El afilado, por el contrario, tiene como objetivo crear competencia permanente. Cuando afinas un modelo, modificas fundamentalmente su estructura interna. Los nuevos conocimientos se convierten en parte integral de su identidad.
Camille: Por lo tanto, ¿los conocimientos obtenidos del afilado permanecen en todas las conversaciones de forma permanente?
Luc: ¡Sí! Es como aprender a montar en bicicleta. La habilidad se queda grabada. Ya no necesitas recordar las leyes del equilibrio cada vez que te subes.
Camille: Luc, esto explica una experiencia muy común con los chatbots: puedes tener una conversación larga y detallada, pero si inicias una nueva conversación, la inteligencia artificial no recuerda lo discutido previamente.
Luc: ¡Exactamente! Este es el aprendizaje en contexto en acción. Todo el historial de su conversación en esta sesión sirve como contexto.
Camille: ¡Entiendo!
Luc: Cuando abres una nueva ventana, comienzas desde un contexto en blanco. La IA no 'olvida' en el sentido humano; simplemente se limpia su espacio de trabajo temporal.
Camille: ¿Pero qué pasa con nuevas funciones como la 'Memoria' que algunas IA comienzan a integrar? Uno tiene la impresión de que realmente empiezan a recordar cosas de una sesión a otra.
Luc: Es una excelente observación, y es fundamental entender cómo funciona la IA al respecto. La inteligencia artificial no se mejora continuamente a través de nuestras conversaciones; hacerlo sería extremadamente ineficiente.
Camille: ¿Es entonces un truco?
Luc: Se puede decir que es así. Estas funciones de memoria son una forma astuta de aprendizaje en contexto automatizado. Cuando inicias una nueva conversación, el sistema busca rápidamente en tus intercambios previos la información relevante para tu solicitud. Luego, inserta automáticamente estos fragmentos en la petición, detrás de escena.
Camille: Por lo tanto, da la impresión de que la IA recuerda los detalles de mi proyecto, pero en realidad solo le proporcionaron un esquema justo antes de comenzar a conversar conmigo.
Luc: Precisamente. El modelo no aprende ni evoluciona a partir de las discusiones con los usuarios. En su lugar, utiliza un sistema inteligente para recordar y utilizar el contexto anterior en la conversación.
Camille: ¿Por lo tanto, la gran pregunta para quien utiliza estas herramientas es: ¿Necesito un consultor temporal o un experto permanente?
Luc: Esta es, en efecto, la manera ideal de plantear el problema. Y sobre esta reflexión, es momento de concluir.
Camille: ¡Gracias por escucharnos! Nos vemos pronto en el próximo episodio de 'Tech Éclair'.
