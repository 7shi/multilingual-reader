Camille: ¡Hola a todos! Bienvenidos a 'Tecno Revelada', el podcast en el que explicamos la tecnología que transforma nuestro mundo. Soy Camille.
Luc: Y yo soy Luc. Hoy, vamos a desvelar cómo los modelos de IA que utilizamos en nuestro día a día aprenden y se vuelven así de inteligentes.
Camille: Es un tema fascinante. A menudo vemos a estas IA como algo misterioso, pero su aprendizaje sigue un proceso muy concreto.
Luc: Exactamente. Y este aprendizaje comienza a través de un proceso llamado pre-entrenamiento.
Camille: Pre-entrenamiento
Luc: Imaginen que enviamos una IA completamente nueva a la escuela para proporcionarle una base de conocimientos generales. Lee una gran cantidad de datos en Internet para aprender los fundamentos del lenguaje, el razonamiento y cómo funciona el mundo.
Camille: Así que, después del pre-entrenamiento, la IA es como un joven universitario: inteligente y competente, pero sin experiencia profesional específica.
Luc: Precisamente. Y durante mucho tiempo, la siguiente etapa fue « el perfeccionamiento » (fine-tuning). Es como enviar a ese profesional a especializarse.
Camille: El perfeccionamiento... ¿Es en ese punto cuando se utiliza « el aprendizaje por transferencia »? Ya he oído ese término.
Luc: Exactamente. El aprendizaje por transferencia es la clave. Por ejemplo, no le enseñaría matemáticas básicas a un brillante físico antes de que se dedicara a la mecánica cuántica. Transfiere sus conocimientos matemáticos existentes. La IA actúa de manera similar. Los idiomas son un excelente ejemplo.
Camille: ¿Qué quiere decir?
Luc: Se puede tomar un modelo experto en inglés y luego exponerle una cantidad significativamente menor de texto en francés. Aprenderá francés de forma sorprendentemente rápida.
Camille: Porque ya comprende los conceptos generales de gramática, sintaxis y estructura de la oración gracias al inglés?
Luc: Exactamente. No necesita volver a aprender qué es un verbo. Simplemente aprende las palabras y las reglas del francés, aprovechando los conceptos subyacentes. Esa es toda la potencia de este enfoque.
Camille: Así, transfiere su amplio conocimiento general derivado del pre-entrenamiento a la nueva tarea específica.
Luc: Así es exactamente. Es por eso que puede convertirse en un experto de sus datos con sorprendentemente poca información nueva. No parte de cero; se apoya en cimientos extremadamente sólidos.
Camille: Es lógico. Pero como discutimos en nuestro último episodio sobre los Transformers, un enfoque más flexible está emergiendo gradualmente, ¿no es así?
Luc: Sí, y esto es posible gracias a un aumento significativo de la memoria a corto plazo de la IA, o 'ventana de contexto'. Este enfoque se llama aprendizaje en contexto, o ICL (Aprendizaje en Contexto).
Camille: Así, en lugar de volver a entrenar a la IA para convertirla en especialista, simplemente le proporcionamos la información necesaria para llevar a cabo la tarea.
Luc: Lo has entendido perfectamente. Es como contratar a un consultor brillante y, en lugar de enviarlo a un programa de formación de varios años, simplemente darle la información precisa que necesita para el proyecto actual.
Camille: Es ahí donde entra en juego el concepto de 'fundamentación', que consiste en conectar las respuestas de la IA con la información específica que tú proporcionas. Esto permite que la IA se base en datos concretos y reales para generar sus respuestas.
Luc: Precisamente. Pero esto nos lleva a un punto crucial que a menudo se malinterpreta: cómo la IA 'recuerda' esta información. Es la diferencia entre un conocimiento temporal y un dominio.
Camille: La diferencia entre aprender de memoria para un examen y comprender realmente un tema?
Luc: Una analogía perfecta. El aprendizaje en contexto es como estudiar deprisa para un examen. Las informaciones que le proporcionas en el prompt son temporales. Simplemente, una vez finalizada la conversación, estas informaciones se desvanecen.
Camille: Ella lo olvida.
Luc: Simplemente lo olvida todo. Así que es como una memoria de uso único. Si quiero que ella tenga conocimiento de la misma información mañana, tengo que volver a proporcionársela.
Camille: De acuerdo.
Luc: Esta es la realidad del ICL. Es increíblemente flexible, pero se basa en una memoria a corto plazo. El ajuste fino, por otro lado, tiene como objetivo crear una competencia permanente. Cuando entrenas un modelo, modificas fundamentalmente su estructura interna. Los nuevos conocimientos se integran en sus capacidades aprendidas.
Camille: Así que, el conocimiento adquirido a través del ajuste fino persiste en todas las conversaciones, simplemente para siempre?
Luc: Sí. Es como aprender a montar en bicicleta. La habilidad queda grabada, se aprende para siempre. No necesitas que te recuerden las leyes del equilibrio cada vez que te subes a la bicicleta.
Camille: Luc, esto explica una experiencia muy común con los chatbots. Puedes tener una conversación larga y detallada, pero si abres una nueva ventana de chat, la IA simplemente no recuerda lo que hablamos.
Luc: ¡Exactamente! Esto es aprendizaje basado en el contexto en acción. Todo el historial de tu conversación en esta sesión es lo que proporciona el contexto.
Camille: Entiendo.
Luc: Cuando abres una nueva ventana, partes de un contexto vacío. La IA no ha « olvidado » en el sentido humano del término; su área de trabajo temporal simplemente ha sido reiniciada.
Camille: Pero, ¿qué pasa con las nuevas funcionalidades como la ‘Memoria’ que algunas IAs están empezando a integrar? Uno podría pensar que realmente empiezan a acordarse de cosas de una sesión a otra.
Luc: Es una observación excelente, y es crucial entender cómo funciona. La IA no se refina constantemente con tus conversaciones, sería muy poco práctico.
Camille: ¿Es un truco, entonces?
Luc: Podemos decir esto. Las funciones de memorización son una forma astuta de aprendizaje en contexto automatizado. Cuando comienzas una nueva conversación, el sistema busca rápidamente en tus antiguos intercambios la información que parece relevante para tu nueva solicitud. Luego, inserta automáticamente estos extractos en el prompt, de forma automática en segundo plano.
Camille: Entonces, da la impresión de que la IA recuerda los detalles de mi proyecto, pero en realidad, simplemente le hemos proporcionado un atajo justo antes de que empezara a responder.
Luc: Exactamente. El propio modelo no aprende ni evoluciona de tus conversaciones. Simplemente consulta un método más ingenioso para acceder al contexto previo.
Camille: Entonces, la gran pregunta para quien usa estas herramientas es: ¿Necesito un consultor temporal o un experto a largo plazo?
Luc: Es la forma ideal de plantear el problema. Así, con esta reflexión, es momento de concluir.
Camille: Gracias por escucharnos, ¡nos vemos pronto para el próximo episodio de « Tech Éclair »!
