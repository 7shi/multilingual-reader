Camille: Hola y bienvenidos a «Tech Éclair», el podcast donde desciframos la tecnología que configura nuestro mundo. Es un placer tenerlos aquí. Soy Camille.
Luc: Y soy Luc. Hoy vamos a revelar cómo los modelos de IA que utilizamos cada día aprenden y se vuelven tan inteligentes.
Camille: Es un tema fascinante. A menudo percibimos estas IA como si fueran cajas oscuras, pero en realidad, su aprendizaje sigue un proceso muy definido y real.
Luc: En efecto, y este aprendizaje comienza por un proceso llamado el « pre-entrenamiento ».
Camille: El preentrenamiento
Luc: Imaginen que enviamos una inteligencia artificial completamente nueva a la escuela para darle una cultura general. Lee una cantidad enorme de datos en Internet para aprender los fundamentos del lenguaje, el razonamiento y el funcionamiento del mundo en general.
Camille: Entonces, una vez completado el preentrenamiento, la IA es como un recién graduado: inteligente y competente, pero sin experiencia laboral específica.
Luc: Exactamente. Y durante mucho tiempo, la etapa siguiente ha sido el "afinamiento". Es como enviar a este graduado a realizar una especialización.
Camille: El afinamiento... ahí es donde interviene « el aprendizaje por transferencia » ? Ya he oído este término.
Luc: Exactamente. El aprendizaje por transferencia es fundamental. Por ejemplo, no enseñarías matemáticas básicas a un brillante físico antes de que se ocupe de la mecánica cuántica; en su lugar, aplicaría las habilidades matemáticas que ya posee. De manera similar, la IA hace lo mismo. Los idiomas son un ejemplo excelente de esto.
Camille: ?Es decir? or more naturally ?Qué quieres decir?
Luc: Puedes tomar un modelo experto en inglés y luego presentarle una cantidad mucho menor de texto en francés. Aprenderá el francés de manera increíblemente rápida.
Camille: ¿Es porque ya comprende los conceptos lingüísticos generales, como la gramática y la sintaxis, gracias al inglés?
Luc: Exactamente. No tiene que volver a aprender lo que es un verbo. Simplemente aprende las palabras y las reglas de una nueva lengua, al transferir los conceptos básicos. Es toda la fuerza de este método.
Camille: Entonces, transfiere sus amplios conocimientos generales obtenidos en el preentrenamiento a la nueva tarea específica.
Luc: Es completamente así. Es por eso que puede convertirse en un experto en tus datos con una cantidad sorprendentemente pequeña de nueva información. No parte de cero; se basa en fundamentos muy sólidos.
Camille: Es lógico. Pero como lo discutimos en nuestro último episodio sobre los Transformers, un enfoque más innovador y adaptable está surgiendo.
Luc: Sí, y se hace posible gracias a una gran expansión de la memoria a corto plazo de la IA, o «ventana de contexto». Este enfoque recibe el nombre de aprendizaje en contexto, o ICL (Aprendizaje en Contexto), lo que permite un proceso de aprendizaje más flexible y adaptado al contexto.
Camille: Entonces, en lugar de reentrenar a la IA para hacer de ella una especialista, simplemente se le da la información necesaria para la tarea.
Luc: Ustedes han entendido todo. Es como tomar a un asesor excepcional y, en lugar de enviarlo a seguir un programa de formación de varios años, simplemente proporcionarle los informes precisos necesarios para el proyecto en curso.
Camille: Es donde interviene el concepto de 'anclaje' (anclaje), que consiste en vincular las respuestas de la IA a la información específica que usted proporciona.
Luc: En efecto, esto nos lleva a un punto crucial que frecuentemente es malentendido: la forma en que la IA 'recuerda' esta información. Esta distinción es fundamental entre un conocimiento temporal y una competencia permanente.
Camille: ¿Cuál es la diferencia entre prepararse a fondo para un examen y realmente dominar un tema?
Luc: ¡Una analogía perfecta! El aprendizaje en contexto es como un aprendizaje superficial. Los conocimientos que usted proporciona en el prompt son temporales. La IA los utiliza para esta única conversación, pero una vez que la conversación termina, estos conocimientos desaparecen.
Camille: Ella lo olvida todo. (However, given that 'Ella olvida todo' already accurately translates the original message and considering the context might not necessarily require 'lo', the original draft translation is deemed sufficient for most purposes.)
Luc: Ella olvida todo. Es por eso una memoria para un solo uso. Si quiero que tenga conocimiento de la misma información mañana, debo proporcionarle los documentos de nuevo.
Camille: De acuerdo
Luc: Así es la realidad de la ICL: es extremadamente flexible, pero se basa en una memoria a corto plazo. Por otro lado, el perfeccionamiento o afinación busca crear una competencia permanente. Cuando perfeccionas o afinas un modelo, modificas fundamentalmente su estructura interna, haciendo que los nuevos conocimientos se conviertan en parte integral de su identidad.
Camille: ¿Entonces, los conocimientos obtenidos del perfeccionamiento persisten en todas las conversaciones, para siempre?
Luc: Sí, es como cuando aprendes a montar en bicicleta; la habilidad se arraiga. No necesitas que te expliquen las leyes del equilibrio cada vez que te sientas en el asiento.
Camille: Luc, esto explica una experiencia muy común con los chatbots. Una conversación puede ser larga y detallada, pero si se abre una nueva ventana de conversación, la IA no tiene idea de lo que se ha dicho antes.
Luc: Exacto, se trata del aprendizaje en contexto en acción. La totalidad del historial de su discusión en esta sesión constituye el contexto.
Camille: Entiendo
Luc: Cuando abres una nueva ventana, comienzas sin ningún contexto previo. La IA no tiene la capacidad de recordar como lo hace un ser humano; simplemente se ha reiniciado su espacio de trabajo temporal.
Camille: Pero ¿qué hay de las nuevas funcionalidades como la «Memoria» que algunas IAs empiezan a integrar? Parece que realmente comienzan a recordar cosas de una sesión a otra.
Luc: Es un excelente comentario y es crucial comprender cómo funciona esto. La IA no se perfecciona constantemente a través de sus conversaciones. Sería sumamente ineficaz.
Camille: ¿Es un truco?
Luc: Se puede decir eso. Estas funciones de memoria son una forma astuta de aprendizaje automático en contexto. Cuando comienzas una nueva conversación, el sistema busca rápidamente en tus antiguos intercambios la información que parece relevante para tu nueva solicitud. Luego, inserta automáticamente estos extractos en el prompt, detrás de escena.
Camille: Entonces, se tiene la impresión de que la IA recuerda los detalles de mi proyecto, pero en realidad, acaba de recibir la información justo antes de empezar a hablar.
Luc: Precisamente, el modelo en sí no aprende ni evoluciona a partir de conversaciones. Simplemente utiliza un sistema más inteligente para recordar el contexto pasado.
Camille: Entonces, la gran pregunta para quienquiera que use estos recursos es: ¿Necesito un consultor temporal o un experto permanente?
Luc: Es la manera ideal de plantear el problema. Con esta reflexión, llega el momento de concluir.
Camille: Gracias por habernos escuchado, y hasta la próxima para el próximo episodio de 'Tech Éclair'.
